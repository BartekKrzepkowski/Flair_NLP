{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip3 install git+https://github.com/zalandoresearch/flair","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting git+https://github.com/zalandoresearch/flair\n  Cloning https://github.com/zalandoresearch/flair to /tmp/pip-req-build-m25ialjt\n  Running command git clone -q https://github.com/zalandoresearch/flair /tmp/pip-req-build-m25ialjt\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n\u001b[?25hCollecting segtok>=1.5.7 (from flair==0.4.2)\n  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (1.1.0)\nCollecting bpemb>=0.2.9 (from flair==0.4.2)\n  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\nRequirement already satisfied: matplotlib>=2.2.3 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (3.0.3)\nCollecting sqlitedict>=1.6.0 (from flair==0.4.2)\n  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\nRequirement already satisfied: sklearn in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (0.0)\nRequirement already satisfied: ipython==7.6.1 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (7.6.1)\nCollecting pytorch-transformers>=1.0.0 (from flair==0.4.2)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/b5/2d78e74001af0152ee61d5ad4e290aec9a1e43925b21df2dc74ec100f1ab/pytorch_transformers-1.0.0-py3-none-any.whl (137kB)\n\u001b[K     |████████████████████████████████| 143kB 6.8MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pytest>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (5.0.1)\nRequirement already satisfied: hyperopt>=0.1.1 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (0.1.2)\nRequirement already satisfied: ipython-genutils==0.2.0 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (0.2.0)\nRequirement already satisfied: tqdm>=4.26.0 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (4.32.1)\nRequirement already satisfied: urllib3<1.25,>=1.20 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (1.24.2)\nRequirement already satisfied: langdetect in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (1.0.7)\nRequirement already satisfied: mpld3==0.3 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (0.3)\nRequirement already satisfied: gensim>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (3.8.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (2019.6.8)\nCollecting deprecated>=1.2.4 (from flair==0.4.2)\n  Downloading https://files.pythonhosted.org/packages/88/0e/9d5a1a8cd7130c49334cce7b8167ceda63d6a329c8ea65b626116bc9e9e6/Deprecated-1.2.6-py2.py3-none-any.whl\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.6/site-packages/tabulate-0.8.3-py3.6.egg (from flair==0.4.2) (0.8.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch>=1.0.0->flair==0.4.2) (1.16.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (from bpemb>=0.2.9->flair==0.4.2) (0.1.82)\nRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from bpemb>=0.2.9->flair==0.4.2) (2.22.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair==0.4.2) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair==0.4.2) (1.1.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.4.0)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.8.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from sklearn->flair==0.4.2) (0.21.2)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (0.7.5)\nRequirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (2.4.2)\nRequirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (4.3.2)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (0.1.0)\nRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (2.0.9)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (4.4.0)\nRequirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (4.7.0)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (41.0.1)\nRequirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (0.13.3)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from pytorch-transformers>=1.0.0->flair==0.4.2) (1.9.194)\nRequirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (1.8.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (19.0)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (19.1.0)\nRequirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (7.0.0)\nRequirement already satisfied: atomicwrites>=1.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (1.3.0)\nRequirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (0.12.0)\nRequirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (0.17)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (0.1.7)\nRequirement already satisfied: networkx==2.2 in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair==0.4.2) (2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair==0.4.2) (1.2.1)\nRequirement already satisfied: pymongo in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair==0.4.2) (3.8.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair==0.4.2) (1.12.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair==0.4.2) (0.17.1)\nRequirement already satisfied: smart-open>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from gensim>=3.4.0->flair==0.4.2) (1.8.4)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.6/site-packages (from deprecated>=1.2.4->flair==0.4.2) (1.11.2)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->bpemb>=0.2.9->flair==0.4.2) (2019.6.16)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->bpemb>=0.2.9->flair==0.4.2) (2.8)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->bpemb>=0.2.9->flair==0.4.2) (3.0.4)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn->flair==0.4.2) (0.13.2)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython==7.6.1->flair==0.4.2) (0.6.0)\nRequirement already satisfied: parso>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from jedi>=0.10->ipython==7.6.1->flair==0.4.2) (0.5.0)\nRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-transformers>=1.0.0->flair==0.4.2) (0.2.1)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-transformers>=1.0.0->flair==0.4.2) (0.9.4)\nRequirement already satisfied: botocore<1.13.0,>=1.12.194 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-transformers>=1.0.0->flair==0.4.2) (1.12.194)\n","name":"stdout"},{"output_type":"stream","text":"Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=0.12->pytest>=3.6.4->flair==0.4.2) (0.5.1)\nRequirement already satisfied: boto>=2.32 in /opt/conda/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim>=3.4.0->flair==0.4.2) (2.49.0)\nRequirement already satisfied: docutils<0.15,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.194->boto3->pytorch-transformers>=1.0.0->flair==0.4.2) (0.14)\nBuilding wheels for collected packages: flair\n  Building wheel for flair (PEP 517) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for flair: filename=flair-0.4.2-cp36-none-any.whl size=102754 sha256=d6474b207d26704633e38ec18b2df7c4ca42504f9cc5d4b22f9e23da0312c3b3\n  Stored in directory: /tmp/pip-ephem-wheel-cache-8_3dc2wt/wheels/8e/47/da/f22675cf094ae69648b301413ef8639296775f876b38a5507f\nSuccessfully built flair\nBuilding wheels for collected packages: segtok, sqlitedict\n  Building wheel for segtok (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23257 sha256=a3cb5c0065e59be731183efa9f0aa449a786d61479c6cfeb5951adb5395a0a75\n  Stored in directory: /tmp/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=72fdda6576d90b320e4aa0b469609727cf6076c8d0d35616bffcec9316fc1239\n  Stored in directory: /tmp/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\nSuccessfully built segtok sqlitedict\nInstalling collected packages: segtok, bpemb, sqlitedict, pytorch-transformers, deprecated, flair\nSuccessfully installed bpemb-0.3.0 deprecated-1.2.6 flair-0.4.2 pytorch-transformers-1.0.0 segtok-1.5.7 sqlitedict-1.6.0\n\u001b[33mWARNING: You are using pip version 19.2.1, however version 19.2.2 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\n%matplotlib inline\n\nimport torch\ntorch.cuda.is_available()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"> ## Create a Corpus"},{"metadata":{},"cell_type":"markdown","source":"### 1) Load from simple CSV file"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from flair.datasets import CSVClassificationCorpus","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great development.."},{"metadata":{},"cell_type":"markdown","source":"### 2) FastText Format"},{"metadata":{"trusted":true},"cell_type":"code","source":"from flair.data import Corpus\nfrom flair.datasets import ClassificationCorpus","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FILE_PATH = \"../input/bbc-text.csv\"\nDATASET_FOLDER_PATH = \"splitted_data\"\n# DATASET_FOLDER_PATH = os.path.join(\"splitted_data\", FILE_PATH.split(\".\")[0].split(\"/\")[1])\n\ncolumn_name = {\n    \"text\": \"text\",\n    \"label\": \"category\"\n}","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# file format\n__label__<label_1> <text>\n__label__<label_1> __label__<label_2> <text>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df = pd.read_csv(FILE_PATH).sample(frac=1)\ndata_df[column_name[\"label\"]] = '__label__' + data_df[column_name[\"label\"]].astype(str)\n\n# number of chars\ndata_df[column_name[\"text\"]].str.len().plot(kind=\"hist\", title=\"line lenght distribution\", grid=True, figsize=(10,10), bins=50);","execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x720 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nfrom string import digits, punctuation\n\ndef clear_text(text, is_all_lower=True):\n    punct = re.sub(r'[\\.,!?&\\-]', '', punctuation)\n    punctuation_table = str.maketrans({key: \"#\" for key in punct})\n    for char in [\"\\\"\", \"\\'\"]:\n        del punctuation_table[ord(char)]\n    \n    review_cleaned = text.apply(lambda x: re.sub(r'[^\\x00-\\x7F]', ' ', x))\n    review_cleaned = review_cleaned.apply(lambda x: re.sub(r'[0-9]', '9', x))\n    review_cleaned = review_cleaned.apply(lambda x: x.translate(punctuation_table))\n    review_cleaned = review_cleaned.apply(lambda x: re.sub(r' +', ' ', x))\n    review_cleaned = review_cleaned.apply(lambda x: re.sub(r' (?=[\\.,!?&\\-])','', x))\n    \n    if is_all_lower:\n        review_cleaned = review_cleaned.str.lower()\n        \n    return review_cleaned\n\ndata_df[column_name[\"text\"]] = clear_text(data_df[\"text\"])\ndata_df[column_name[\"text\"]] = data_df[column_name[\"text\"]].apply(lambda x: x[:1000])\n\n# number of chars\ndata_df[column_name[\"text\"]].str.len().plot(kind=\"hist\", title=\"line lenght distribution\", grid=True, figsize=(10,10), bins=50);","execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x720 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.exists(DATASET_FOLDER_PATH):\n    os.makedirs(DATASET_FOLDER_PATH)\ndata_df.iloc[0: int(len(data_df)*0.8)].to_csv(os.path.join(DATASET_FOLDER_PATH, 'train.csv'), sep='\\t', index = False, header = False)\ndata_df.iloc[int(len(data_df)*0.8): int(len(data_df)*0.9)].to_csv(os.path.join(DATASET_FOLDER_PATH, 'dev.csv'), sep='\\t', index = False, header = False)\ndata_df.iloc[int(len(data_df)*0.9): ].to_csv(os.path.join(DATASET_FOLDER_PATH, 'test.csv'), sep='\\t', index = False, header = False);","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus = ClassificationCorpus(DATASET_FOLDER_PATH)","execution_count":8,"outputs":[{"output_type":"stream","text":"2019-08-11 17:36:08,963 Reading data from splitted_data\n2019-08-11 17:36:08,967 Train: splitted_data/train.csv\n2019-08-11 17:36:08,971 Dev: splitted_data/dev.csv\n2019-08-11 17:36:08,972 Test: splitted_data/test.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Each line in a corpus is converted to a Sentence object annotated with the labels."},{"metadata":{},"cell_type":"markdown","source":"## Check distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(os.path.join(DATASET_FOLDER_PATH, \"train.csv\"), names=[\"label\", \"text\"], delimiter=\"\\t\")\ntrain_df.label.value_counts()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"__label__business         415\n__label__sport            414\n__label__politics         329\n__label__tech             313\n__label__entertainment    309\nName: label, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_df = pd.read_csv(os.path.join(DATASET_FOLDER_PATH, \"dev.csv\"), names=[\"label\", \"text\"], delimiter=\"\\t\")\nval_df.label.value_counts()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"__label__politics         48\n__label__business         48\n__label__sport            46\n__label__tech             44\n__label__entertainment    36\nName: label, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(os.path.join(DATASET_FOLDER_PATH, \"test.csv\"), names=[\"label\", \"text\"], delimiter=\"\\t\")\ntest_df.label.value_counts()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"__label__sport            51\n__label__business         47\n__label__tech             44\n__label__entertainment    41\n__label__politics         40\nName: label, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Training a Model"},{"metadata":{},"cell_type":"markdown","source":"## OpenAI GPT-2"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from flair.embeddings import OpenAIGPT2Embeddings, FlairEmbeddings, DocumentRNNEmbeddings\nfrom flair.models import TextClassifier\nfrom flair.trainers import ModelTrainer\nfrom flair.training_utils import EvaluationMetric\n# from flair.visual.training_curves import Plotter","execution_count":17,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"Cannot load backend 'TkAgg' which requires the 'tk' interactive framework, as 'headless' is currently running","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-952113a122fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvaluationMetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_curves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlotter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/flair/visual/training_curves.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# change from Agg to TkAgg for interative mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TkAgg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36muse\u001b[0;34m(arg, warn, force)\u001b[0m\n\u001b[1;32m   1389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mswitch_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m             \u001b[0mswitch_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1392\u001b[0m     \u001b[0;31m# Finally if pyplot is not imported update both rcParams and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m     \u001b[0;31m# rcDefaults so restoring the defaults later with rcdefaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mswitch_backend\u001b[0;34m(newbackend)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;34m\"Cannot load backend {!r} which requires the {!r} interactive \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \"framework, as {!r} is currently running\".format(\n\u001b[0;32m--> 222\u001b[0;31m                     newbackend, required_framework, current_framework))\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backend'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParamsDefault\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backend'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: Cannot load backend 'TkAgg' which requires the 'tk' interactive framework, as 'headless' is currently running"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"MODEL_FOLDER_PATH = \"model/OPENAIGPT2\"\nif not os.path.exists(MODEL_FOLDER_PATH):\n    os.makedirs(MODEL_FOLDER_PATH)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_train = {\n    \"flair_emb_forward\": 'news-forward-fast',\n    \"flair_emb_backward\": 'news-backward-fast',\n    \"hidden_size\": 256,\n    \"reproject_words_dimension\": 128,\n    \"max_epoch\": 20,\n    \"evaluation_metric\": EvaluationMetric.MICRO_ACCURACY\n}\n\nword_embeddings = [OpenAIGPT2Embeddings(), FlairEmbeddings(params_train[\"flair_emb_forward\"]),\n                   FlairEmbeddings(params_train[\"flair_emb_backward\"])]\n\ndocument_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=params_train[\"hidden_size\"],\n                                            reproject_words=True, reproject_words_dimension=params_train[\"reproject_words_dimension\"])\n\nclassifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n\ntrainer = ModelTrainer(classifier, corpus)","execution_count":15,"outputs":[{"output_type":"stream","text":"100%|██████████| 1042301/1042301 [00:00<00:00, 2142627.55B/s]\n100%|██████████| 456318/456318 [00:00<00:00, 1385148.90B/s]\n100%|██████████| 293/293 [00:00<00:00, 109180.09B/s]\n100%|██████████| 1520013706/1520013706 [00:48<00:00, 31224924.46B/s]\n","name":"stderr"},{"output_type":"stream","text":"2019-08-11 17:37:37,429 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmp5b_cwqbz\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 19689779/19689779 [00:00<00:00, 41272009.13B/s]","name":"stderr"},{"output_type":"stream","text":"2019-08-11 17:37:38,072 copying /tmp/tmp5b_cwqbz to cache at /tmp/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"2019-08-11 17:37:38,105 removing temp file /tmp/tmp5b_cwqbz\n2019-08-11 17:37:38,263 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmp8hymdgh7\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 19689779/19689779 [00:00<00:00, 39424017.25B/s]","name":"stderr"},{"output_type":"stream","text":"2019-08-11 17:37:38,931 copying /tmp/tmp8hymdgh7 to cache at /tmp/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"2019-08-11 17:37:38,963 removing temp file /tmp/tmp8hymdgh7\n2019-08-11 17:37:39,038 Computing label dictionary. Progress:\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 1780/1780 [00:10<00:00, 167.91it/s]","name":"stderr"},{"output_type":"stream","text":"2019-08-11 17:37:50,071 [b'entertainment', b'politics', b'sport', b'business', b'tech']\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"learning_rate_tsv = trainer.find_learning_rate(MODEL_FOLDER_PATH, 'learning_rate.tsv')\n\nplotter = Plotter()\nplotter.plot_learning_rate(learning_rate_tsv)","execution_count":16,"outputs":[{"output_type":"stream","text":"2019-08-11 17:41:04,483 ----------------------------------------------------------------------------------------------------\n2019-08-11 17:41:04,485 learning rate finder finished - plot model/OPENAIGPT2/learning_rate.tsv\n2019-08-11 17:41:04,487 ----------------------------------------------------------------------------------------------------\n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'Plotter' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-ba58b7d88350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearning_rate_tsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_FOLDER_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'learning_rate.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplotter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlotter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate_tsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Plotter' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer.train(MODEL_FOLDER_PATH, max_epochs=params_train[\"max_epoch\"])#, evaluation_metric=params_train[\"evaluation_metric\"])","execution_count":18,"outputs":[{"output_type":"stream","text":"2019-08-11 17:47:51,768 ----------------------------------------------------------------------------------------------------\n2019-08-11 17:47:51,772 Model: \"TextClassifier(\n  (document_embeddings): DocumentRNNEmbeddings(\n    (embeddings): StackedEmbeddings(\n      (list_embedding_0): OpenAIGPT2Embeddings(\n        (model): GPT2Model(\n          (wte): Embedding(50257, 1024)\n          (wpe): Embedding(1024, 1024)\n          (drop): Dropout(p=0.1)\n          (h): ModuleList(\n            (0): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (1): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (2): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (3): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (4): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (5): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (6): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (7): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (8): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (9): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (10): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (11): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (12): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (13): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (14): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (15): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (16): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (17): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (18): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (19): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (20): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (21): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (22): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n            (23): Block(\n              (ln_1): BertLayerNorm()\n              (attn): Attention(\n                (c_attn): Conv1D()\n                (c_proj): Conv1D()\n                (attn_dropout): Dropout(p=0.1)\n                (resid_dropout): Dropout(p=0.1)\n              )\n              (ln_2): BertLayerNorm()\n              (mlp): MLP(\n                (c_fc): Conv1D()\n                (c_proj): Conv1D()\n                (dropout): Dropout(p=0.1)\n              )\n            )\n          )\n          (ln_f): BertLayerNorm()\n        )\n      )\n      (list_embedding_1): FlairEmbeddings(\n        (lm): LanguageModel(\n          (drop): Dropout(p=0.25)\n          (encoder): Embedding(275, 100)\n          (rnn): LSTM(100, 1024)\n          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n        )\n      )\n      (list_embedding_2): FlairEmbeddings(\n        (lm): LanguageModel(\n          (drop): Dropout(p=0.25)\n          (encoder): Embedding(275, 100)\n          (rnn): LSTM(100, 1024)\n          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n        )\n      )\n    )\n    (word_reprojection_map): Linear(in_features=4096, out_features=128, bias=True)\n    (rnn): GRU(128, 256)\n    (dropout): Dropout(p=0.5)\n  )\n  (decoder): Linear(in_features=256, out_features=5, bias=True)\n  (loss_function): CrossEntropyLoss()\n)\"\n","name":"stdout"},{"output_type":"stream","text":"2019-08-11 17:47:51,774 ----------------------------------------------------------------------------------------------------\n2019-08-11 17:47:51,775 Corpus: \"Corpus: 1780 train + 222 dev + 223 test sentences\"\n2019-08-11 17:47:51,776 ----------------------------------------------------------------------------------------------------\n2019-08-11 17:47:51,777 Parameters:\n2019-08-11 17:47:51,778  - learning_rate: \"0.1\"\n2019-08-11 17:47:51,779  - mini_batch_size: \"32\"\n2019-08-11 17:47:51,780  - patience: \"3\"\n2019-08-11 17:47:51,780  - anneal_factor: \"0.5\"\n2019-08-11 17:47:51,781  - max_epochs: \"20\"\n2019-08-11 17:47:51,782  - shuffle: \"True\"\n2019-08-11 17:47:51,783  - train_with_dev: \"False\"\n2019-08-11 17:47:51,784 ----------------------------------------------------------------------------------------------------\n2019-08-11 17:47:51,785 Model training base path: \"model/OPENAIGPT2\"\n2019-08-11 17:47:51,786 ----------------------------------------------------------------------------------------------------\n2019-08-11 17:47:51,787 Device: cuda:0\n2019-08-11 17:47:51,787 ----------------------------------------------------------------------------------------------------\n2019-08-11 17:47:51,788 Embeddings storage mode: cpu\n2019-08-11 17:47:51,790 ----------------------------------------------------------------------------------------------------\n2019-08-11 17:47:57,215 epoch 1 - iter 0/56 - loss 2.22230601 throughput (samples/sec): 33.57\n2019-08-11 17:48:18,428 epoch 1 - iter 5/56 - loss 2.74820968 throughput (samples/sec): 7.77\n2019-08-11 17:48:39,034 epoch 1 - iter 10/56 - loss 2.71496595 throughput (samples/sec): 8.02\n2019-08-11 17:48:59,486 epoch 1 - iter 15/56 - loss 2.65799004 throughput (samples/sec): 8.14\n2019-08-11 17:49:19,846 epoch 1 - iter 20/56 - loss 2.60666693 throughput (samples/sec): 8.18\n2019-08-11 17:49:40,103 epoch 1 - iter 25/56 - loss 2.61654946 throughput (samples/sec): 8.12\n2019-08-11 17:50:00,261 epoch 1 - iter 30/56 - loss 2.59728107 throughput (samples/sec): 8.08\n2019-08-11 17:50:20,733 epoch 1 - iter 35/56 - loss 2.55795751 throughput (samples/sec): 8.13\n2019-08-11 17:50:41,292 epoch 1 - iter 40/56 - loss 2.52469811 throughput (samples/sec): 8.10\n2019-08-11 17:51:01,943 epoch 1 - iter 45/56 - loss 2.53503699 throughput (samples/sec): 8.06\n2019-08-11 17:51:21,240 epoch 1 - iter 50/56 - loss 2.53566669 throughput (samples/sec): 8.54\n2019-08-11 17:51:39,501 epoch 1 - iter 55/56 - loss 2.52773267 throughput (samples/sec): 9.01\n2019-08-11 17:51:39,964 ----------------------------------------------------------------------------------------------------\n2019-08-11 17:51:39,965 EPOCH 1 done: loss 2.5277 - lr 0.1000\n2019-08-11 17:52:08,604 DEV : loss 1.91029691696167 - score 0.2072\n2019-08-11 17:52:10,976 BAD EPOCHS (no improvement): 0\n2019-08-11 17:52:13,565 ----------------------------------------------------------------------------------------------------\n2019-08-11 17:52:20,836 epoch 2 - iter 0/56 - loss 2.06022000 throughput (samples/sec): 36.20\n2019-08-11 17:52:40,716 epoch 2 - iter 5/56 - loss 2.25667063 throughput (samples/sec): 8.29\n2019-08-11 17:53:01,532 epoch 2 - iter 10/56 - loss 2.35487999 throughput (samples/sec): 8.00\n2019-08-11 17:53:21,240 epoch 2 - iter 15/56 - loss 2.44287254 throughput (samples/sec): 8.45\n2019-08-11 17:53:40,968 epoch 2 - iter 20/56 - loss 2.43142608 throughput (samples/sec): 8.36\n2019-08-11 17:54:00,661 epoch 2 - iter 25/56 - loss 2.42021353 throughput (samples/sec): 8.39\n2019-08-11 17:54:20,395 epoch 2 - iter 30/56 - loss 2.44315767 throughput (samples/sec): 8.38\n2019-08-11 17:54:39,730 epoch 2 - iter 35/56 - loss 2.44777561 throughput (samples/sec): 8.52\n2019-08-11 17:54:59,600 epoch 2 - iter 40/56 - loss 2.44910931 throughput (samples/sec): 8.40\n2019-08-11 17:55:19,365 epoch 2 - iter 45/56 - loss 2.46369523 throughput (samples/sec): 8.45\n2019-08-11 17:55:38,948 epoch 2 - iter 50/56 - loss 2.45364740 throughput (samples/sec): 8.49\n2019-08-11 17:55:57,517 epoch 2 - iter 55/56 - loss 2.44718728 throughput (samples/sec): 8.87\n2019-08-11 17:55:57,959 ----------------------------------------------------------------------------------------------------\n2019-08-11 17:55:57,960 EPOCH 2 done: loss 2.4472 - lr 0.1000\n2019-08-11 17:56:25,737 DEV : loss 2.506629467010498 - score 0.2162\n2019-08-11 17:56:27,802 BAD EPOCHS (no improvement): 0\n2019-08-11 17:56:30,710 ----------------------------------------------------------------------------------------------------\n2019-08-11 17:56:38,973 epoch 3 - iter 0/56 - loss 2.47903848 throughput (samples/sec): 24.63\n2019-08-11 17:56:58,735 epoch 3 - iter 5/56 - loss 2.55332740 throughput (samples/sec): 8.34\n2019-08-11 17:57:18,888 epoch 3 - iter 10/56 - loss 2.43089267 throughput (samples/sec): 8.20\n2019-08-11 17:57:38,908 epoch 3 - iter 15/56 - loss 2.51922715 throughput (samples/sec): 8.25\n2019-08-11 17:57:58,676 epoch 3 - iter 20/56 - loss 2.54847452 throughput (samples/sec): 8.34\n2019-08-11 17:58:18,783 epoch 3 - iter 25/56 - loss 2.52238943 throughput (samples/sec): 8.21\n2019-08-11 17:58:38,522 epoch 3 - iter 30/56 - loss 2.55812165 throughput (samples/sec): 8.36\n2019-08-11 17:58:58,190 epoch 3 - iter 35/56 - loss 2.58939192 throughput (samples/sec): 8.39\n2019-08-11 17:59:17,552 epoch 3 - iter 40/56 - loss 2.60787283 throughput (samples/sec): 8.51\n2019-08-11 17:59:36,915 epoch 3 - iter 45/56 - loss 2.60010744 throughput (samples/sec): 8.61\n2019-08-11 17:59:55,886 epoch 3 - iter 50/56 - loss 2.59033098 throughput (samples/sec): 8.88\n2019-08-11 18:00:13,778 epoch 3 - iter 55/56 - loss 2.59936330 throughput (samples/sec): 9.21\n2019-08-11 18:00:14,232 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:00:14,233 EPOCH 3 done: loss 2.5994 - lr 0.1000\n2019-08-11 18:00:42,455 DEV : loss 2.1446471214294434 - score 0.1622\n2019-08-11 18:00:44,489 BAD EPOCHS (no improvement): 1\n2019-08-11 18:00:44,491 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:00:52,710 epoch 4 - iter 0/56 - loss 2.24961257 throughput (samples/sec): 36.20\n2019-08-11 18:01:13,672 epoch 4 - iter 5/56 - loss 2.38534588 throughput (samples/sec): 7.94\n2019-08-11 18:01:33,355 epoch 4 - iter 10/56 - loss 2.39714908 throughput (samples/sec): 8.32\n2019-08-11 18:01:52,995 epoch 4 - iter 15/56 - loss 2.48356203 throughput (samples/sec): 8.60\n2019-08-11 18:02:12,763 epoch 4 - iter 20/56 - loss 2.46797093 throughput (samples/sec): 8.36\n2019-08-11 18:02:32,481 epoch 4 - iter 25/56 - loss 2.43020099 throughput (samples/sec): 8.38\n2019-08-11 18:02:52,444 epoch 4 - iter 30/56 - loss 2.44557681 throughput (samples/sec): 8.34\n2019-08-11 18:03:12,527 epoch 4 - iter 35/56 - loss 2.48641005 throughput (samples/sec): 8.31\n2019-08-11 18:03:32,811 epoch 4 - iter 40/56 - loss 2.51324778 throughput (samples/sec): 8.08\n2019-08-11 18:03:52,479 epoch 4 - iter 45/56 - loss 2.50834463 throughput (samples/sec): 8.39\n2019-08-11 18:04:11,576 epoch 4 - iter 50/56 - loss 2.51416589 throughput (samples/sec): 8.63\n2019-08-11 18:04:29,726 epoch 4 - iter 55/56 - loss 2.51358575 throughput (samples/sec): 9.20\n2019-08-11 18:04:30,232 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:04:30,234 EPOCH 4 done: loss 2.5136 - lr 0.1000\n2019-08-11 18:04:58,607 DEV : loss 2.3178603649139404 - score 0.2027\n2019-08-11 18:05:00,870 BAD EPOCHS (no improvement): 2\n2019-08-11 18:05:00,872 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:05:07,126 epoch 5 - iter 0/56 - loss 2.28775644 throughput (samples/sec): 38.69\n2019-08-11 18:05:26,954 epoch 5 - iter 5/56 - loss 2.31419899 throughput (samples/sec): 8.30\n2019-08-11 18:05:46,703 epoch 5 - iter 10/56 - loss 2.39166538 throughput (samples/sec): 8.36\n2019-08-11 18:06:07,783 epoch 5 - iter 15/56 - loss 2.33477566 throughput (samples/sec): 7.99\n2019-08-11 18:06:27,461 epoch 5 - iter 20/56 - loss 2.38692374 throughput (samples/sec): 8.40\n2019-08-11 18:06:47,341 epoch 5 - iter 25/56 - loss 2.39532798 throughput (samples/sec): 8.36\n2019-08-11 18:07:07,194 epoch 5 - iter 30/56 - loss 2.37773647 throughput (samples/sec): 8.31\n","name":"stdout"},{"output_type":"stream","text":"2019-08-11 18:07:26,743 epoch 5 - iter 35/56 - loss 2.42470578 throughput (samples/sec): 8.33\n2019-08-11 18:07:46,461 epoch 5 - iter 40/56 - loss 2.39305915 throughput (samples/sec): 8.37\n2019-08-11 18:08:05,937 epoch 5 - iter 45/56 - loss 2.39141402 throughput (samples/sec): 8.66\n2019-08-11 18:08:25,034 epoch 5 - iter 50/56 - loss 2.38986279 throughput (samples/sec): 8.64\n2019-08-11 18:08:42,845 epoch 5 - iter 55/56 - loss 2.40284807 throughput (samples/sec): 9.24\n2019-08-11 18:08:43,350 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:08:43,351 EPOCH 5 done: loss 2.4028 - lr 0.1000\n2019-08-11 18:09:11,404 DEV : loss 2.041531801223755 - score 0.2162\n2019-08-11 18:09:13,408 BAD EPOCHS (no improvement): 3\n2019-08-11 18:09:16,031 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:09:25,228 epoch 6 - iter 0/56 - loss 2.17345452 throughput (samples/sec): 41.07\n2019-08-11 18:09:44,610 epoch 6 - iter 5/56 - loss 2.24203392 throughput (samples/sec): 8.59\n2019-08-11 18:10:03,828 epoch 6 - iter 10/56 - loss 2.26736685 throughput (samples/sec): 8.60\n2019-08-11 18:10:23,065 epoch 6 - iter 15/56 - loss 2.18297715 throughput (samples/sec): 8.67\n2019-08-11 18:10:42,710 epoch 6 - iter 20/56 - loss 2.22040400 throughput (samples/sec): 8.49\n2019-08-11 18:11:03,042 epoch 6 - iter 25/56 - loss 2.23320235 throughput (samples/sec): 8.19\n2019-08-11 18:11:22,507 epoch 6 - iter 30/56 - loss 2.23020445 throughput (samples/sec): 8.39\n2019-08-11 18:11:42,175 epoch 6 - iter 35/56 - loss 2.24840983 throughput (samples/sec): 8.39\n2019-08-11 18:12:01,714 epoch 6 - iter 40/56 - loss 2.26372451 throughput (samples/sec): 8.53\n2019-08-11 18:12:21,191 epoch 6 - iter 45/56 - loss 2.27732073 throughput (samples/sec): 8.57\n2019-08-11 18:12:40,290 epoch 6 - iter 50/56 - loss 2.27764307 throughput (samples/sec): 8.73\n2019-08-11 18:12:57,853 epoch 6 - iter 55/56 - loss 2.29367940 throughput (samples/sec): 9.37\n2019-08-11 18:12:58,340 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:12:58,341 EPOCH 6 done: loss 2.2937 - lr 0.1000\n2019-08-11 18:13:25,665 DEV : loss 2.5452561378479004 - score 0.2072\nEpoch     5: reducing learning rate of group 0 to 5.0000e-02.\n2019-08-11 18:13:27,967 BAD EPOCHS (no improvement): 4\n2019-08-11 18:13:27,968 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:13:33,548 epoch 7 - iter 0/56 - loss 2.50782561 throughput (samples/sec): 35.52\n2019-08-11 18:13:53,429 epoch 7 - iter 5/56 - loss 2.02442946 throughput (samples/sec): 8.40\n2019-08-11 18:14:13,097 epoch 7 - iter 10/56 - loss 1.96421818 throughput (samples/sec): 8.51\n2019-08-11 18:14:32,986 epoch 7 - iter 15/56 - loss 1.96635174 throughput (samples/sec): 8.30\n2019-08-11 18:14:52,264 epoch 7 - iter 20/56 - loss 1.93885610 throughput (samples/sec): 8.65\n2019-08-11 18:15:11,849 epoch 7 - iter 25/56 - loss 1.91859389 throughput (samples/sec): 8.43\n2019-08-11 18:15:31,132 epoch 7 - iter 30/56 - loss 1.91702621 throughput (samples/sec): 8.55\n2019-08-11 18:15:50,336 epoch 7 - iter 35/56 - loss 1.91494139 throughput (samples/sec): 8.67\n2019-08-11 18:16:10,408 epoch 7 - iter 40/56 - loss 1.91348503 throughput (samples/sec): 8.33\n2019-08-11 18:16:29,109 epoch 7 - iter 45/56 - loss 1.91443667 throughput (samples/sec): 8.79\n2019-08-11 18:16:47,769 epoch 7 - iter 50/56 - loss 1.90114595 throughput (samples/sec): 8.95\n2019-08-11 18:17:04,636 epoch 7 - iter 55/56 - loss 1.89818058 throughput (samples/sec): 9.92\n2019-08-11 18:17:05,089 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:17:05,090 EPOCH 7 done: loss 1.8982 - lr 0.0500\n2019-08-11 18:17:32,308 DEV : loss 1.9456826448440552 - score 0.2162\n2019-08-11 18:17:34,251 BAD EPOCHS (no improvement): 1\n2019-08-11 18:17:36,983 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:17:46,434 epoch 8 - iter 0/56 - loss 1.66044915 throughput (samples/sec): 42.67\n2019-08-11 18:18:05,347 epoch 8 - iter 5/56 - loss 1.86264898 throughput (samples/sec): 8.60\n2019-08-11 18:18:24,285 epoch 8 - iter 10/56 - loss 1.86433261 throughput (samples/sec): 8.70\n2019-08-11 18:18:43,216 epoch 8 - iter 15/56 - loss 1.86964839 throughput (samples/sec): 8.78\n2019-08-11 18:19:02,240 epoch 8 - iter 20/56 - loss 1.86713017 throughput (samples/sec): 8.67\n2019-08-11 18:19:21,100 epoch 8 - iter 25/56 - loss 1.86683967 throughput (samples/sec): 8.82\n2019-08-11 18:19:40,353 epoch 8 - iter 30/56 - loss 1.87424247 throughput (samples/sec): 8.56\n2019-08-11 18:19:59,324 epoch 8 - iter 35/56 - loss 1.86726341 throughput (samples/sec): 8.56\n2019-08-11 18:20:18,932 epoch 8 - iter 40/56 - loss 1.86010206 throughput (samples/sec): 8.48\n2019-08-11 18:20:38,129 epoch 8 - iter 45/56 - loss 1.87164898 throughput (samples/sec): 8.60\n2019-08-11 18:20:57,201 epoch 8 - iter 50/56 - loss 1.86829889 throughput (samples/sec): 8.64\n2019-08-11 18:21:15,061 epoch 8 - iter 55/56 - loss 1.86776564 throughput (samples/sec): 9.12\n2019-08-11 18:21:15,558 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:21:15,560 EPOCH 8 done: loss 1.8678 - lr 0.0500\n2019-08-11 18:21:42,845 DEV : loss 1.8334760665893555 - score 0.2072\n2019-08-11 18:21:44,857 BAD EPOCHS (no improvement): 2\n2019-08-11 18:21:44,859 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:21:52,593 epoch 9 - iter 0/56 - loss 1.58567667 throughput (samples/sec): 43.73\n2019-08-11 18:22:11,564 epoch 9 - iter 5/56 - loss 1.93388226 throughput (samples/sec): 8.70\n2019-08-11 18:22:30,242 epoch 9 - iter 10/56 - loss 1.96131247 throughput (samples/sec): 8.85\n2019-08-11 18:22:49,121 epoch 9 - iter 15/56 - loss 1.93226086 throughput (samples/sec): 8.83\n2019-08-11 18:23:07,990 epoch 9 - iter 20/56 - loss 1.91640231 throughput (samples/sec): 8.75\n2019-08-11 18:23:27,199 epoch 9 - iter 25/56 - loss 1.90200956 throughput (samples/sec): 8.68\n2019-08-11 18:23:46,151 epoch 9 - iter 30/56 - loss 1.89567467 throughput (samples/sec): 8.59\n2019-08-11 18:24:05,956 epoch 9 - iter 35/56 - loss 1.90936974 throughput (samples/sec): 8.33\n2019-08-11 18:24:25,165 epoch 9 - iter 40/56 - loss 1.89598703 throughput (samples/sec): 8.68\n2019-08-11 18:24:43,964 epoch 9 - iter 45/56 - loss 1.88293814 throughput (samples/sec): 8.77\n2019-08-11 18:25:02,542 epoch 9 - iter 50/56 - loss 1.86409313 throughput (samples/sec): 8.97\n2019-08-11 18:25:19,478 epoch 9 - iter 55/56 - loss 1.85591274 throughput (samples/sec): 9.73\n2019-08-11 18:25:19,972 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:25:19,973 EPOCH 9 done: loss 1.8559 - lr 0.0500\n2019-08-11 18:25:47,540 DEV : loss 1.7273563146591187 - score 0.2072\n2019-08-11 18:25:49,535 BAD EPOCHS (no improvement): 3\n2019-08-11 18:25:49,537 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:25:57,246 epoch 10 - iter 0/56 - loss 2.14789176 throughput (samples/sec): 23.92\n2019-08-11 18:26:16,684 epoch 10 - iter 5/56 - loss 2.06343790 throughput (samples/sec): 8.55\n2019-08-11 18:26:35,209 epoch 10 - iter 10/56 - loss 2.05565191 throughput (samples/sec): 8.93\n2019-08-11 18:26:54,104 epoch 10 - iter 15/56 - loss 1.98295435 throughput (samples/sec): 8.94\n2019-08-11 18:27:13,063 epoch 10 - iter 20/56 - loss 1.94992743 throughput (samples/sec): 8.68\n2019-08-11 18:27:31,903 epoch 10 - iter 25/56 - loss 1.91168541 throughput (samples/sec): 8.86\n2019-08-11 18:27:50,818 epoch 10 - iter 30/56 - loss 1.88161040 throughput (samples/sec): 8.73\n2019-08-11 18:28:09,604 epoch 10 - iter 35/56 - loss 1.87487247 throughput (samples/sec): 8.70\n2019-08-11 18:28:28,604 epoch 10 - iter 40/56 - loss 1.85077457 throughput (samples/sec): 8.70\n2019-08-11 18:28:47,230 epoch 10 - iter 45/56 - loss 1.84253512 throughput (samples/sec): 9.07\n2019-08-11 18:29:05,932 epoch 10 - iter 50/56 - loss 1.84534862 throughput (samples/sec): 8.80\n","name":"stdout"},{"output_type":"stream","text":"2019-08-11 18:29:22,743 epoch 10 - iter 55/56 - loss 1.84739753 throughput (samples/sec): 9.83\n2019-08-11 18:29:23,239 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:29:23,241 EPOCH 10 done: loss 1.8474 - lr 0.0500\n2019-08-11 18:29:51,453 DEV : loss 1.7432754039764404 - score 0.2072\nEpoch     9: reducing learning rate of group 0 to 2.5000e-02.\n2019-08-11 18:29:53,576 BAD EPOCHS (no improvement): 4\n2019-08-11 18:29:53,577 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:29:59,070 epoch 11 - iter 0/56 - loss 1.83586848 throughput (samples/sec): 36.12\n2019-08-11 18:30:17,894 epoch 11 - iter 5/56 - loss 1.73408967 throughput (samples/sec): 8.79\n2019-08-11 18:30:36,951 epoch 11 - iter 10/56 - loss 1.69875210 throughput (samples/sec): 8.76\n2019-08-11 18:30:56,145 epoch 11 - iter 15/56 - loss 1.71058492 throughput (samples/sec): 8.60\n2019-08-11 18:31:15,654 epoch 11 - iter 20/56 - loss 1.71508685 throughput (samples/sec): 8.46\n2019-08-11 18:31:34,734 epoch 11 - iter 25/56 - loss 1.70864915 throughput (samples/sec): 8.76\n2019-08-11 18:31:53,266 epoch 11 - iter 30/56 - loss 1.70199117 throughput (samples/sec): 8.78\n2019-08-11 18:32:12,059 epoch 11 - iter 35/56 - loss 1.70594986 throughput (samples/sec): 8.77\n2019-08-11 18:32:30,612 epoch 11 - iter 40/56 - loss 1.70630777 throughput (samples/sec): 8.97\n2019-08-11 18:32:48,994 epoch 11 - iter 45/56 - loss 1.70280923 throughput (samples/sec): 8.99\n2019-08-11 18:33:07,042 epoch 11 - iter 50/56 - loss 1.70697593 throughput (samples/sec): 9.14\n2019-08-11 18:33:23,466 epoch 11 - iter 55/56 - loss 1.70846534 throughput (samples/sec): 10.03\n2019-08-11 18:33:23,915 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:33:23,916 EPOCH 11 done: loss 1.7085 - lr 0.0250\n2019-08-11 18:33:51,862 DEV : loss 1.6675934791564941 - score 0.2162\n2019-08-11 18:33:53,977 BAD EPOCHS (no improvement): 1\n2019-08-11 18:33:56,631 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:34:04,147 epoch 12 - iter 0/56 - loss 1.59903347 throughput (samples/sec): 35.44\n2019-08-11 18:34:23,143 epoch 12 - iter 5/56 - loss 1.66773645 throughput (samples/sec): 8.77\n2019-08-11 18:34:42,395 epoch 12 - iter 10/56 - loss 1.68567416 throughput (samples/sec): 8.60\n2019-08-11 18:35:01,261 epoch 12 - iter 15/56 - loss 1.72855729 throughput (samples/sec): 8.83\n2019-08-11 18:35:20,238 epoch 12 - iter 20/56 - loss 1.73091126 throughput (samples/sec): 8.83\n2019-08-11 18:35:39,087 epoch 12 - iter 25/56 - loss 1.70968693 throughput (samples/sec): 8.74\n2019-08-11 18:35:58,391 epoch 12 - iter 30/56 - loss 1.70997189 throughput (samples/sec): 8.75\n2019-08-11 18:36:17,170 epoch 12 - iter 35/56 - loss 1.71155491 throughput (samples/sec): 8.68\n2019-08-11 18:36:36,819 epoch 12 - iter 40/56 - loss 1.71037460 throughput (samples/sec): 8.70\n2019-08-11 18:36:55,062 epoch 12 - iter 45/56 - loss 1.70116616 throughput (samples/sec): 9.08\n2019-08-11 18:37:13,460 epoch 12 - iter 50/56 - loss 1.69023610 throughput (samples/sec): 9.05\n2019-08-11 18:37:30,310 epoch 12 - iter 55/56 - loss 1.69142209 throughput (samples/sec): 9.92\n2019-08-11 18:37:30,741 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:37:30,742 EPOCH 12 done: loss 1.6914 - lr 0.0250\n2019-08-11 18:37:59,122 DEV : loss 1.630503535270691 - score 0.2162\n2019-08-11 18:38:01,262 BAD EPOCHS (no improvement): 2\n2019-08-11 18:38:04,113 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:38:11,301 epoch 13 - iter 0/56 - loss 1.75466824 throughput (samples/sec): 27.99\n2019-08-11 18:38:30,801 epoch 13 - iter 5/56 - loss 1.72032984 throughput (samples/sec): 8.57\n2019-08-11 18:38:49,959 epoch 13 - iter 10/56 - loss 1.71853468 throughput (samples/sec): 8.83\n2019-08-11 18:39:09,673 epoch 13 - iter 15/56 - loss 1.71580148 throughput (samples/sec): 8.36\n2019-08-11 18:39:28,877 epoch 13 - iter 20/56 - loss 1.71402854 throughput (samples/sec): 8.77\n2019-08-11 18:39:47,968 epoch 13 - iter 25/56 - loss 1.71699529 throughput (samples/sec): 8.77\n2019-08-11 18:40:07,002 epoch 13 - iter 30/56 - loss 1.71639637 throughput (samples/sec): 8.74\n2019-08-11 18:40:26,218 epoch 13 - iter 35/56 - loss 1.70637822 throughput (samples/sec): 8.69\n2019-08-11 18:40:45,183 epoch 13 - iter 40/56 - loss 1.70094255 throughput (samples/sec): 8.80\n2019-08-11 18:41:04,266 epoch 13 - iter 45/56 - loss 1.69965227 throughput (samples/sec): 8.84\n2019-08-11 18:41:23,390 epoch 13 - iter 50/56 - loss 1.68948082 throughput (samples/sec): 8.61\n2019-08-11 18:41:40,692 epoch 13 - iter 55/56 - loss 1.68662695 throughput (samples/sec): 9.65\n2019-08-11 18:41:41,161 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:41:41,162 EPOCH 13 done: loss 1.6866 - lr 0.0250\n2019-08-11 18:42:10,710 DEV : loss 1.6179612874984741 - score 0.1982\n2019-08-11 18:42:12,990 BAD EPOCHS (no improvement): 3\n2019-08-11 18:42:12,992 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:42:18,921 epoch 14 - iter 0/56 - loss 1.62397099 throughput (samples/sec): 33.91\n2019-08-11 18:42:38,103 epoch 14 - iter 5/56 - loss 1.65232319 throughput (samples/sec): 8.58\n2019-08-11 18:42:57,001 epoch 14 - iter 10/56 - loss 1.69291092 throughput (samples/sec): 8.83\n2019-08-11 18:43:17,079 epoch 14 - iter 15/56 - loss 1.70394056 throughput (samples/sec): 8.20\n2019-08-11 18:43:37,413 epoch 14 - iter 20/56 - loss 1.69991512 throughput (samples/sec): 8.12\n2019-08-11 18:43:56,548 epoch 14 - iter 25/56 - loss 1.69596331 throughput (samples/sec): 8.64\n2019-08-11 18:44:15,830 epoch 14 - iter 30/56 - loss 1.70470927 throughput (samples/sec): 8.53\n2019-08-11 18:44:35,334 epoch 14 - iter 35/56 - loss 1.70001703 throughput (samples/sec): 8.44\n2019-08-11 18:44:54,448 epoch 14 - iter 40/56 - loss 1.70035971 throughput (samples/sec): 8.62\n2019-08-11 18:45:13,502 epoch 14 - iter 45/56 - loss 1.70025064 throughput (samples/sec): 8.77\n2019-08-11 18:45:32,295 epoch 14 - iter 50/56 - loss 1.70073073 throughput (samples/sec): 8.87\n2019-08-11 18:45:49,546 epoch 14 - iter 55/56 - loss 1.69745990 throughput (samples/sec): 9.45\n2019-08-11 18:45:50,002 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:45:50,003 EPOCH 14 done: loss 1.6975 - lr 0.0250\n2019-08-11 18:46:17,387 DEV : loss 1.6716126203536987 - score 0.2162\nEpoch    13: reducing learning rate of group 0 to 1.2500e-02.\n2019-08-11 18:46:19,367 BAD EPOCHS (no improvement): 4\n2019-08-11 18:46:22,348 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:46:31,554 epoch 15 - iter 0/56 - loss 1.81167662 throughput (samples/sec): 32.80\n2019-08-11 18:46:51,115 epoch 15 - iter 5/56 - loss 1.68922009 throughput (samples/sec): 8.52\n2019-08-11 18:47:10,440 epoch 15 - iter 10/56 - loss 1.67411156 throughput (samples/sec): 8.63\n2019-08-11 18:47:30,125 epoch 15 - iter 15/56 - loss 1.65382245 throughput (samples/sec): 8.41\n2019-08-11 18:47:49,124 epoch 15 - iter 20/56 - loss 1.65545659 throughput (samples/sec): 8.79\n2019-08-11 18:48:07,869 epoch 15 - iter 25/56 - loss 1.65727636 throughput (samples/sec): 8.88\n2019-08-11 18:48:26,518 epoch 15 - iter 30/56 - loss 1.65151156 throughput (samples/sec): 8.94\n2019-08-11 18:48:45,236 epoch 15 - iter 35/56 - loss 1.65597277 throughput (samples/sec): 8.75\n2019-08-11 18:49:04,113 epoch 15 - iter 40/56 - loss 1.65842332 throughput (samples/sec): 8.84\n2019-08-11 18:49:22,848 epoch 15 - iter 45/56 - loss 1.65313503 throughput (samples/sec): 8.89\n2019-08-11 18:49:41,734 epoch 15 - iter 50/56 - loss 1.65653546 throughput (samples/sec): 8.84\n2019-08-11 18:49:58,698 epoch 15 - iter 55/56 - loss 1.65542437 throughput (samples/sec): 9.73\n2019-08-11 18:49:59,169 ----------------------------------------------------------------------------------------------------\n","name":"stdout"},{"output_type":"stream","text":"2019-08-11 18:49:59,170 EPOCH 15 done: loss 1.6554 - lr 0.0125\n2019-08-11 18:50:27,476 DEV : loss 1.6633492708206177 - score 0.2072\n2019-08-11 18:50:29,617 BAD EPOCHS (no improvement): 1\n2019-08-11 18:50:29,619 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:50:35,445 epoch 16 - iter 0/56 - loss 1.73412824 throughput (samples/sec): 33.27\n2019-08-11 18:50:54,073 epoch 16 - iter 5/56 - loss 1.64891519 throughput (samples/sec): 8.85\n2019-08-11 18:51:13,368 epoch 16 - iter 10/56 - loss 1.66555891 throughput (samples/sec): 8.64\n2019-08-11 18:51:33,194 epoch 16 - iter 15/56 - loss 1.66543571 throughput (samples/sec): 8.40\n2019-08-11 18:51:52,258 epoch 16 - iter 20/56 - loss 1.66376075 throughput (samples/sec): 8.57\n2019-08-11 18:52:10,794 epoch 16 - iter 25/56 - loss 1.65871082 throughput (samples/sec): 8.88\n2019-08-11 18:52:29,985 epoch 16 - iter 30/56 - loss 1.65574518 throughput (samples/sec): 8.71\n2019-08-11 18:52:48,974 epoch 16 - iter 35/56 - loss 1.64736432 throughput (samples/sec): 8.68\n2019-08-11 18:53:07,508 epoch 16 - iter 40/56 - loss 1.64753701 throughput (samples/sec): 8.84\n2019-08-11 18:53:25,826 epoch 16 - iter 45/56 - loss 1.64696354 throughput (samples/sec): 9.19\n2019-08-11 18:53:43,879 epoch 16 - iter 50/56 - loss 1.64745956 throughput (samples/sec): 9.06\n2019-08-11 18:54:00,724 epoch 16 - iter 55/56 - loss 1.64720911 throughput (samples/sec): 9.80\n2019-08-11 18:54:01,194 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:54:01,195 EPOCH 16 done: loss 1.6472 - lr 0.0125\n2019-08-11 18:54:30,006 DEV : loss 1.6258177757263184 - score 0.2162\n2019-08-11 18:54:32,216 BAD EPOCHS (no improvement): 2\n2019-08-11 18:54:35,214 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:54:42,363 epoch 17 - iter 0/56 - loss 1.54946709 throughput (samples/sec): 36.91\n2019-08-11 18:55:01,215 epoch 17 - iter 5/56 - loss 1.64681717 throughput (samples/sec): 8.66\n2019-08-11 18:55:20,142 epoch 17 - iter 10/56 - loss 1.63664968 throughput (samples/sec): 8.80\n2019-08-11 18:55:39,416 epoch 17 - iter 15/56 - loss 1.65074071 throughput (samples/sec): 8.57\n2019-08-11 18:55:58,293 epoch 17 - iter 20/56 - loss 1.64877997 throughput (samples/sec): 8.82\n2019-08-11 18:56:17,616 epoch 17 - iter 25/56 - loss 1.65124228 throughput (samples/sec): 8.73\n2019-08-11 18:56:37,273 epoch 17 - iter 30/56 - loss 1.64464873 throughput (samples/sec): 8.36\n2019-08-11 18:56:56,175 epoch 17 - iter 35/56 - loss 1.64955516 throughput (samples/sec): 8.78\n2019-08-11 18:57:15,053 epoch 17 - iter 40/56 - loss 1.64576517 throughput (samples/sec): 8.66\n2019-08-11 18:57:33,769 epoch 17 - iter 45/56 - loss 1.64661718 throughput (samples/sec): 8.91\n2019-08-11 18:57:52,445 epoch 17 - iter 50/56 - loss 1.64670017 throughput (samples/sec): 8.93\n2019-08-11 18:58:09,558 epoch 17 - iter 55/56 - loss 1.64661067 throughput (samples/sec): 9.65\n2019-08-11 18:58:09,996 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:58:09,997 EPOCH 17 done: loss 1.6466 - lr 0.0125\n2019-08-11 18:58:38,488 DEV : loss 1.6097553968429565 - score 0.2072\n2019-08-11 18:58:40,667 BAD EPOCHS (no improvement): 3\n2019-08-11 18:58:40,669 ----------------------------------------------------------------------------------------------------\n2019-08-11 18:58:46,529 epoch 18 - iter 0/56 - loss 1.58613825 throughput (samples/sec): 40.65\n2019-08-11 18:59:05,931 epoch 18 - iter 5/56 - loss 1.64148629 throughput (samples/sec): 8.57\n2019-08-11 18:59:25,055 epoch 18 - iter 10/56 - loss 1.63217858 throughput (samples/sec): 8.64\n2019-08-11 18:59:45,025 epoch 18 - iter 15/56 - loss 1.64005320 throughput (samples/sec): 8.25\n2019-08-11 19:00:04,476 epoch 18 - iter 20/56 - loss 1.63860213 throughput (samples/sec): 8.57\n2019-08-11 19:00:24,368 epoch 18 - iter 25/56 - loss 1.63786825 throughput (samples/sec): 8.42\n2019-08-11 19:00:43,794 epoch 18 - iter 30/56 - loss 1.63734186 throughput (samples/sec): 8.52\n2019-08-11 19:01:03,159 epoch 18 - iter 35/56 - loss 1.64064580 throughput (samples/sec): 8.61\n2019-08-11 19:01:22,701 epoch 18 - iter 40/56 - loss 1.64488643 throughput (samples/sec): 8.54\n2019-08-11 19:01:42,405 epoch 18 - iter 45/56 - loss 1.64821885 throughput (samples/sec): 8.38\n2019-08-11 19:02:01,157 epoch 18 - iter 50/56 - loss 1.64808197 throughput (samples/sec): 8.92\n2019-08-11 19:02:19,233 epoch 18 - iter 55/56 - loss 1.64687523 throughput (samples/sec): 9.25\n2019-08-11 19:02:19,674 ----------------------------------------------------------------------------------------------------\n2019-08-11 19:02:19,675 EPOCH 18 done: loss 1.6469 - lr 0.0125\n2019-08-11 19:02:48,716 DEV : loss 1.6140189170837402 - score 0.2162\nEpoch    17: reducing learning rate of group 0 to 6.2500e-03.\n2019-08-11 19:02:50,878 BAD EPOCHS (no improvement): 4\n2019-08-11 19:02:54,777 ----------------------------------------------------------------------------------------------------\n2019-08-11 19:03:01,984 epoch 19 - iter 0/56 - loss 1.56199253 throughput (samples/sec): 35.81\n2019-08-11 19:03:21,147 epoch 19 - iter 5/56 - loss 1.61426584 throughput (samples/sec): 8.49\n2019-08-11 19:03:40,190 epoch 19 - iter 10/56 - loss 1.61250924 throughput (samples/sec): 8.70\n2019-08-11 19:03:59,812 epoch 19 - iter 15/56 - loss 1.61523607 throughput (samples/sec): 8.39\n2019-08-11 19:04:18,926 epoch 19 - iter 20/56 - loss 1.60535237 throughput (samples/sec): 8.66\n2019-08-11 19:04:38,164 epoch 19 - iter 25/56 - loss 1.61154106 throughput (samples/sec): 8.58\n2019-08-11 19:04:57,390 epoch 19 - iter 30/56 - loss 1.61749750 throughput (samples/sec): 8.57\n2019-08-11 19:05:16,342 epoch 19 - iter 35/56 - loss 1.61248750 throughput (samples/sec): 8.69\n2019-08-11 19:05:35,352 epoch 19 - iter 40/56 - loss 1.61821713 throughput (samples/sec): 8.69\n2019-08-11 19:05:54,236 epoch 19 - iter 45/56 - loss 1.62009838 throughput (samples/sec): 8.84\n2019-08-11 19:06:13,149 epoch 19 - iter 50/56 - loss 1.62282289 throughput (samples/sec): 8.73\n2019-08-11 19:06:30,552 epoch 19 - iter 55/56 - loss 1.62457920 throughput (samples/sec): 9.36\n2019-08-11 19:06:31,013 ----------------------------------------------------------------------------------------------------\n2019-08-11 19:06:31,015 EPOCH 19 done: loss 1.6246 - lr 0.0063\n2019-08-11 19:06:59,162 DEV : loss 1.6149247884750366 - score 0.2072\n2019-08-11 19:07:01,276 BAD EPOCHS (no improvement): 1\n2019-08-11 19:07:01,277 ----------------------------------------------------------------------------------------------------\n2019-08-11 19:07:08,518 epoch 20 - iter 0/56 - loss 1.54124331 throughput (samples/sec): 25.98\n2019-08-11 19:07:28,359 epoch 20 - iter 5/56 - loss 1.59461000 throughput (samples/sec): 8.32\n2019-08-11 19:07:47,904 epoch 20 - iter 10/56 - loss 1.58779874 throughput (samples/sec): 8.53\n2019-08-11 19:08:07,410 epoch 20 - iter 15/56 - loss 1.60558772 throughput (samples/sec): 8.49\n2019-08-11 19:08:27,267 epoch 20 - iter 20/56 - loss 1.61049094 throughput (samples/sec): 8.31\n2019-08-11 19:08:47,137 epoch 20 - iter 25/56 - loss 1.60971596 throughput (samples/sec): 8.47\n2019-08-11 19:09:06,953 epoch 20 - iter 30/56 - loss 1.61494389 throughput (samples/sec): 8.24\n2019-08-11 19:09:26,252 epoch 20 - iter 35/56 - loss 1.61376097 throughput (samples/sec): 8.63\n2019-08-11 19:09:46,288 epoch 20 - iter 40/56 - loss 1.61834053 throughput (samples/sec): 8.37\n2019-08-11 19:10:05,750 epoch 20 - iter 45/56 - loss 1.61691670 throughput (samples/sec): 8.56\n2019-08-11 19:10:24,756 epoch 20 - iter 50/56 - loss 1.61617812 throughput (samples/sec): 8.76\n2019-08-11 19:10:42,098 epoch 20 - iter 55/56 - loss 1.61909637 throughput (samples/sec): 9.49\n2019-08-11 19:10:42,562 ----------------------------------------------------------------------------------------------------\n2019-08-11 19:10:42,563 EPOCH 20 done: loss 1.6191 - lr 0.0063\n2019-08-11 19:11:10,123 DEV : loss 1.6187273263931274 - score 0.2072\n2019-08-11 19:11:12,282 BAD EPOCHS (no improvement): 2\n2019-08-11 19:11:14,974 ----------------------------------------------------------------------------------------------------\n","name":"stdout"},{"output_type":"stream","text":"2019-08-11 19:11:14,976 Testing using best model ...\n2019-08-11 19:11:14,982 loading file model/OPENAIGPT2/best-model.pt\n2019-08-11 19:11:41,432 0.2108\t0.2108\t0.2108\n2019-08-11 19:11:41,433 \nMICRO_AVG: acc 0.1178 - f1-score 0.2108\nMACRO_AVG: acc 0.0422 - f1-score 0.06964000000000001\nbusiness   tp: 47 - fp: 176 - fn: 0 - tn: 0 - precision: 0.2108 - recall: 1.0000 - accuracy: 0.2108 - f1-score: 0.3482\nentertainment tp: 0 - fp: 0 - fn: 41 - tn: 182 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\npolitics   tp: 0 - fp: 0 - fn: 40 - tn: 183 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\nsport      tp: 0 - fp: 0 - fn: 51 - tn: 172 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\ntech       tp: 0 - fp: 0 - fn: 44 - tn: 179 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n2019-08-11 19:11:41,435 ----------------------------------------------------------------------------------------------------\n","name":"stdout"},{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"{'test_score': 0.2108,\n 'dev_score_history': [0.2072,\n  0.2162,\n  0.1622,\n  0.2027,\n  0.2162,\n  0.2072,\n  0.2162,\n  0.2072,\n  0.2072,\n  0.2072,\n  0.2162,\n  0.2162,\n  0.1982,\n  0.2162,\n  0.2072,\n  0.2162,\n  0.2072,\n  0.2162,\n  0.2072,\n  0.2072],\n 'train_loss_history': [2.5277326745646342,\n  2.447187283209392,\n  2.599363299352782,\n  2.5135857484170367,\n  2.4028480734143938,\n  2.293679403407233,\n  1.8981805784361703,\n  1.867765641638211,\n  1.8559127364839827,\n  1.8473975317818778,\n  1.708465344139508,\n  1.691422089934349,\n  1.6866269537380763,\n  1.6974598999534334,\n  1.655424369232995,\n  1.6472091057470866,\n  1.6466106687273299,\n  1.6468752260719026,\n  1.6245791954653603,\n  1.6190963749374663],\n 'dev_loss_history': [tensor(1.9103, device='cuda:0'),\n  tensor(2.5066, device='cuda:0'),\n  tensor(2.1446, device='cuda:0'),\n  tensor(2.3179, device='cuda:0'),\n  tensor(2.0415, device='cuda:0'),\n  tensor(2.5453, device='cuda:0'),\n  tensor(1.9457, device='cuda:0'),\n  tensor(1.8335, device='cuda:0'),\n  tensor(1.7274, device='cuda:0'),\n  tensor(1.7433, device='cuda:0'),\n  tensor(1.6676, device='cuda:0'),\n  tensor(1.6305, device='cuda:0'),\n  tensor(1.6180, device='cuda:0'),\n  tensor(1.6716, device='cuda:0'),\n  tensor(1.6633, device='cuda:0'),\n  tensor(1.6258, device='cuda:0'),\n  tensor(1.6098, device='cuda:0'),\n  tensor(1.6140, device='cuda:0'),\n  tensor(1.6149, device='cuda:0'),\n  tensor(1.6187, device='cuda:0')]}"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Plot training curves"},{"metadata":{"trusted":false},"cell_type":"code","source":"from flair.visual.training_curves import Plotter\n\nplotter = Plotter()\nplotter.plot_training_curves(os.path.join(MODEL_FOLDER_PATH, 'loss.tsv'))\nplotter.plot_weights(os.path.join(MODEL_FOLDER_PATH, 'weights.txt'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}