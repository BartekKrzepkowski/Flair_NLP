{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter optimisation (or tuning) is the process of choosing a set of optimal parameters for a machine learning algorithm.<br>\n",
    "The most typical hyperparameters in deep learning include learning rate, number of hidden layers in a deep neural network, batch size, dropout…<br>\n",
    "But also, in NLP with should bother with parameters like type of embedding, embedding dimension, number of RNN layers…<br>\n",
    "Hyperparameter optimisation, in NLP, require better method than hand-picking, with respect to exponentially growing parameters space.<br>\n",
    "Currently, the dominant algorithms of searching the parameter space for complex models are Bayesian Optimization and Tree-structured Parzen Estimator(TPE).<br>\n",
    "Due to the fact that much more time and resources are required, as it basically performs a lot of training, it is recommended to run this on hardware accelerated by the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/3a/2e777f65a71c1eaa259df44c44e39d7071ba8c7780a1564316a38bf86449/flair-0.4.2-py3-none-any.whl (136kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 8.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sqlitedict>=1.6.0 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /opt/conda/lib/python3.6/site-packages (from flair) (3.0.3)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.6/site-packages/tabulate-0.8.3-py3.6.egg (from flair) (0.8.3)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.20 in /opt/conda/lib/python3.6/site-packages (from flair) (1.24.2)\n",
      "Requirement already satisfied: pytorch-pretrained-bert>=0.6.1 in /opt/conda/lib/python3.6/site-packages (from flair) (0.6.2)\n",
      "Collecting segtok>=1.5.7 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
      "Collecting deprecated>=1.2.4 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/88/0e/9d5a1a8cd7130c49334cce7b8167ceda63d6a329c8ea65b626116bc9e9e6/Deprecated-1.2.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.6/site-packages (from flair) (0.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from flair) (2019.6.8)\n",
      "Collecting bpemb>=0.2.9 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
      "Requirement already satisfied: pytest>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from flair) (5.0.1)\n",
      "Requirement already satisfied: mpld3==0.3 in /opt/conda/lib/python3.6/site-packages (from flair) (0.3)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from flair) (1.1.0)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in /opt/conda/lib/python3.6/site-packages (from flair) (4.32.1)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from flair) (3.8.0)\n",
      "Requirement already satisfied: hyperopt>=0.1.1 in /opt/conda/lib/python3.6/site-packages (from flair) (0.1.2)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (1.16.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (2.8.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from pytorch-pretrained-bert>=0.6.1->flair) (2.22.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from pytorch-pretrained-bert>=0.6.1->flair) (1.9.194)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.6/site-packages (from deprecated>=1.2.4->flair) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from sklearn->flair) (0.21.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (from bpemb>=0.2.9->flair) (0.1.82)\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (1.8.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (19.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (19.1.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (7.0.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (1.3.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (0.17)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (0.1.7)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from gensim>=3.4.0->flair) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from gensim>=3.4.0->flair) (1.8.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.6/site-packages (from gensim>=3.4.0->flair) (1.2.1)\n",
      "Requirement already satisfied: pymongo in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair) (3.8.0)\n",
      "Requirement already satisfied: networkx==2.2 in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair) (2.2)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair) (0.17.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.2.3->flair) (41.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2.8)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.194 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (1.12.194)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn->flair) (0.13.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=0.12->pytest>=3.6.4->flair) (0.5.1)\n",
      "Requirement already satisfied: boto>=2.32 in /opt/conda/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim>=3.4.0->flair) (2.49.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx==2.2->hyperopt>=0.1.1->flair) (4.4.0)\n",
      "Requirement already satisfied: docutils<0.15,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.194->boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.14)\n",
      "Building wheels for collected packages: sqlitedict, segtok\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=fa38cbab40f3a0f5b8b97018b46b4fd61aa30b10681362a3c0f884ecb486087e\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
      "  Building wheel for segtok (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23257 sha256=af8501d27445c6064385fcb23079e40b3531005e76c7615290fc748a9bda7dce\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
      "Successfully built sqlitedict segtok\n",
      "Installing collected packages: sqlitedict, segtok, deprecated, bpemb, flair\n",
      "Successfully installed bpemb-0.3.0 deprecated-1.2.6 flair-0.4.2 segtok-1.5.7 sqlitedict-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ClassificationCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"../input/spam.csv\"\n",
    "DATASET_FOLDER_PATH = \"splitted_data/spam\"\n",
    "MODEL_FOLDER_PATH = \"model\"\n",
    "column_name = {\n",
    "    \"text\": \"v2\",\n",
    "    \"label\": \"v1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAJOCAYAAAAOBIslAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xu4ZWV9J/jvTyqKSuQSTKlALOzQRqO5YKl0zCSFRIMaxeTRVoeO4GDTMzGtdnRiaXzadDr2kOl0jI6Oaby0aGyJokYiJIao1XZm4g1NvGFGojQUEG8gWmpEzG/+2Kv0UJyq2gVnn31e6vN5nvOctd717vX+zn6fXXxZl72quwMAwMZ3h2UXAADAfAQ3AIBBCG4AAIMQ3AAABiG4AQAMQnADABiE4AbsU1VdUVU/Ny2/oKpevYAxtlXVzrXe73qMU1U7qurp0/LpVfXna7jvT1bVtmn5N6vqD9dw3wuZS2CxNi27AGAc3f0fll3DIlXV65Ls7O4X3prXd/cbk7xxrcbp7h+9NXWsMt62JH/Y3ceu2Pftei7h9soRN4ANpqr8TzWwKsENmNvK03VVtaWquqrOqKorq+pLVfUbK/reoaq2V9XfVdWXq+rNVXXUnOPcq6reWlVfrKrPVdUz96jhzVX1+qr62nQ6ceuK7SdW1UenbW+pqj+qqt/eY//PqaovVNW1VfW0qe3sJKcn+fWq2lVVf7KX2h5RVZ+uqhuq6uVJasW2M6vqL6flqqqXTOPcUFUfq6oH7G2c6ZT086rqY0m+XlWbVp6mnhw6/T1fq6qPVNWPrxi7q+qHV6y/rqp+u6rumuRPk9xrGm/X9P7e7NRrVT1uei+/Mp3+vd+KbVdU1XOnv+GGqYZD55lLYG0JbsBt9dNJ7pvklCT/dsV/8J+Z5PFJfjbJvZJcn+QV+9tZVd0hyZ8k+Zskx0z7fXZV/fyKbo9Lcn6SI5JcmOTl02vvmOTtSV6X5Kgkb0ryi3sMcY8kh0/7PivJK6rqyO4+N7PTnP9ndx/W3Y9dpbajk7w1yQuTHJ3k75I8bC9/yiOT/EySfzrV+aQkX97POE9J8pgkR3T3Tavs87Qkb5n+tv+a5I+r6vv2Mn6SpLu/nuRRSa6Zxjusu6/Z4+/6p5m9V89OcvckFyf5k+n93O2fJzk1yfFJfizJmfsaF1gMwQ24rf5dd3+zu/8ms7C1+yjQv0ryG929s7u/leQ3kzxhjtOAD05y9+7+re6+sbs/m+RVSZ68os9fdvfF3f2dJG9YMeZJmV27+7Lu/nZ3vy3JB/fY/7eT/Na0/eIkuzILnvN4dJJPdfcF3f3tJL+f5O/30vfbSb4/yY8kqe6+rLuv3c/+X9bdV3X3N/ey/dIVY/9ekkMz+5tvqycluai7L5n2/btJ7pzkp/ao7Zruvi6zYP0TazAucIBcRwHcViuDyzeSHDYt3zvJ26vqH1ds/06SzUmu3sf+7p3Zab2vrGg7JMl/38eYh06B8F5Jru7uXrH9qj32/+U9jmatrHl/7rVyf93dVbXn/ndve890KvUVSX6oqt6e5Lnd/dV97H/Vfa22vbv/cbpD9l5z1r4v90ryP/bY91WZHZXcbc/3fC3GBQ6QI27AolyV5FHdfcSKn0O7e1+hbffrPrfH676/ux89x5jXJjmmqmpF23EHUHPvZ/u1K/c3jbPX/Xf3y7r7QUl+NLNTpv/7fsbZ3/grx75DkmOT7D7t+Y0kd1nR9x4HsN9rMgvMu/e9++/a31wB60xwAxblD5K8uKrunSRVdfeqOm2O130wyVenC/XvXFWHTBf1P3iO1/5VZkf1fnW6uP+0JA85gJo/n+Q++9h+UZIfrapfmo7wPTM3D0jfVVUPrqqHTtegfT3JP0y1zTPO3jxoxdjPTvKtJO+ftv11kv95er9OzezawpV/1w9U1eF72e+bkzymqk6Z6n3OtO//91bUCCyQ4AYsykszu3Hgz6vqa5kFjIfu70XTdWuPzewaqs8l+VKSV2d2Q8H+Xntjkl/K7KaDryT5F0nemVkImcdrktx/urPyj1fZ/5eSPDHJOUm+nOSEJP/PXvZ1t8yuzbs+s9OQX87s2rH9jrMP78jserTrk/xykl+arklLkmdl9r59JbO7Vr+73+7+dGY3H3x2GvNmpzm7+28ze6/+r8ze78cmeez0fgIbSN38UhCA25eq+kCSP+ju/7LsWgBuK0fcgNuVqvrZqrrHdKr0jMy+uuLPll0XwFpwVylwe3PfzK7ZOiyz71l7whxfwwEwBKdKAQAG4VQpAMAgbpenSo8++ujesmXLQsf4+te/nrve9a4LHYPFMHdjM39jM39jM3+Lcemll36pu+8+T9/bZXDbsmVLPvzhDy90jB07dmTbtm0LHYPFMHdjM39jM39jM3+LUVX/Y/+9ZpwqBQAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCAENwCAQQhuAACDENwAAAYhuAEADGLTsgs4GGzZftFc/a445zELrgQAGJkjbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCAENwCAQQhuAACDENwAAAYhuAEADEJwAwAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIMQ3AAABrGw4FZVr62qL1TVJ1bZ9tyq6qo6elqvqnpZVV1eVR+rqhNX9D2jqj4z/ZyxqHoBADa6RR5xe12SU/dsrKrjkjwiyZUrmh+V5ITp5+wkr5z6HpXkRUkemuQhSV5UVUcusGYAgA1rYcGtu9+X5LpVNr0kya8n6RVtpyV5fc+8P8kRVXXPJD+f5JLuvq67r09ySVYJgwAAB4NN6zlYVT0uydXd/TdVtXLTMUmuWrG+c2rbW/tq+z47s6N12bx5c3bs2LF2ha9i165dc4/xnAfeNFe/RdfMzIHMHRuP+Rub+Rub+Vu+dQtuVXWXJL+R5JGrbV6lrffRfsvG7nOTnJskW7du7W3btt26Que0Y8eOzDvGmdsvmqvfFafPtz9umwOZOzYe8zc28zc287d863lX6T9JcnySv6mqK5Icm+QjVXWPzI6kHbei77FJrtlHOwDAQWfdglt3f7y7f7C7t3T3lsxC2Ynd/fdJLkzy1Onu0pOS3NDd1yZ5V5JHVtWR000Jj5zaAAAOOov8OpA3JfmrJPetqp1VddY+ul+c5LNJLk/yqiS/kiTdfV2Sf5/kQ9PPb01tAAAHnYVd49bdT9nP9i0rljvJM/bS77VJXrumxQEADMiTEwAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCAENwCAQQhuAACDENwAAAYhuAEADEJwAwAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCAENwCAQQhuAACDENwAAAYhuAEADEJwAwAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCAWFtyq6rVV9YWq+sSKtv9YVZ+uqo9V1dur6ogV255fVZdX1d9W1c+vaD91aru8qrYvql4AgI1ukUfcXpfk1D3aLknygO7+sST/X5LnJ0lV3T/Jk5P86PSa/7uqDqmqQ5K8Ismjktw/yVOmvgAAB52FBbfufl+S6/Zo+/PuvmlafX+SY6fl05Kc393f6u7PJbk8yUOmn8u7+7PdfWOS86e+AAAHnU1LHPt/SfJH0/IxmQW53XZObUly1R7tD11tZ1V1dpKzk2Tz5s3ZsWPHWtZ6C7t27Zp7jOc88Kb9d0oWXjMzBzJ3bDzmb2zmb2zmb/mWEtyq6jeS3JTkjbubVunWWf2IYK+2z+4+N8m5SbJ169betm3bbS90H3bs2JF5xzhz+0Vz9bvi9Pn2x21zIHPHxmP+xmb+xmb+lm/dg1tVnZHkF5Kc0t27Q9jOJMet6HZskmum5b21AwAcVNb160Cq6tQkz0vyuO7+xopNFyZ5clXdqaqOT3JCkg8m+VCSE6rq+Kq6Y2Y3MFy4njUDAGwUCzviVlVvSrItydFVtTPJizK7i/ROSS6pqiR5f3f/r939yap6c5JPZXYK9Rnd/Z1pP7+a5F1JDkny2u7+5KJqBgDYyBYW3Lr7Kas0v2Yf/V+c5MWrtF+c5OI1LA0AYEienAAAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCAENwCAQQhuAACDENwAAAYhuAEADEJwAwAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCAENwCAQQhuAACDENwAAAYhuAEADEJwAwAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCAENwCAQQhuAACDENwAAAaxsOBWVa+tqi9U1SdWtB1VVZdU1Wem30dO7VVVL6uqy6vqY1V14orXnDH1/0xVnbGoegEANrpNC9z365K8PMnrV7RtT/Lu7j6nqrZP689L8qgkJ0w/D03yyiQPraqjkrwoydYkneTSqrqwu69fYN1Ls2X7RXP1u+Kcxyy4EgBgI1rYEbfufl+S6/ZoPi3JedPyeUkev6L99T3z/iRHVNU9k/x8kku6+7oprF2S5NRF1QwAsJEt8ojbajZ397VJ0t3XVtUPTu3HJLlqRb+dU9ve2m+hqs5OcnaSbN68OTt27Fjbyvewa9euucd4zgNvWtOxF/233d4dyNyx8Zi/sZm/sZm/5Vvv4LY3tUpb76P9lo3d5yY5N0m2bt3a27ZtW7PiVrNjx47MO8aZc54CndcVp883Lqs7kLlj4zF/YzN/YzN/y7fed5V+fjoFmun3F6b2nUmOW9Hv2CTX7KMdAOCgs97B7cIku+8MPSPJO1a0P3W6u/SkJDdMp1TfleSRVXXkdAfqI6c2AICDzsJOlVbVm5JsS3J0Ve3M7O7Qc5K8uarOSnJlkidO3S9O8ugklyf5RpKnJUl3X1dV/z7Jh6Z+v9Xde97wAABwUFhYcOvup+xl0ymr9O0kz9jLfl6b5LVrWBoAwJA8OQEAYBCCGwDAIAQ3AIBBCG4AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCAENwCAQQhuAACDENwAAAYhuAEADEJwAwAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCAENwCAQQhuAACDENwAAAYhuAEADEJwAwAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIOYK7hV1QMWXQgAAPs27xG3P6iqD1bVr1TVEQutCACAVc0V3Lr7p5OcnuS4JB+uqv9aVY9YaGUAANzM3Ne4dfdnkrwwyfOS/GySl1XVp6vqlxZVHAAA3zPvNW4/VlUvSXJZkocneWx3329afskC6wMAYLJpzn4vT/KqJC/o7m/ubuzua6rqhQupDACAm5k3uD06yTe7+ztJUlV3SHJod3+ju9+wsOoAAPiuea9x+4skd16xfpepDQCAdTJvcDu0u3ftXpmW77KYkgAAWM28we3rVXXi7pWqelCSb+6jPwAAa2zea9yeneQtVXXNtH7PJE+6tYNW1b9J8vQkneTjSZ427fP8JEcl+UiSX+7uG6vqTklen+RBSb6c5EndfcWtHRsAYFTzfgHvh5L8SJL/LcmvJLlfd196awasqmOSPDPJ1u5+QJJDkjw5ye8keUl3n5Dk+iRnTS85K8n13f3DmX31yO/cmnEBAEZ3IA+Zf3CSH0vyk0meUlVPvQ3jbkpy56ralNm1ctdm9p1wF0zbz0vy+Gn5tGk90/ZTqqpuw9gAAEOq7t5/p6o3JPknSf46yXem5u7uZ96qQaueleTFmV0n9+dJnpXk/dNRtVTVcUn+tLsfUFWfSHJqd++ctv1dkod295f22OfZSc5Oks2bNz/o/PPPvzWlzW3Xrl057LDD5ur78atvWNOxH3jM4Wu6v4PNgcwdG4/5G5v5G5v5W4yTTz750u7eOk/fea9x25rk/j1PytuPqjoys6Noxyf5SpK3JHnUKl13j7Xa0bVb1NHd5yY5N0m2bt3a27Ztu62l7tOOHTsy7xhnbr9oTce+4vT5xmV1BzJ3bDzmb2zmb2zmb/nmPVX6iST3WKMxfy7J57r7i9397SRvS/JTSY6YTp0mybFJdt8IsTOzh9tn2n54kuvWqBYAgGHMe8Tt6CSfqqoPJvnW7sbuftytGPPKJCdV1V0yO1V6SpIPJ3lvkidkdmfpGUneMfW/cFr/q2n7e9biyB8AwGjmDW6/uVYDdvcHquqCzL7y46YkH83sFOdFSc6vqt+e2l4zveQ1Sd5QVZdndqTtyWtVCwDASOYKbt3936rq3klO6O6/mI6WHXJrB+3uFyV50R7Nn03ykFX6/kOSJ97asQAAbi/musatqv5lZl/F8Z+npmOS/PGiigIA4JbmvTnhGUkeluSrSdLdn0nyg4sqCgCAW5o3uH2ru2/cvTLd3ekGAQCAdTRvcPtvVfWCzJ528IjMvnvtTxZXFgAAe5o3uG1P8sXMHgj/r5JcnOSFiyoKAIBbmveu0n9M8qrpBwCAJZgruFXV57L6Y6bus+YVAQCwqgN5Vuluh2b2vWpHrX05AADszVzXuHX3l1f8XN3dv5/k4QuuDQCAFeY9VXriitU7ZHYE7vsXUhEAAKua91Tpf1qxfFOSK5L88zWvBgCAvZr3rtKTF10IAAD7Nu+p0l/b1/bu/r21KQcAgL05kLtKH5zkwmn9sUnel+SqRRQFAMAtzRvcjk5yYnd/LUmq6jeTvKW7n76owgAAuLl5H3n1Q0luXLF+Y5Ita14NAAB7Ne8Rtzck+WBVvT2zJyj8YpLXL6wqAABuYd67Sl9cVX+a5H+amp7W3R9dXFkAAOxp3lOlSXKXJF/t7pcm2VlVxy+oJgAAVjFXcKuqFyV5XpLnT03fl+QPF1UUAAC3NO8Rt19M8rgkX0+S7r4mHnkFALCu5g1uN3Z3Z3ZjQqrqrosrCQCA1cwb3N5cVf85yRFV9S+T/EWSVy2uLAAA9jTvXaW/W1WPSPLVJPdN8m+7+5KFVgYAwM3sN7hV1SFJ3tXdP5dEWAMAWJL9nirt7u8k+UZVHb4O9QAAsBfzPjnhH5J8vKouyXRnaZJ09zMXUhUAALcwb3C7aPoBAGBJ9hncquqHuvvK7j5vvQoCAGB1+7vG7Y93L1TVWxdcCwAA+7C/4FYrlu+zyEIAANi3/QW33ssyAADrbH83J/x4VX01syNvd56WM613d99todUBAPBd+wxu3X3IehUCAMC+zfusUgAAlkxwAwAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEFsWnYBHNy2bL9orn5XnPOYBVcCABufI24AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAG4ZFXA/KYKAA4ODniBgAwiKUEt6o6oqouqKpPV9VlVfXPquqoqrqkqj4z/T5y6ltV9bKquryqPlZVJy6jZgCAZVvWEbeXJvmz7v6RJD+e5LIk25O8u7tPSPLuaT1JHpXkhOnn7CSvXP9yAQCWb92DW1XdLcnPJHlNknT3jd39lSSnJTlv6nZeksdPy6cleX3PvD/JEVV1z3UuGwBg6aq713fAqp9Icm6ST2V2tO3SJM9KcnV3H7Gi3/XdfWRVvTPJOd39l1P7u5M8r7s/vMd+z87siFw2b978oPPPP3+hf8euXbty2GGHzdX341ffsNBa9uaBxxy+lHEPxLzvzVr+LQcyd2w85m9s5m9s5m8xTj755Eu7e+s8fZdxV+mmJCcm+dfd/YGqemm+d1p0NbVK2y3SZnefm1kgzNatW3vbtm1rUOre7dixI/OOceacd4GutStO37aUcQ/EvO/NWv4tBzJ3bDzmb2zmb2zmb/mWcY3bziQ7u/sD0/oFmQW5z+8+BTr9/sKK/seteP2xSa5Zp1oBADaMdQ9u3f33Sa6qqvtOTadkdtr0wiRnTG1nJHnHtHxhkqdOd5eelOSG7r52PWsGANgIlvUFvP86yRur6o5JPpvkaZmFyDdX1VlJrkzyxKnvxUkeneTyJN+Y+gIAHHSWEty6+6+TrHYR3imr9O0kz1h4UQAAG5wnJwAADEJwAwAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCAENwCAQQhuAACDENwAAAYhuAEADEJwAwAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCAENwCAQQhuAACDENwAAAaxadkFsDhbtl80d98rznnMAisBANaCI24AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwiKUFt6o6pKo+WlXvnNaPr6oPVNVnquqPquqOU/udpvXLp+1bllUzAMAyLfOI27OSXLZi/XeSvKS7T0hyfZKzpvazklzf3T+c5CVTPwCAg85SgltVHZvkMUlePa1XkocnuWDqcl6Sx0/Lp03rmbafMvUHADioVHev/6BVFyT5P5J8f5LnJjkzyfuno2qpquOS/Gl3P6CqPpHk1O7eOW37uyQP7e4v7bHPs5OcnSSbN29+0Pnnn7/Qv2HXrl057LDD5ur78atvWGgta+GBxxy+lHHnfW/Wsr4DmTs2HvM3NvM3NvO3GCeffPKl3b11nr6bFl3MnqrqF5J8obsvraptu5tX6dpzbPteQ/e5Sc5Nkq1bt/a2bdv27LKmduzYkXnHOHP7RQutZS1ccfq2pYw773uzlvUdyNyx8Zi/sZm/sZm/5Vv34JbkYUkeV1WPTnJokrsl+f0kR1TVpu6+KcmxSa6Z+u9MclySnVW1KcnhSa5b/7I5EFsGCKsAMJp1v8atu5/f3cd295YkT07ynu4+Pcl7kzxh6nZGkndMyxdO65m2v6eXcX4XAGDJNtL3uD0vya9V1eVJfiDJa6b21yT5gan915JsX1J9AABLtYxTpd/V3TuS7JiWP5vkIav0+YckT1zXwgAANqCNdMQNAIB9ENwAAAYhuAEADEJwAwAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCA2LbsAxrJl+0XLLgEADlqOuAEADEJwAwAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIPwPW4k8f1sADACR9wAAAYhuAEADEJwAwAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCAENwCAQQhuAACDENwAAAYhuAEADEJwAwAYhOAGADAIwQ0AYBCCGwDAINY9uFXVcVX13qq6rKo+WVXPmtqPqqpLquoz0+8jp/aqqpdV1eVV9bGqOnG9awYA2AiWccTtpiTP6e77JTkpyTOq6v5Jtid5d3efkOTd03qSPCrJCdPP2Uleuf4lAwAs37oHt+6+trs/Mi1/LcllSY5JclqS86Zu5yV5/LR8WpLX98z7kxxRVfdc57IBAJauunt5g1dtSfK+JA9IcmV3H7Fi2/XdfWRVvTPJOd39l1P7u5M8r7s/vMe+zs7siFw2b978oPPPP3+hte/atSuHHXbYXH0/fvUNC63lYPDAYw5fs30dyNyx8Zi/sZm/sZm/xTj55JMv7e6t8/TdtOhi9qaqDkvy1iTP7u6vVtVeu67Sdou02d3nJjk3SbZu3drbtm1bo0pXt2PHjsw7xpnbL1poLQeDK07ftmb7OpC5Y+Mxf2Mzf2Mzf8u3lLtKq+r7Mgttb+zut03Nn999CnT6/YWpfWeS41a8/Ngk16xXrQAAG8Uy7iqtJK9Jcll3/96KTRcmOWNaPiPJO1a0P3W6u/SkJDd097XrVjAAwAaxjFOlD0vyy0k+XlV/PbW9IMk5Sd5cVWcluTLJE6dtFyd5dJLLk3wjydPWt1wAgI1h3YPbdJPB3i5oO2WV/p3kGQstCgBgAJ6cAAAwCMENAGAQghsAwCAENwCAQQhuAACDENwAAAaxtEde3R5s8SgrAGAdOeIGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMC2meZMAAAGPUlEQVQgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCAENwCAQQhuAACDENwAAAYhuAEADEJwAwAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBBCG4AAIMQ3AAABiG4AQAMYtOyC4B5bNl+0Vz9rjjnMQuuBACWxxE3AIBBCG4AAIMQ3AAABiG4AQAMQnADABiE4AYAMAjBDQBgEIIbAMAgBDcAgEEIbgAAgxDcAAAGIbgBAAxCcAMAGITgBgAwCMENAGAQghsAwCA2LbsAWEtbtl+03z7PeeBN2bb4UgBgzTniBgAwCMENAGAQTpXCfsxz+jVJrjjnMQuuBICDneDGQWneMLZMAiMAe3KqFABgEI64wRpxhAyARRsmuFXVqUlemuSQJK/u7nOWXBLcKmt9mlZgBDh4DBHcquqQJK9I8ogkO5N8qKou7O5PLbcyGMciruubNwxu9HC50esD2G2I4JbkIUku7+7PJklVnZ/ktCSCGyzRMo4ePueBN+XMJd1csszwu9HN+94sYv5uL+/hMs07f6879a4LrmT9jPo/bNXdy65hv6rqCUlO7e6nT+u/nOSh3f2rK/qcneTsafW+Sf52wWUdneRLCx6DxTB3YzN/YzN/YzN/i3Hv7r77PB1HOeJWq7TdLHF297lJzl2fcpKq+nB3b12v8Vg75m5s5m9s5m9s5m/5Rvk6kJ1JjluxfmySa5ZUCwDAUowS3D6U5ISqOr6q7pjkyUkuXHJNAADraohTpd19U1X9apJ3ZfZ1IK/t7k8uuax1Oy3LmjN3YzN/YzN/YzN/SzbEzQkAAIxzqhQA4KAnuAEADEJwO0BVdWpV/W1VXV5V25ddD7dUVcdV1Xur6rKq+mRVPWtqP6qqLqmqz0y/j5zaq6peNs3px6rqxOX+BVTVIVX10ap657R+fFV9YJq7P5puUkpV3Wlav3zavmWZdZNU1RFVdUFVfXr6DP4zn71xVNW/mf7d/ERVvamqDvX521gEtwOw4tFbj0py/yRPqar7L7cqVnFTkud09/2SnJTkGdM8bU/y7u4+Icm7p/VkNp8nTD9nJ3nl+pfMHp6V5LIV67+T5CXT3F2f5Kyp/awk13f3Dyd5ydSP5Xppkj/r7h9J8uOZzaPP3gCq6pgkz0yytbsfkNnNgE+Oz9+GIrgdmO8+equ7b0yy+9FbbCDdfW13f2Ra/lpm/+E4JrO5Om/qdl6Sx0/LpyV5fc+8P8kRVXXPdS6bSVUdm+QxSV49rVeShye5YOqy59ztntMLkpwy9WcJqupuSX4myWuSpLtv7O6vxGdvJJuS3LmqNiW5S5Jr4/O3oQhuB+aYJFetWN85tbFBTYfufzLJB5Js7u5rk1m4S/KDUzfzurH8fpJfT/KP0/oPJPlKd980ra+cn+/O3bT9hqk/y3GfJF9M8l+mU92vrqq7xmdvCN19dZLfTXJlZoHthiSXxudvQxHcDsx+H73FxlFVhyV5a5Jnd/dX99V1lTbzugRV9QtJvtDdl65sXqVrz7GN9bcpyYlJXtndP5nk6/neadHVmL8NZLr28LQkxye5V5K7ZnY6e08+f0skuB0Yj94aRFV9X2ah7Y3d/bap+fO7T8NMv78wtZvXjeNhSR5XVVdkdinCwzM7AnfEdOomufn8fHfupu2HJ7luPQvmZnYm2dndH5jWL8gsyPnsjeHnknyuu7/Y3d9O8rYkPxWfvw1FcDswHr01gOkai9ckuay7f2/FpguTnDEtn5HkHSvanzrd4XZSkht2n9ZhfXX387v72O7ektnn6z3dfXqS9yZ5wtRtz7nbPadPmPr7P/4l6e6/T3JVVd13ajolyafiszeKK5OcVFV3mf4d3T1/Pn8biCcnHKCqenRmRwB2P3rrxUsuiT1U1U8n+e9JPp7vXSf1gsyuc3tzkh/K7B+oJ3b3ddM/UC9PcmqSbyR5Wnd/eN0L52aqaluS53b3L1TVfTI7AndUko8m+Rfd/a2qOjTJGzK7jvG6JE/u7s8uq2aSqvqJzG4suWOSzyZ5WmYHCXz2BlBV/y7JkzK7O/+jSZ6e2bVsPn8bhOAGADAIp0oBAAYhuAEADEJwAwAYhOAGADAIwQ0AYBCCGwDAIAQ3AIBB/P8LEdXP9RxSFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = pd.read_csv(FILE_PATH, encoding=\"latin\").sample(frac=1)\n",
    "data_df[column_name[\"label\"]] = '__label__' + data_df[column_name[\"label\"]].astype(str)\n",
    "\n",
    "# number of chars\n",
    "data_df[column_name[\"text\"]].str.len().plot(kind=\"hist\", title=\"line lenght distribution\", grid=True, figsize=(10,10), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAJOCAYAAADyEaDvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X20ZWddJ/jvjwRIoDABwTIkkQptpEXSIpTADNreAl9C0hBwRGEYTRQ79hocZRl7KNSlaGtP7DaijAwaRAmIFm8ikUC3GC0ZZgYxwUCCgSZACXkxaSAkFMRAwm/+OLv0prhV9yS5596n7v181jrrnrP3Ps/+PWefe+73PvvlVHcHAIAx3GejCwAA4J8JZwAAAxHOAAAGIpwBAAxEOAMAGIhwBgAwEOEMSJJU1b6q+s7p/s9U1e8uYB1LVXXtWre7Huupqr1V9aPT/edV1Z+tYdsfrKql6f5LquoP1rDthWxLYHGO3ugCgPF093/c6BoWqapeneTa7v65e/L87n5dktet1Xq6+5vuSR0rrG8pyR9090nL2t7U2xI2IyNnABukqvyDDHwF4Qz4Cst3rVXVjqrqqjq7qj5RVZ+qqp9dtux9qmp3VX20qj5dVW+oqofMuZ6HV9Wbq+q/V9XHq+onDqrhDVX1mqr63LTrb+ey+Y+rqr+d5r2xql5fVb98UPvnVdVNVXVDVf3wNO3cJM9L8r9X1f6q+tND1PZdVfWhqrqlqn4rSS2bd05VvXu6X1X10mk9t1TVB6rqMYdaz7T7+EVV9YEkn6+qo5fvUp4cM/Xnc1X1vqr65mXr7qr6+mWPX11Vv1xVD0zyjiQPn9a3f3p977KbtKqeMb2Wn5121X7jsnn7quqnpz7cMtVwzDzbElg7whkwr29L8qgkT03y88v+qP9Ekmcm+Y4kD09yc5KXr9ZYVd0nyZ8meX+SE6d2X1hV37NssWck2ZPk+CQXJ/mt6bn3S/KWJK9O8pAkf5TkWQet4muTHDe1/fwkL6+qB3f3hZntkvxP3b2tu5++Qm0PTfLmJD+X5KFJPprkyYfoyncn+ddJvmGq8weSfHqV9Tw3yZlJju/uO1Zo86wkb5z69odJ/qSq7nuI9SdJuvvzSZ6W5Pppfdu6+/qD+vUNmb1WL0zysCRvT/Kn0+t5wPcnOT3JKUn+VZJzDrdeYO0JZ8C8frG7b+vu92cWqA6M5vxYkp/t7mu7+/YkL0nyfXPssvvWJA/r7l/q7i9298eSvDLJc5Yt8+7ufnt335nktcvW+aTMjpl9WXd/qbv/OMl7D2r/S0l+aZr/9iT7MwuX8zgjyd9195u6+0tJfiPJPxxi2S8leVCSf5mkuvvq7r5hlfZf1t2f7O7bDjH/8mXr/vUkx2TW53vrB5Jc0t3vnNr+tSTHJvkfD6rt+u7+TGbh+bFrsF7gbnC8AzCv5eHkC0m2TfcfkeQtVfXlZfPvTLI9yXWHae8Rme2C++yyaUcl+b8Ps85jptD38CTXdXcvm//Jg9r/9EGjUstrXs3Dl7fX3V1VB7d/YN5fTLs9X57k66rqLUl+urtvPUz7K7a10vzu/vJ05unD56z9cB6e5O8PavuTmY0uHnDwa74W6wXuBiNnwL31ySRP6+7jl92O6e7DBbMDz/v4Qc97UHefMcc6b0hyYlXVsmkn342ae5X5Nyxvb1rPIdvv7pd19+OTfFNmuzf//SrrWW39y9d9nyQnJTmwi/ILSR6wbNmvvRvtXp9ZKD7Q9oF+rbatgHUknAH31m8n+ZWqekSSVNXDquqsOZ733iS3TgfHH1tVR00H0n/rHM/9/zIbnfvx6YD6s5I84W7UfGOSRx5m/iVJvqmqvncaqfuJ3DUE/ZOq+taqeuJ0TNjnk/zjVNs86zmUxy9b9wuT3J7kPdO8K5L8z9PrdXpmx/ot79dXV9Vxh2j3DUnOrKqnTvWeN7X9/96DGoEFEc6Ae+s3MztY/8+q6nOZhYgnrvak6Tiyp2d2TNPHk3wqye9mdhD/as/9YpLvzexA/88m+V+SvC2zoDGPVyV59HTG4p+s0P6nkjw7yflJPp3k1CT/zyHa+qrMjpW7ObNdhp/O7FiuVddzGG/N7Piwm5P8YJLvnY4RS5KfzOx1+2xmZ4P+U7vd/aHMDvj/2LTOu+yS7O4PZ/Za/Z+Zvd5PT/L06fUEBlF3PWQD4MhUVX+d5Le7+/c3uhaAe8PIGXBEqqrvqKqvnXZrnp3ZZR/+y0bXBXBvOVsTOFI9KrNjqLZldh2y75vjEhYAw7NbEwBgIHZrAgAM5IjerfnQhz60d+zYsWbtff7zn88DH/jANWvvSLPV+594DfRf//Vf/7eq9ej/5Zdf/qnufthqyx3R4WzHjh257LLL1qy9vXv3Zmlpac3aO9Js9f4nXgP913/9X9roMjaM/i++/1X196svZbcmAMBQhDMAgIEIZwAAAxHOAAAGIpwBAAxEOAMAGIhwBgAwEOEMAGAgwhkAwECEMwCAgQhnAAADEc4AAAYinAEADEQ4AwAYiHAGADAQ4QwAYCDCGQDAQIQzAICBCGcAAAMRzgAABrLwcFZVR1XV31bV26bHp1TVX1fVR6rq9VV1v2n6/afH10zzdyy6NgCA0azHyNlPJrl62eNfTfLS7j41yc1Jnj9Nf36Sm7v765O8dFoOAGBLWWg4q6qTkpyZ5Henx5XkKUneNC1yUZJnTvfPmh5nmv/UaXkAgC2juntxjVe9Kcn/keRBSX46yTlJ3jONjqWqTk7yju5+TFVdleT07r52mvfRJE/s7k8d1Oa5Sc5Nku3btz9+z549a1bv/v37s23btjVr70iz1fufeA30X//1X/+3qvXo/65duy7v7p2rLXf0ogqoqn+T5Kbuvryqlg5MXmHRnmPeP0/ovjDJhUmyc+fOXlpaOniRe2zv3r1Zy/ZGs2P3JYedf95pd+aCd38++84/c50qGs9mfw+sRv/1X/+XNrqMDaP/4/R/YeEsyZOTPKOqzkhyTJKvSvIbSY6vqqO7+44kJyW5flr+2iQnJ7m2qo5OclySzyywPgCA4SzsmLPufnF3n9TdO5I8J8lfdPfzkvxlku+bFjs7yVun+xdPjzPN/4te5D5XAIABbcR1zl6U5Keq6pokX53kVdP0VyX56mn6TyXZvQG1AQBsqEXu1vwn3b03yd7p/seSPGGFZf4xybPXox4AgFH5hgAAgIEIZwAAAxHOAAAGIpwBAAxEOAMAGIhwBgAwEOEMAGAgwhkAwECEMwCAgQhnAAADEc4AAAYinAEADEQ4AwAYiHAGADAQ4QwAYCDCGQDAQIQzAICBCGcAAAMRzgAABiKcAQAMRDgDABiIcAYAMBDhDABgIMIZAMBAhDMAgIEIZwAAAxHOAAAGIpwBAAxEOAMAGIhwBgAwEOEMAGAgwhkAwECEMwCAgQhnAAADEc4AAAYinAEADEQ4AwAYiHAGADAQ4QwAYCDCGQDAQIQzAICBCGcAAAMRzgAABiKcAQAMRDgDABiIcAYAMBDhDABgIMIZAMBAhDMAgIEIZwAAAxHOAAAGIpwBAAxEOAMAGIhwBgAwEOEMAGAgwhkAwEAWFs6q6piqem9Vvb+qPlhVvzhNf3VVfbyqrphuj52mV1W9rKquqaoPVNXjFlUbAMCojl5g27cneUp376+q+yZ5d1W9Y5r377v7TQct/7Qkp063JyZ5xfQTAGDLWNjIWc/snx7ed7r1YZ5yVpLXTM97T5Ljq+qERdUHADCi6j5cXrqXjVcdleTyJF+f5OXd/aKqenWS/yGzkbVLk+zu7tur6m1Jzu/ud0/PvTTJi7r7soPaPDfJuUmyffv2x+/Zs2fN6t2/f3+2bdu2Zu2N5srrbjns/O3HJjfelpx24nHrVNF4Nvt7YDX6r//6r/9b1Xr0f9euXZd3987Vllvkbs10951JHltVxyd5S1U9JsmLk/xDkvsluTDJi5L8UpJaqYkV2rxwel527tzZS0tLa1bv3r17s5btjeac3Zccdv55p92RC648Ovuet7Q+BQ1os78HVqP/+q//SxtdxobR/3H6vy5na3b3Z5PsTXJ6d98w7bq8PcnvJ3nCtNi1SU5e9rSTkly/HvUBAIxikWdrPmwaMUtVHZvkO5N86MBxZFVVSZ6Z5KrpKRcn+aHprM0nJbmlu29YVH0AACNa5G7NE5JcNB13dp8kb+jut1XVX1TVwzLbjXlFkn83Lf/2JGckuSbJF5L88AJrAwAY0sLCWXd/IMm3rDD9KYdYvpO8YFH1AAAcCXxDAADAQIQzAICBCGcAAAMRzgAABiKcAQAMRDgDABiIcAYAMBDhDABgIMIZAMBAhDMAgIEIZwAAAxHOAAAGIpwBAAxEOAMAGIhwBgAwEOEMAGAgwhkAwECEMwCAgQhnAAADEc4AAAZy9EYXwHh27L5k7mX3nX/mAisBgK3HyBkAwECMnHGvzDvKZoQNAOZj5AwAYCDCGQDAQIQzAICBCGcAAAMRzgAABiKcAQAMRDgDABiIcAYAMBDhDABgIMIZAMBAhDMAgIEIZwAAAxHOAAAGIpwBAAxEOAMAGIhwBgAwEOEMAGAgwhkAwECEMwCAgQhnAAADEc4AAAYinAEADEQ4AwAYiHAGADAQ4QwAYCDCGQDAQIQzAICBCGcAAAMRzgAABiKcAQAMRDgDABiIcAYAMJCjN7oAtoYduy+Za7l955+54EoAYGwLGzmrqmOq6r1V9f6q+mBV/eI0/ZSq+uuq+khVvb6q7jdNv//0+Jpp/o5F1QYAMKpF7ta8PclTuvubkzw2yelV9aQkv5rkpd19apKbkzx/Wv75SW7u7q9P8tJpOQCALWVh4axn9k8P7zvdOslTkrxpmn5RkmdO98+aHmea/9SqqkXVBwAwouruxTVedVSSy5N8fZKXJ/nPSd4zjY6lqk5O8o7ufkxVXZXk9O6+dpr30SRP7O5PHdTmuUnOTZLt27c/fs+ePWtW7/79+7Nt27Y1a280V153y2Hnbz82ufG2dSrmEE478bgNXf9mfw+sRv/1X//1f6taj/7v2rXr8u7eudpyCz0hoLvvTPLYqjo+yVuSfONKi00/Vxol+4rk2N0XJrkwSXbu3NlLS0trU2ySvXv3Zi3bG805qxyUf95pd+SCKzf2HJF9z1va0PVv9vfAavRf//V/aaPL2DD6P07/1+VSGt392SR7kzwpyfFVdSABnJTk+un+tUlOTpJp/nFJPrMe9QEAjGKRZ2s+bBoxS1Udm+Q7k1yd5C+TfN+02NlJ3jrdv3h6nGn+X/Qi97kCAAxokfuwTkhy0XTc2X2SvKG731ZVf5dkT1X9cpK/TfKqaflXJXltVV2T2YjZcxZYGwDAkBYWzrr7A0m+ZYXpH0vyhBWm/2OSZy+qHgCAI4GvbwIAGIhwBgAwEOEMAGAgwhkAwECEMwCAgQhnAAADEc4AAAYinAEADEQ4AwAYiHAGADAQ4QwAYCDCGQDAQIQzAICBCGcAAAMRzgAABiKcAQAMRDgDABiIcAYAMBDhDABgIEdvdAGw3I7dl8y13L7zz1xwJQCwMYycAQAMRDgDABiIcAYAMBDhDABgIMIZAMBAhDMAgIEIZwAAAxHOAAAGIpwBAAxEOAMAGIhwBgAwEOEMAGAgwhkAwECEMwCAgQhnAAADEc4AAAYinAEADEQ4AwAYiHAGADAQ4QwAYCDCGQDAQIQzAICBCGcAAAMRzgAABiKcAQAMRDgDABiIcAYAMBDhDABgIMIZAMBAhDMAgIEIZwAAAxHOAAAGIpwBAAxEOAMAGIhwBgAwkIWFs6o6uar+sqqurqoPVtVPTtNfUlXXVdUV0+2MZc95cVVdU1UfrqrvWVRtAACjOnqBbd+R5Lzufl9VPSjJ5VX1zmneS7v715YvXFWPTvKcJN+U5OFJ/ryqvqG771xgjQAAQ1nYyFl339Dd75vufy7J1UlOPMxTzkqyp7tv7+6PJ7kmyRMWVR8AwIiquxe/kqodSd6V5DFJfirJOUluTXJZZqNrN1fVbyV5T3f/wfScVyV5R3e/6aC2zk1ybpJs37798Xv27FmzOvfv359t27atWXujufK6Ww47f/uxyY23rVMx99JpJx63kHY3+3tgNfqv//qv/1vVevR/165dl3f3ztWWW+RuzSRJVW1L8uYkL+zuW6vqFUn+Q5Kefl6Q5EeS1ApP/4rk2N0XJrkwSXbu3NlLS0trVuvevXuzlu2N5pzdlxx2/nmn3ZELrlz4W2JN7Hve0kLa3ezvgdXov/7r/9JGl7Fh9H+c/i/0bM2qum9mwex13f3HSdLdN3b3nd395SSvzD/vurw2ycnLnn5SkusXWR8AwGgWebZmJXlVkqu7+9eXTT9h2WLPSnLVdP/iJM+pqvtX1SlJTk3y3kXVBwAwokXuw3pykh9McmVVXTFN+5kkz62qx2a2y3Jfkh9Lku7+YFW9IcnfZXam5wucqQkAbDULC2fd/e6sfBzZ2w/znF9J8iuLqgkAYHS+IQAAYCDCGQDAQIQzAICBCGcAAAMRzgAABiKcAQAMRDgDABjIkfFFinCQHat8T+gB+84/c8GVAMDaMnIGADAQ4QwAYCDCGQDAQIQzAICBCGcAAAMRzgAABiKcAQAMxHXO2NRcDw2AI42RMwCAgQhnAAADEc4AAAYinAEADEQ4AwAYiHAGADAQ4QwAYCBzhbOqesyiCwEAYP6Rs9+uqvdW1f9aVccvtCIAgC1srnDW3d+W5HlJTk5yWVX9YVV910IrAwDYguY+5qy7P5Lk55K8KMl3JHlZVX2oqr53UcUBAGw18x5z9q+q6qVJrk7ylCRP7+5vnO6/dIH1AQBsKfN+8flvJXllkp/p7tsOTOzu66vq5xZSGQAcQXbsvmSu5fadf+aCK+FIN284OyPJbd19Z5JU1X2SHNPdX+ju1y6sOgCALWbeY87+PMmxyx4/YJoGAMAamjecHdPd+w88mO4/YDElAQBsXfOGs89X1eMOPKiqxye57TDLAwBwD8x7zNkLk7yxqq6fHp+Q5AcWUxIAwNY1Vzjr7r+pqn+Z5FFJKsmHuvtLC60MAGALmnfkLEm+NcmO6TnfUlXp7tcspCoAgC1qrnBWVa9N8i+SXJHkzmlyJxHOAADW0LwjZzuTPLq7e5HFAABsdfOerXlVkq9dZCEAAMw/cvbQJH9XVe9NcvuBid39jIVUBQCwRc0bzl6yyCIAAJiZ91Iaf1VVj0hyanf/eVU9IMlRiy0NAGDrmeuYs6r6t0nelOR3pkknJvmTRRUFALBVzXtCwAuSPDnJrUnS3R9J8jWLKgoAYKuaN5zd3t1fPPCgqo7O7DpnAACsoXnD2V9V1c8kObaqvivJG5P86eLKAgDYmuYNZ7uT/PckVyb5sSRvT/JziyoKAGCrmvdszS8neeV0AwBgQeb9bs2PZ4VjzLr7kWteEQDAFnZ3vlvzgGOSPDvJQ9a+HACArW2uY866+9PLbtd1928kecqCawMA2HLm3a35uGUP75PZSNqDFlIRAMAWNu9uzQuW3b8jyb4k37/m1QAAbHHznq25a9GFAAAw/27Nnzrc/O7+9bUpBwBga7s7Z2t+a5KLp8dPT/KuJJ9cRFGw3nbsviRJct5pd+Sc6f5K9p1/5nqVBMAWNW84e2iSx3X355Kkql6S5I3d/aOHekJVnZzkNUm+NsmXk1zY3b9ZVQ9J8vokOzIdu9bdN1dVJfnNJGck+UKSc7r7ffekUwAAR6p5v77p65J8cdnjL2YWrg7njiTndfc3JnlSkhdU1aMz+yqoS7v71CSXTo+T5GlJTp1u5yZ5xZy1AQBsGvOOnL02yXur6i2ZfVPAszIbFTuk7r4hyQ3T/c9V1dVJTkxyVpKlabGLkuxN8qJp+mu6u5O8p6qOr6oTpnYAALaEmmWhORacXevs26eH7+ruv517JVU7MjtG7TFJPtHdxy+bd3N3P7iq3pbk/O5+9zT90iQv6u7LDmrr3MxG1rJ9+/bH79mzZ94yVrV///5s27ZtzdobzZXX3XLY+duPTW68bZ2KGdRqr8FpJx63fsVsgM3+O7Aa/df/e9P/1T5jDxj1c8T2X3z/d+3adXl371xtuXlHzpLkAUlu7e7fr6qHVdUp3f3x1Z5UVduSvDnJC7v71tmhZSsvusK0lb7P88IkFybJzp07e2lpad76V7V3796sZXujOdyB7snsYPgLrrw7b4nNZ7XXYN/zltavmA2w2X8HVqP/+n9v+r/aZ+wBo36O2P7j9H+uY86q6hcy2/X44mnSfZP8wRzPu29mwex13f3H0+Qbq+qEaf4JSW6apl+b5ORlTz8pyfXz1AcAsFnMe0LAs5I8I8nnk6S7r88qX980nX35qiRXH3QdtIuTnD3dPzvJW5dN/6GaeVKSWxxvBgBsNfPuw/pid3dVdZJU1QPneM6Tk/xgkiur6opp2s8kOT/JG6rq+Uk+keTZ07y3Z3YZjWsyu5TGD89ZGwDApjFvOHtDVf1OkuOr6t8m+ZEkrzzcE6YD+w91gNlTV1i+k7xgznoAADaleb9b89eq6ruS3JrkUUl+vrvfudDKAAC2oFXDWVUdleS/dvd3JhHIAAAWaNUTArr7ziRfqKoxL8wCALCJzHvM2T9mdmD/OzOdsZkk3f0TC6kKAAaxY87rl8FamTecXTLdAABYoMOGs6r6uu7+RHdftF4FAQBsZasdc/YnB+5U1ZsXXAsAwJa3Wjhbfp2yRy6yEAAAVg9nfYj7AAAswGonBHxzVd2a2QjasdP9TI+7u79qodUBAGwxhw1n3X3UehUCAMAcF6EFAGD9CGcAAAMRzgAABiKcAQAMRDgDABiIcAYAMBDhDABgIMIZAMBAhDMAgIEIZwAAAxHOAAAGIpwBAAxEOAMAGIhwBgAwEOEMAGAgwhkAwECEMwCAgQhnAAADEc4AAAYinAEADEQ4AwAYiHAGADAQ4QwAYCDCGQDAQIQzAICBCGcAAAMRzgAABiKcAQAMRDgDABiIcAYAMBDhDABgIMIZAMBAhDMAgIEIZwAAAxHOAAAGcvRGFwBHkh27L5l72X3nn7nASgDYrIycAQAMRDgDABiIcAYAMBDhDABgIMIZAMBAhDMAgIEIZwAAAxHOAAAGIpwBAAxkYeGsqn6vqm6qqquWTXtJVV1XVVdMtzOWzXtxVV1TVR+uqu9ZVF0AACNb5MjZq5OcvsL0l3b3Y6fb25Okqh6d5DlJvml6zv9VVUctsDYAgCEtLJx197uSfGbOxc9Ksqe7b+/ujye5JskTFlUbAMCoqrsX13jVjiRv6+7HTI9fkuScJLcmuSzJed19c1X9VpL3dPcfTMu9Ksk7uvtNK7R5bpJzk2T79u2P37Nnz5rVu3///mzbtm3N2hvNldfdctj5249NbrxtnYoZ1Fq+BqedeNzaNLSONvvvwGr0X/9X6v9qn51316ifDbb/4vu/a9euy7t752rLHb3QKr7SK5L8hyQ9/bwgyY8kqRWWXTE1dveFSS5Mkp07d/bS0tKaFbd3796sZXujOWf3JYedf95pd+SCK9f7LTGWtXwN9j1vaU3aWU+b/XdgNfqv/yv1f7XPzrtr1M8G23+c/q/r2ZrdfWN339ndX07yyvzzrstrk5y8bNGTkly/nrUBAIxgXcNZVZ2w7OGzkhw4k/PiJM+pqvtX1SlJTk3y3vWsDQBgBAvbh1VVf5RkKclDq+raJL+QZKmqHpvZLst9SX4sSbr7g1X1hiR/l+SOJC/o7jsXVRsAwKgWFs66+7krTH7VYZb/lSS/sqh6YKvYMefxMfvOP3PBlQBwT/iGAACAgQhnAAADEc4AAAYinAEADEQ4AwAYyNa+HDwMwNmVACxn5AwAYCDCGQDAQIQzAICBCGcAAANxQgAsyLwH+gPAckbOAAAGIpwBAAxEOAMAGIhwBgAwEOEMAGAgwhkAwECEMwCAgQhnAAADcRFaOEK4qC3A1mDkDABgIMIZAMBAhDMAgIEIZwAAAxHOAAAGIpwBAAxEOAMAGIhwBgAwEOEMAGAgwhkAwECEMwCAgQhnAAADEc4AAAYinAEADOTojS4A2Bg7dl/yFdPOO+2OnHPQ9H3nn7leJQEQI2cAAEMRzgAABmK3JrAmVtpNeih2lTKCg9+zK+3W58g372fTq09/4IIrmZ+RMwCAgQhnAAADEc4AAAYinAEADEQ4AwAYiHAGADAQ4QwAYCDCGQDAQIQzAICBCGcAAAMRzgAABuK7NQHYVO7O97zCiIycAQAMRDgDABiIcAYAMBDhDABgIMIZAMBAhDMAgIEsLJxV1e9V1U1VddWyaQ+pqndW1Uemnw+epldVvayqrqmqD1TV4xZVFwDAyBY5cvbqJKcfNG13kku7+9Qkl06Pk+RpSU6dbucmecUC6wIAGNbCwll3vyvJZw6afFaSi6b7FyV55rLpr+mZ9yQ5vqpOWFRtAACjqu5eXONVO5K8rbsfMz3+bHcfv2z+zd394Kp6W5Lzu/vd0/RLk7youy9boc1zMxtdy/bt2x+/Z8+eNat3//792bZt25q1N5orr7vlsPO3H5vceNs6FTOorf4arNT/0048bq7nrvb+uidtrrfN/hmwms3S/7vzXlxuvX7/vf/X17zvh1OOO2rh/d+1a9fl3b1zteVG+fqmWmHaiqmxuy9McmGS7Ny5s5eWltasiL1792Yt2xvNOat8pcl5p92RC64c5S2xMbb6a7BS//c9b2mu5672/ronba63zf4ZsJrN0v+7815cbr1+/73/19e874dXn/7AYfq/3mdr3nhgd+X086Zp+rVJTl623ElJrl/n2gAANtx6h7OLk5w93T87yVuXTf+h6azNJyW5pbtvWOfaAAA23MLGb6vqj5IsJXloVV2b5BeSnJ/kDVX1/CSfSPLsafG3JzkjyTVJvpDkhxdVF7Dxdsy5m2Hf+WcuuBKOJPO+b+BIt7Bw1t3PPcSsp66wbCd5waJqAQA4UviGAACAgQhnAAADEc4AAAYinAEADGTrXm0TmIsz5ADWl5EzAICBGDkDYM3dnRFX17ODuzJyBgAwEOEMAGAgwhkAwECEMwCAgQhnAAADEc4AAAYinAEADEQ4AwAYiHAGADAQ4QwAYCDCGQDAQIQzAIAHZZoSAAAKV0lEQVSBCGcAAAMRzgAABiKcAQAMRDgDABjI0RtdAMC9tWP3JXMtt+/8MxdcCffEvNsPtgrhDADW0d0Jo/6h2Jrs1gQAGIhwBgAwEOEMAGAgwhkAwECEMwCAgThbE4Ds2H1JzjvtjpyzypmEzh6ExTNyBgAwECNnAAdxUVtgIwlnAMzN1fxh8YQzYFibJQi4IjxwdzjmDABgIMIZAMBA7NYEuIeOhN2uR0KNwF0JZwADcaYoYLcmAMBAhDMAgIEIZwAAAxHOAAAGIpwBAAxEOAMAGIhwBgAwEOEMAGAgwhkAwECEMwCAgfj6JoAjkO/MhM1LONsEfEgDwOZhtyYAwECEMwCAgQhnAAADEc4AAAYinAEADGRDztasqn1JPpfkziR3dPfOqnpIktcn2ZFkX5Lv7+6bN6I+AICNspEjZ7u6+7HdvXN6vDvJpd19apJLp8cAAFvKSLs1z0py0XT/oiTP3MBaAAA2RHX3+q+06uNJbk7SSX6nuy+sqs929/HLlrm5ux+8wnPPTXJukmzfvv3xe/bsWbO69u/fn23btq1Ze+vlyutuWZN2th+b3HjbmjR1xNrqr8Fm7/9pJx532PkHPgPW6nfqSLPZt/9qRuz/au/ZtXSk/g1czby/z6ccd9TC+79r167Ll+0xPKSNCmcP7+7rq+prkrwzyf+W5OJ5wtlyO3fu7Msuu2zN6tq7d2+WlpbWrL31slbfEHDeaXfkgiu39pdGbPXXYLP3f9/5Zx52/oHPgK36rRubffuvZsT+r/aeXUtH6t/A1cz7+/zq0x+48P5X1VzhbEN2a3b39dPPm5K8JckTktxYVSckyfTzpo2oDQBgI617OKuqB1bVgw7cT/LdSa5KcnGSs6fFzk7y1vWuDQBgo23E+O32JG+pqgPr/8Pu/i9V9TdJ3lBVz0/yiSTP3oDaAAA21LqHs+7+WJJvXmH6p5M8db3rAQAYyUiX0gAA2PKEMwCAgQhnAAADGeuCLtzFVr3WEgBsZUbOAAAGIpwBAAxEOAMAGIhwBgAwEOEMAGAgwhkAwECEMwCAgbjOGbBlrHbtwPNOuyPnuL4gsMGMnAEADEQ4AwAYiHAGADAQ4QwAYCDCGQDAQIQzAICBCGcAAAMRzgAABuIitHNY7cKVB+w7/8wFVwIAbHZGzgAABmLkbA0ZYQNgLfm7sjUZOQMAGIiRsw0w739CAMDWY+QMAGAgwhkAwECEMwCAgQhnAAADEc4AAAYinAEADEQ4AwAYiHAGADAQ4QwAYCDCGQDAQIQzAICBCGcAAAPxxecAcITbsfuSuZbbd/6ZC66EtWDkDABgIMIZAMBAhDMAgIE45gwAtojDHZt23ml35Jw5j107wDFsi2HkDABgIEbOAIB7xFmii2HkDABgIMIZAMBAhDMAgIEIZwAAA3FCAAAwhHlPMEg290kGRs4AAAYinAEADMRuTQDgiHN3doEeaYycAQAMRDgDABiIcAYAMBDHnAEAC7WZjw9bhOFGzqrq9Kr6cFVdU1W7N7oeAID1NFQ4q6qjkrw8ydOSPDrJc6vq0RtbFQDA+hkqnCV5QpJruvtj3f3FJHuSnLXBNQEArJvq7o2u4Z9U1fclOb27f3R6/INJntjdP75smXOTnDs9fFSSD69hCQ9N8qk1bO9Is9X7n3gN9F//9X/r0v/F9/8R3f2w1RYa7YSAWmHaXdJjd1+Y5MKFrLzqsu7euYi2jwRbvf+J10D/9V//9X+j69goI/V/tN2a1yY5ednjk5Jcv0G1AACsu9HC2d8kObWqTqmq+yV5TpKLN7gmAIB1M9Ruze6+o6p+PMl/TXJUkt/r7g+uYwkL2V16BNnq/U+8Bvq/ten/1qb/gxjqhAAAgK1utN2aAABbmnAGADAQ4Wyy1b42qqpOrqq/rKqrq+qDVfWT0/SXVNV1VXXFdDtjo2tdlKraV1VXTv28bJr2kKp6Z1V9ZPr54I2ucxGq6lHLtvEVVXVrVb1wM2//qvq9qrqpqq5aNm3F7V0zL5s+Dz5QVY/buMrXxiH6/5+r6kNTH99SVcdP03dU1W3L3ge/vXGVr41D9P+Q7/eqevG0/T9cVd+zMVWvnUP0//XL+r6vqq6Ypm/G7X+ov3ljfgZ095a/ZXbywUeTPDLJ/ZK8P8mjN7quBff5hCSPm+4/KMl/y+wrs16S5Kc3ur51eg32JXnoQdP+U5Ld0/3dSX51o+tch9fhqCT/kOQRm3n7J/nXSR6X5KrVtneSM5K8I7NrLz4pyV9vdP0L6v93Jzl6uv+ry/q/Y/lym+F2iP6v+H6fPgvfn+T+SU6Z/j4ctdF9WOv+HzT/giQ/v4m3/6H+5g35GWDkbGbLfW1Ud9/Q3e+b7n8uydVJTtzYqoZwVpKLpvsXJXnmBtayXp6a5KPd/fcbXcgidfe7knzmoMmH2t5nJXlNz7wnyfFVdcL6VLoYK/W/u/+su++YHr4ns2tLbkqH2P6HclaSPd19e3d/PMk1mf2dOGIdrv9VVUm+P8kfrWtR6+gwf/OG/AwQzmZOTPLJZY+vzRYKKlW1I8m3JPnradKPT8O4v7dZd+tNOsmfVdXlNftasCTZ3t03JLNf5iRfs2HVrZ/n5K4fyltl+yeH3t5b8TPhRzIbKTjglKr626r6q6r69o0qah2s9H7fatv/25Pc2N0fWTZt027/g/7mDfkZIJzNrPq1UZtVVW1L8uYkL+zuW5O8Ism/SPLYJDdkNtS9WT25ux+X5GlJXlBV/3qjC1pvNbvY8zOSvHGatJW2/+Fsqc+EqvrZJHcked006YYkX9fd35Lkp5L8YVV91UbVt0CHer9vqe2f5Lm56z9om3b7r/A375CLrjBt3d4DwtnMlvzaqKq6b2Zv0td19x8nSXff2N13dveXk7wyR/hQ/uF09/XTz5uSvCWzvt54YOh6+nnTxlW4Lp6W5H3dfWOytbb/5FDbe8t8JlTV2Un+TZLn9XSwzbQ779PT/cszO+bqGzauysU4zPt9K23/o5N8b5LXH5i2Wbf/Sn/zMuhngHA2s+W+Nmo6xuBVSa7u7l9fNn35PvVnJbnq4OduBlX1wKp60IH7mR0YfVVm2/3sabGzk7x1YypcN3f5j3mrbP9lDrW9L07yQ9MZW09KcsuBXR+bSVWdnuRFSZ7R3V9YNv1hVXXUdP+RSU5N8rGNqXJxDvN+vzjJc6rq/lV1Smb9f+9617dOvjPJh7r72gMTNuP2P9TfvIz6GbCRZ0+MdMvszIz/ltl/CD+70fWsQ3+/LbMh2g8kuWK6nZHktUmunKZfnOSEja51Qf1/ZGZnY70/yQcPbPMkX53k0iQfmX4+ZKNrXeBr8IAkn05y3LJpm3b7ZxZCb0jypcz+K37+obZ3Zrs0Xj59HlyZZOdG17+g/l+T2XE1Bz4Dfnta9n+afi/en+R9SZ6+0fUvqP+HfL8n+dlp+384ydM2uv5F9H+a/uok/+6gZTfj9j/U37whPwN8fRMAwEDs1gQAGIhwBgAwEOEMAGAgwhkAwECEMwCAgQhnAAADEc4AAAby/wMNkBt/bD5r5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from string import digits, punctuation\n",
    "\n",
    "def clear_text(text, is_all_lower=True):\n",
    "    punct = re.sub(r'[\\.,!?&\\-]', '', punctuation)\n",
    "    punctuation_table = str.maketrans({key: \"#\" for key in punct})\n",
    "    for char in [\"\\\"\", \"\\'\"]:\n",
    "        del punctuation_table[ord(char)]\n",
    "    \n",
    "    review_cleaned = text.apply(lambda x: re.sub(r'[^\\x00-\\x7F]', ' ', x))\n",
    "    review_cleaned = review_cleaned.apply(lambda x: re.sub(r'[0-9]', '9', x))\n",
    "    review_cleaned = review_cleaned.apply(lambda x: x.translate(punctuation_table))\n",
    "    review_cleaned = review_cleaned.apply(lambda x: re.sub(r' +', ' ', x))\n",
    "    review_cleaned = review_cleaned.apply(lambda x: re.sub(r' (?=[\\.,!?&\\-])','', x))\n",
    "    \n",
    "    if is_all_lower:\n",
    "        review_cleaned = review_cleaned.str.lower()\n",
    "        \n",
    "    return review_cleaned\n",
    "\n",
    "data_df[column_name[\"text\"]] = data_df[column_name[\"text\"]]\n",
    "data_df[column_name[\"text\"]] = data_df[column_name[\"text\"]].apply(lambda x: x[:200])\n",
    "\n",
    "# number of chars\n",
    "data_df[column_name[\"text\"]].str.len().plot(kind=\"hist\", title=\"line lenght distribution\", grid=True, figsize=(10,10), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATASET_FOLDER_PATH):\n",
    "    os.makedirs(DATASET_FOLDER_PATH)\n",
    "data_df.iloc[0: int(len(data_df)*0.8)].to_csv(os.path.join(DATASET_FOLDER_PATH, 'train.csv'), sep='\\t', index = False, header = False)\n",
    "data_df.iloc[int(len(data_df)*0.8): int(len(data_df)*0.9)].to_csv(os.path.join(DATASET_FOLDER_PATH, 'dev.csv'), sep='\\t', index = False, header = False)\n",
    "data_df.iloc[int(len(data_df)*0.9): ].to_csv(os.path.join(DATASET_FOLDER_PATH, 'test.csv'), sep='\\t', index = False, header = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-10 13:03:23,622 Reading data from splitted_data/spam\n",
      "2019-08-10 13:03:23,623 Train: splitted_data/spam/train.csv\n",
      "2019-08-10 13:03:23,625 Dev: splitted_data/spam/dev.csv\n",
      "2019-08-10 13:03:23,626 Test: splitted_data/spam/test.csv\n"
     ]
    }
   ],
   "source": [
    "corpus: Corpus = ClassificationCorpus(DATASET_FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.training_utils import EvaluationMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_FOLDER_PATH):\n",
    "    os.makedirs(MODEL_FOLDER_PATH)\n",
    "\n",
    "params_train = {\n",
    "    \"word_emb\": 'glove',\n",
    "    \"flair_emb_forward\": 'news-forward-fast',\n",
    "    \"flair_emb_backward\": 'news-backward-fast',\n",
    "    \"hidden_size\": 256,\n",
    "    \"reproject_words_dimension\": 128,\n",
    "    \"max_epoch\": 10,\n",
    "    \"evaluation_metric\": EvaluationMetric.MICRO_ACCURACY\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = [WordEmbeddings(params_train[\"word_emb\"]), FlairEmbeddings(params_train[\"flair_emb_forward\"]),\n",
    "                   FlairEmbeddings(params_train[\"flair_emb_backward\"])]\n",
    "\n",
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=params_train[\"hidden_size\"],\n",
    "                                            reproject_words=True, reproject_words_dimension=params_train[\"reproject_words_dimension\"])\n",
    "\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "\n",
    "trainer.train(MODEL_FOLDER_PATH, max_epochs=params_train[\"max_epoch\"], evaluation_metric=params_train[\"evaluation_metric\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_tsv = trainer.find_learning_rate(MODEL_FOLDER_PATH, 'learning_rate.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = Plotter()\n",
    "plotter.plot_learning_rate(learning_rate_tsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"model/learning_rate.png\" height=1000, width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list of all available hyperparameters to tune\n",
    "https://github.com/zalandoresearch/flair/blob/master/flair/hyperparameter/parameter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from flair.hyperparameter.param_selection import SearchSpace, Parameter, TextClassifierParamSelector, OptimizationValue\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings\n",
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your search space\n",
    "search_space = SearchSpace()\n",
    "search_space.add(Parameter.EMBEDDINGS, hp.choice, options=[\n",
    "    [ WordEmbeddings('en') ], \n",
    "    [ FlairEmbeddings('news-forward'), FlairEmbeddings('news-backward') ]\n",
    "])\n",
    "search_space.add(Parameter.HIDDEN_SIZE, hp.choice, options=[32, 64, 128, 256])\n",
    "search_space.add(Parameter.RNN_LAYERS, hp.choice, options=[1, 2])\n",
    "search_space.add(Parameter.DROPOUT, hp.uniform, low=0.1, high=0.5)\n",
    "search_space.add(Parameter.LEARNING_RATE, hp.choice, options=[0.05, 0.1, 0.15, 0.2])\n",
    "search_space.add(Parameter.MINI_BATCH_SIZE, hp.choice, options=[8, 16, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-10 16:02:17,098 {'ham', 'spam'}\n"
     ]
    }
   ],
   "source": [
    "param_selector = TextClassifierParamSelector(\n",
    "    corpus=corpus, \n",
    "    multi_label=False, \n",
    "    base_path=MODEL_FOLDER_PATH, \n",
    "    document_embedding_type='lstm',\n",
    "    max_epochs=10, \n",
    "    training_runs=3,\n",
    "    optimization_value=OptimizationValue.DEV_SCORE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]2019-08-10 16:02:21,526 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:02:21,530 Evaluation run: 1\n",
      "2019-08-10 16:02:21,532 Evaluating parameter combination:\n",
      "2019-08-10 16:02:21,535 \tdropout: 0.10426696339723916\n",
      "2019-08-10 16:02:21,537 \tembeddings: /tmp/.flair/embeddings/news-forward-0.4.1.pt,/tmp/.flair/embeddings/news-backward-0.4.1.pt\n",
      "2019-08-10 16:02:21,539 \thidden_size: 128\n",
      "2019-08-10 16:02:21,541 \tlearning_rate: 0.2\n",
      "2019-08-10 16:02:21,546 \tmini_batch_size: 16\n",
      "2019-08-10 16:02:21,548 \trnn_layers: 2\n",
      "2019-08-10 16:02:21,550 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:02:24,255 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:02:24,259 Training run: 1\n",
      "2019-08-10 16:02:24,565 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:02:24,568 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 16:02:25,376 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:02:26,695 epoch 1 - iter 0/277 - loss 0.76230216\n",
      "2019-08-10 16:02:33,094 epoch 1 - iter 27/277 - loss 0.21146747\n",
      "2019-08-10 16:02:39,185 epoch 1 - iter 54/277 - loss 0.14793852\n",
      "2019-08-10 16:02:45,429 epoch 1 - iter 81/277 - loss 0.13119775\n",
      "2019-08-10 16:02:51,904 epoch 1 - iter 108/277 - loss 0.12009372\n",
      "2019-08-10 16:02:58,435 epoch 1 - iter 135/277 - loss 0.11032976\n",
      "2019-08-10 16:03:04,995 epoch 1 - iter 162/277 - loss 0.10410604\n",
      "2019-08-10 16:03:11,116 epoch 1 - iter 189/277 - loss 0.09478059\n",
      "2019-08-10 16:03:17,396 epoch 1 - iter 216/277 - loss 0.09057053\n",
      "2019-08-10 16:03:23,855 epoch 1 - iter 243/277 - loss 0.08804627\n",
      "2019-08-10 16:03:30,207 epoch 1 - iter 270/277 - loss 0.08126153\n",
      "2019-08-10 16:03:32,013 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:03:32,017 EPOCH 1 done: loss 0.0804 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 16:03:42,829 DEV : loss 0.05286106839776039 - score 0.9802\n",
      "2019-08-10 16:03:42,832 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:03:44,290 epoch 2 - iter 0/277 - loss 0.00201674\n",
      "2019-08-10 16:03:50,841 epoch 2 - iter 27/277 - loss 0.01764937\n",
      "2019-08-10 16:03:57,251 epoch 2 - iter 54/277 - loss 0.03119606\n",
      "2019-08-10 16:04:03,435 epoch 2 - iter 81/277 - loss 0.03120614\n",
      "2019-08-10 16:04:09,813 epoch 2 - iter 108/277 - loss 0.03036582\n",
      "2019-08-10 16:04:16,234 epoch 2 - iter 135/277 - loss 0.03674530\n",
      "2019-08-10 16:04:22,649 epoch 2 - iter 162/277 - loss 0.03788596\n",
      "2019-08-10 16:04:29,220 epoch 2 - iter 189/277 - loss 0.04031126\n",
      "2019-08-10 16:04:35,577 epoch 2 - iter 216/277 - loss 0.03965084\n",
      "2019-08-10 16:04:41,825 epoch 2 - iter 243/277 - loss 0.03909353\n",
      "2019-08-10 16:04:48,228 epoch 2 - iter 270/277 - loss 0.04147621\n",
      "2019-08-10 16:04:49,937 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:04:49,940 EPOCH 2 done: loss 0.0416 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 16:04:58,706 DEV : loss 0.04778539761900902 - score 0.982\n",
      "2019-08-10 16:04:58,710 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:05:00,112 epoch 3 - iter 0/277 - loss 0.01964325\n",
      "2019-08-10 16:05:06,751 epoch 3 - iter 27/277 - loss 0.03892378\n",
      "2019-08-10 16:05:12,998 epoch 3 - iter 54/277 - loss 0.03495352\n",
      "2019-08-10 16:05:19,247 epoch 3 - iter 81/277 - loss 0.03456585\n",
      "2019-08-10 16:05:25,372 epoch 3 - iter 108/277 - loss 0.03063894\n",
      "2019-08-10 16:05:34,332 epoch 3 - iter 135/277 - loss 0.03458998\n",
      "2019-08-10 16:05:40,729 epoch 3 - iter 162/277 - loss 0.03153105\n",
      "2019-08-10 16:05:46,783 epoch 3 - iter 189/277 - loss 0.02960137\n",
      "2019-08-10 16:05:53,006 epoch 3 - iter 216/277 - loss 0.02880718\n",
      "2019-08-10 16:05:59,333 epoch 3 - iter 243/277 - loss 0.03239139\n",
      "2019-08-10 16:06:05,750 epoch 3 - iter 270/277 - loss 0.03148011\n",
      "2019-08-10 16:06:07,612 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:06:07,615 EPOCH 3 done: loss 0.0309 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 16:06:16,614 DEV : loss 0.04783530533313751 - score 0.9874\n",
      "2019-08-10 16:06:16,617 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:06:18,249 epoch 4 - iter 0/277 - loss 0.00125338\n",
      "2019-08-10 16:06:24,573 epoch 4 - iter 27/277 - loss 0.03581722\n",
      "2019-08-10 16:06:30,915 epoch 4 - iter 54/277 - loss 0.02972474\n",
      "2019-08-10 16:06:37,337 epoch 4 - iter 81/277 - loss 0.02541418\n",
      "2019-08-10 16:06:44,003 epoch 4 - iter 108/277 - loss 0.02949371\n",
      "2019-08-10 16:06:50,514 epoch 4 - iter 135/277 - loss 0.02663370\n",
      "2019-08-10 16:06:56,796 epoch 4 - iter 162/277 - loss 0.02750286\n",
      "2019-08-10 16:07:03,225 epoch 4 - iter 189/277 - loss 0.02804935\n",
      "2019-08-10 16:07:09,475 epoch 4 - iter 216/277 - loss 0.02726681\n",
      "2019-08-10 16:07:15,837 epoch 4 - iter 243/277 - loss 0.02507232\n",
      "2019-08-10 16:07:22,153 epoch 4 - iter 270/277 - loss 0.02452075\n",
      "2019-08-10 16:07:26,343 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:07:26,345 EPOCH 4 done: loss 0.0256 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 16:07:35,291 DEV : loss 0.04039057344198227 - score 0.9892\n",
      "2019-08-10 16:07:35,294 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:07:36,924 epoch 5 - iter 0/277 - loss 0.00477743\n",
      "2019-08-10 16:07:43,366 epoch 5 - iter 27/277 - loss 0.01568582\n",
      "2019-08-10 16:07:49,626 epoch 5 - iter 54/277 - loss 0.01145381\n",
      "2019-08-10 16:07:56,058 epoch 5 - iter 81/277 - loss 0.01410033\n",
      "2019-08-10 16:08:02,520 epoch 5 - iter 108/277 - loss 0.01524527\n",
      "2019-08-10 16:08:08,871 epoch 5 - iter 135/277 - loss 0.01596929\n",
      "2019-08-10 16:08:15,209 epoch 5 - iter 162/277 - loss 0.01949816\n",
      "2019-08-10 16:08:21,567 epoch 5 - iter 189/277 - loss 0.01939134\n",
      "2019-08-10 16:08:27,788 epoch 5 - iter 216/277 - loss 0.01741780\n",
      "2019-08-10 16:08:34,197 epoch 5 - iter 243/277 - loss 0.01965620\n",
      "2019-08-10 16:08:40,596 epoch 5 - iter 270/277 - loss 0.02022696\n",
      "2019-08-10 16:08:42,527 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:08:42,529 EPOCH 5 done: loss 0.0199 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 16:08:51,628 DEV : loss 0.04102146252989769 - score 0.9892\n",
      "2019-08-10 16:08:51,631 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:08:53,416 epoch 6 - iter 0/277 - loss 0.00393432\n",
      "2019-08-10 16:08:59,764 epoch 6 - iter 27/277 - loss 0.00535333\n",
      "2019-08-10 16:09:06,278 epoch 6 - iter 54/277 - loss 0.01333050\n",
      "2019-08-10 16:09:12,806 epoch 6 - iter 81/277 - loss 0.01261616\n",
      "2019-08-10 16:09:19,232 epoch 6 - iter 108/277 - loss 0.01263008\n",
      "2019-08-10 16:09:28,134 epoch 6 - iter 135/277 - loss 0.01136400\n",
      "2019-08-10 16:09:34,449 epoch 6 - iter 162/277 - loss 0.01277800\n",
      "2019-08-10 16:09:40,564 epoch 6 - iter 189/277 - loss 0.01279578\n",
      "2019-08-10 16:09:46,845 epoch 6 - iter 216/277 - loss 0.01253467\n",
      "2019-08-10 16:09:53,029 epoch 6 - iter 243/277 - loss 0.01377568\n",
      "2019-08-10 16:09:59,274 epoch 6 - iter 270/277 - loss 0.01425817\n",
      "2019-08-10 16:10:01,246 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:10:01,249 EPOCH 6 done: loss 0.0140 - lr 0.2000 - bad epochs 1\n",
      "2019-08-10 16:10:10,332 DEV : loss 0.04661744087934494 - score 0.982\n",
      "2019-08-10 16:10:10,335 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:10:12,200 epoch 7 - iter 0/277 - loss 0.00034599\n",
      "2019-08-10 16:10:18,637 epoch 7 - iter 27/277 - loss 0.00323870\n",
      "2019-08-10 16:10:25,134 epoch 7 - iter 54/277 - loss 0.00343020\n",
      "2019-08-10 16:10:31,164 epoch 7 - iter 81/277 - loss 0.00285617\n",
      "2019-08-10 16:10:37,595 epoch 7 - iter 108/277 - loss 0.00255059\n",
      "2019-08-10 16:10:43,847 epoch 7 - iter 135/277 - loss 0.00408382\n",
      "2019-08-10 16:10:50,168 epoch 7 - iter 162/277 - loss 0.00589426\n",
      "2019-08-10 16:10:56,327 epoch 7 - iter 189/277 - loss 0.00579146\n",
      "2019-08-10 16:11:02,560 epoch 7 - iter 216/277 - loss 0.00529205\n",
      "2019-08-10 16:11:08,858 epoch 7 - iter 243/277 - loss 0.00481774\n",
      "2019-08-10 16:11:17,652 epoch 7 - iter 270/277 - loss 0.00680614\n",
      "2019-08-10 16:11:19,625 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:11:19,629 EPOCH 7 done: loss 0.0069 - lr 0.2000 - bad epochs 2\n",
      "2019-08-10 16:11:28,651 DEV : loss 0.041834279894828796 - score 0.9838\n",
      "2019-08-10 16:11:28,654 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:11:30,344 epoch 8 - iter 0/277 - loss 0.00572520\n",
      "2019-08-10 16:11:36,796 epoch 8 - iter 27/277 - loss 0.00081695\n",
      "2019-08-10 16:11:43,143 epoch 8 - iter 54/277 - loss 0.00499131\n",
      "2019-08-10 16:11:49,710 epoch 8 - iter 81/277 - loss 0.00383494\n",
      "2019-08-10 16:11:56,146 epoch 8 - iter 108/277 - loss 0.00338716\n",
      "2019-08-10 16:12:02,389 epoch 8 - iter 135/277 - loss 0.00294312\n",
      "2019-08-10 16:12:08,838 epoch 8 - iter 162/277 - loss 0.00281220\n",
      "2019-08-10 16:12:15,121 epoch 8 - iter 189/277 - loss 0.00293106\n",
      "2019-08-10 16:12:21,314 epoch 8 - iter 216/277 - loss 0.00264415\n",
      "2019-08-10 16:12:27,761 epoch 8 - iter 243/277 - loss 0.00249195\n",
      "2019-08-10 16:12:33,996 epoch 8 - iter 270/277 - loss 0.00228830\n",
      "2019-08-10 16:12:35,895 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:12:35,898 EPOCH 8 done: loss 0.0022 - lr 0.2000 - bad epochs 3\n",
      "2019-08-10 16:12:44,990 DEV : loss 0.04736828804016113 - score 0.9856\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-01.\n",
      "  0%|          | 0/10 [10:23<?, ?it/s, best loss: ?]2019-08-10 16:12:45,012 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:12:46,883 epoch 9 - iter 0/277 - loss 0.00030270\n",
      "2019-08-10 16:12:53,194 epoch 9 - iter 27/277 - loss 0.00030457\n",
      "2019-08-10 16:12:59,741 epoch 9 - iter 54/277 - loss 0.00038872\n",
      "2019-08-10 16:13:06,116 epoch 9 - iter 81/277 - loss 0.00037629\n",
      "2019-08-10 16:13:15,156 epoch 9 - iter 108/277 - loss 0.00071972\n",
      "2019-08-10 16:13:21,591 epoch 9 - iter 135/277 - loss 0.00069999\n",
      "2019-08-10 16:13:27,682 epoch 9 - iter 162/277 - loss 0.00069279\n",
      "2019-08-10 16:13:33,840 epoch 9 - iter 189/277 - loss 0.00062988\n",
      "2019-08-10 16:13:40,128 epoch 9 - iter 216/277 - loss 0.00067694\n",
      "2019-08-10 16:13:46,318 epoch 9 - iter 243/277 - loss 0.00064604\n",
      "2019-08-10 16:13:52,526 epoch 9 - iter 270/277 - loss 0.00063893\n",
      "2019-08-10 16:13:54,461 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:13:54,463 EPOCH 9 done: loss 0.0006 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 16:14:03,501 DEV : loss 0.051468733698129654 - score 0.9856\n",
      "2019-08-10 16:14:03,504 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:14:05,130 epoch 10 - iter 0/277 - loss 0.00019489\n",
      "2019-08-10 16:14:11,718 epoch 10 - iter 27/277 - loss 0.00086782\n",
      "2019-08-10 16:14:18,106 epoch 10 - iter 54/277 - loss 0.00060072\n",
      "2019-08-10 16:14:24,410 epoch 10 - iter 81/277 - loss 0.00048312\n",
      "2019-08-10 16:14:30,609 epoch 10 - iter 108/277 - loss 0.00043003\n",
      "2019-08-10 16:14:37,080 epoch 10 - iter 135/277 - loss 0.00073104\n",
      "2019-08-10 16:14:43,525 epoch 10 - iter 162/277 - loss 0.00064952\n",
      "2019-08-10 16:14:49,878 epoch 10 - iter 189/277 - loss 0.00059085\n",
      "2019-08-10 16:14:56,223 epoch 10 - iter 216/277 - loss 0.00058460\n",
      "2019-08-10 16:15:02,372 epoch 10 - iter 243/277 - loss 0.00056259\n",
      "2019-08-10 16:15:11,168 epoch 10 - iter 270/277 - loss 0.00055053\n",
      "2019-08-10 16:15:13,201 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:15:13,203 EPOCH 10 done: loss 0.0005 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 16:15:22,217 DEV : loss 0.058915991336107254 - score 0.9838\n",
      "2019-08-10 16:15:22,223 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:15:22,224 Testing using best model ...\n",
      "2019-08-10 16:15:31,190 0.9856\t0.9856\t0.9856\n",
      "2019-08-10 16:15:31,193 \n",
      "MICRO_AVG: acc 0.9716 - f1-score 0.9856\n",
      "MACRO_AVG: acc 0.9411 - f1-score 0.96915\n",
      "ham        tp: 476 - fp: 5 - fn: 3 - tn: 71 - precision: 0.9896 - recall: 0.9937 - accuracy: 0.9835 - f1-score: 0.9916\n",
      "spam       tp: 71 - fp: 3 - fn: 5 - tn: 476 - precision: 0.9595 - recall: 0.9342 - accuracy: 0.8987 - f1-score: 0.9467\n",
      "2019-08-10 16:15:31,196 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:15:31,199 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:15:31,201 Training run: 2\n",
      "2019-08-10 16:15:31,511 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:15:31,514 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 16:15:32,552 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:15:34,390 epoch 1 - iter 0/277 - loss 0.78631496\n",
      "2019-08-10 16:15:41,193 epoch 1 - iter 27/277 - loss 0.19480117\n",
      "2019-08-10 16:15:47,599 epoch 1 - iter 54/277 - loss 0.13162670\n",
      "2019-08-10 16:15:53,788 epoch 1 - iter 81/277 - loss 0.11314045\n",
      "2019-08-10 16:16:00,095 epoch 1 - iter 108/277 - loss 0.10109578\n",
      "2019-08-10 16:16:06,448 epoch 1 - iter 135/277 - loss 0.08794773\n",
      "2019-08-10 16:16:12,906 epoch 1 - iter 162/277 - loss 0.08870691\n",
      "2019-08-10 16:16:19,190 epoch 1 - iter 189/277 - loss 0.08450172\n",
      "2019-08-10 16:16:25,542 epoch 1 - iter 216/277 - loss 0.08126640\n",
      "2019-08-10 16:16:31,978 epoch 1 - iter 243/277 - loss 0.07991462\n",
      "2019-08-10 16:16:38,435 epoch 1 - iter 270/277 - loss 0.07554896\n",
      "2019-08-10 16:16:40,342 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:16:40,344 EPOCH 1 done: loss 0.0754 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 16:16:49,550 DEV : loss 0.223953977227211 - score 0.9225\n",
      "2019-08-10 16:16:49,554 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:16:51,671 epoch 2 - iter 0/277 - loss 0.24105799\n",
      "2019-08-10 16:16:58,315 epoch 2 - iter 27/277 - loss 0.07108851\n",
      "2019-08-10 16:17:04,504 epoch 2 - iter 54/277 - loss 0.05020323\n",
      "2019-08-10 16:17:10,624 epoch 2 - iter 81/277 - loss 0.04564886\n",
      "2019-08-10 16:17:19,752 epoch 2 - iter 108/277 - loss 0.03580605\n",
      "2019-08-10 16:17:26,070 epoch 2 - iter 135/277 - loss 0.04082563\n",
      "2019-08-10 16:17:32,618 epoch 2 - iter 162/277 - loss 0.03854601\n",
      "2019-08-10 16:17:38,812 epoch 2 - iter 189/277 - loss 0.03512188\n",
      "2019-08-10 16:17:44,953 epoch 2 - iter 216/277 - loss 0.03961956\n",
      "2019-08-10 16:17:51,390 epoch 2 - iter 243/277 - loss 0.04308246\n",
      "2019-08-10 16:17:57,714 epoch 2 - iter 270/277 - loss 0.03970982\n",
      "2019-08-10 16:17:59,659 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:17:59,661 EPOCH 2 done: loss 0.0415 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 16:18:08,729 DEV : loss 0.05266156792640686 - score 0.9784\n",
      "2019-08-10 16:18:08,732 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:18:10,415 epoch 3 - iter 0/277 - loss 0.00922064\n",
      "2019-08-10 16:18:17,090 epoch 3 - iter 27/277 - loss 0.04377284\n",
      "2019-08-10 16:18:23,509 epoch 3 - iter 54/277 - loss 0.04572408\n",
      "2019-08-10 16:18:30,000 epoch 3 - iter 81/277 - loss 0.04097360\n",
      "2019-08-10 16:18:36,231 epoch 3 - iter 108/277 - loss 0.04257259\n",
      "2019-08-10 16:18:42,429 epoch 3 - iter 135/277 - loss 0.04127777\n",
      "2019-08-10 16:18:48,910 epoch 3 - iter 162/277 - loss 0.04142050\n",
      "2019-08-10 16:18:55,353 epoch 3 - iter 189/277 - loss 0.03675730\n",
      "2019-08-10 16:19:01,809 epoch 3 - iter 216/277 - loss 0.03536972\n",
      "2019-08-10 16:19:10,577 epoch 3 - iter 243/277 - loss 0.03415295\n",
      "2019-08-10 16:19:16,759 epoch 3 - iter 270/277 - loss 0.03325677\n",
      "2019-08-10 16:19:18,638 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:19:18,641 EPOCH 3 done: loss 0.0344 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 16:19:27,720 DEV : loss 0.04748532176017761 - score 0.9838\n",
      "2019-08-10 16:19:27,723 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:19:29,454 epoch 4 - iter 0/277 - loss 0.00170505\n",
      "2019-08-10 16:19:36,081 epoch 4 - iter 27/277 - loss 0.04365349\n",
      "2019-08-10 16:19:42,486 epoch 4 - iter 54/277 - loss 0.03114441\n",
      "2019-08-10 16:19:48,829 epoch 4 - iter 81/277 - loss 0.02482853\n",
      "2019-08-10 16:19:55,359 epoch 4 - iter 108/277 - loss 0.02862594\n",
      "2019-08-10 16:20:01,601 epoch 4 - iter 135/277 - loss 0.02630104\n",
      "2019-08-10 16:20:07,995 epoch 4 - iter 162/277 - loss 0.02508220\n",
      "2019-08-10 16:20:14,278 epoch 4 - iter 189/277 - loss 0.02480725\n",
      "2019-08-10 16:20:20,766 epoch 4 - iter 216/277 - loss 0.02612814\n",
      "2019-08-10 16:20:27,141 epoch 4 - iter 243/277 - loss 0.02505834\n",
      "2019-08-10 16:20:33,542 epoch 4 - iter 270/277 - loss 0.02623613\n",
      "2019-08-10 16:20:35,500 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:20:35,502 EPOCH 4 done: loss 0.0269 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 16:20:44,667 DEV : loss 0.0430893637239933 - score 0.9874\n",
      "2019-08-10 16:20:44,671 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:20:46,413 epoch 5 - iter 0/277 - loss 0.01330202\n",
      "2019-08-10 16:20:52,951 epoch 5 - iter 27/277 - loss 0.00659140\n",
      "2019-08-10 16:20:59,062 epoch 5 - iter 54/277 - loss 0.00561594\n",
      "2019-08-10 16:21:05,825 epoch 5 - iter 81/277 - loss 0.01090176\n",
      "2019-08-10 16:21:14,818 epoch 5 - iter 108/277 - loss 0.01036021\n",
      "2019-08-10 16:21:21,200 epoch 5 - iter 135/277 - loss 0.01674133\n",
      "2019-08-10 16:21:27,563 epoch 5 - iter 162/277 - loss 0.01533194\n",
      "2019-08-10 16:21:34,071 epoch 5 - iter 189/277 - loss 0.01679460\n",
      "2019-08-10 16:21:40,424 epoch 5 - iter 216/277 - loss 0.01730982\n",
      "2019-08-10 16:21:46,835 epoch 5 - iter 243/277 - loss 0.01648192\n",
      "2019-08-10 16:21:53,164 epoch 5 - iter 270/277 - loss 0.01951095\n",
      "2019-08-10 16:21:55,403 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:21:55,406 EPOCH 5 done: loss 0.0193 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 16:22:04,631 DEV : loss 0.04854710400104523 - score 0.9856\n",
      "2019-08-10 16:22:04,634 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:22:06,553 epoch 6 - iter 0/277 - loss 0.00110608\n",
      "2019-08-10 16:22:13,006 epoch 6 - iter 27/277 - loss 0.01836011\n",
      "2019-08-10 16:22:19,293 epoch 6 - iter 54/277 - loss 0.01306428\n",
      "2019-08-10 16:22:25,750 epoch 6 - iter 81/277 - loss 0.00965693\n",
      "2019-08-10 16:22:31,822 epoch 6 - iter 108/277 - loss 0.01305054\n",
      "2019-08-10 16:22:37,955 epoch 6 - iter 135/277 - loss 0.01261020\n",
      "2019-08-10 16:22:44,309 epoch 6 - iter 162/277 - loss 0.01438851\n",
      "2019-08-10 16:22:50,878 epoch 6 - iter 189/277 - loss 0.01381218\n",
      "2019-08-10 16:22:57,336 epoch 6 - iter 216/277 - loss 0.01291949\n",
      "2019-08-10 16:23:06,333 epoch 6 - iter 243/277 - loss 0.01502539\n",
      "2019-08-10 16:23:12,515 epoch 6 - iter 270/277 - loss 0.01436843\n",
      "2019-08-10 16:23:14,409 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:23:14,412 EPOCH 6 done: loss 0.0141 - lr 0.2000 - bad epochs 1\n",
      "2019-08-10 16:23:23,411 DEV : loss 0.045948415994644165 - score 0.9874\n",
      "2019-08-10 16:23:23,414 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:23:25,192 epoch 7 - iter 0/277 - loss 0.01488183\n",
      "2019-08-10 16:23:31,839 epoch 7 - iter 27/277 - loss 0.00891840\n",
      "2019-08-10 16:23:38,264 epoch 7 - iter 54/277 - loss 0.00554591\n",
      "2019-08-10 16:23:44,495 epoch 7 - iter 81/277 - loss 0.00920811\n",
      "2019-08-10 16:23:50,735 epoch 7 - iter 108/277 - loss 0.00731275\n",
      "2019-08-10 16:23:57,324 epoch 7 - iter 135/277 - loss 0.00611227\n",
      "2019-08-10 16:24:03,742 epoch 7 - iter 162/277 - loss 0.00541987\n",
      "2019-08-10 16:24:10,162 epoch 7 - iter 189/277 - loss 0.00490323\n",
      "2019-08-10 16:24:16,429 epoch 7 - iter 216/277 - loss 0.00445923\n",
      "2019-08-10 16:24:22,531 epoch 7 - iter 243/277 - loss 0.00427234\n",
      "2019-08-10 16:24:28,914 epoch 7 - iter 270/277 - loss 0.00442258\n",
      "2019-08-10 16:24:30,943 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:24:30,946 EPOCH 7 done: loss 0.0066 - lr 0.2000 - bad epochs 2\n",
      "2019-08-10 16:24:40,049 DEV : loss 0.051515132188797 - score 0.9784\n",
      "2019-08-10 16:24:40,052 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:24:41,875 epoch 8 - iter 0/277 - loss 0.00007187\n",
      "2019-08-10 16:24:48,100 epoch 8 - iter 27/277 - loss 0.03067729\n",
      "2019-08-10 16:24:54,408 epoch 8 - iter 54/277 - loss 0.01931658\n",
      "2019-08-10 16:25:00,994 epoch 8 - iter 81/277 - loss 0.01357666\n",
      "2019-08-10 16:25:10,089 epoch 8 - iter 108/277 - loss 0.01042780\n",
      "2019-08-10 16:25:16,553 epoch 8 - iter 135/277 - loss 0.00964130\n",
      "2019-08-10 16:25:22,775 epoch 8 - iter 162/277 - loss 0.00823126\n",
      "2019-08-10 16:25:29,134 epoch 8 - iter 189/277 - loss 0.00721076\n",
      "2019-08-10 16:25:35,428 epoch 8 - iter 216/277 - loss 0.00654548\n",
      "2019-08-10 16:25:41,576 epoch 8 - iter 243/277 - loss 0.00602814\n",
      "2019-08-10 16:25:47,704 epoch 8 - iter 270/277 - loss 0.00563348\n",
      "2019-08-10 16:25:49,773 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:25:49,776 EPOCH 8 done: loss 0.0062 - lr 0.2000 - bad epochs 3\n",
      "2019-08-10 16:25:58,838 DEV : loss 0.0469624288380146 - score 0.9838\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-01.\n",
      "  0%|          | 0/10 [23:37<?, ?it/s, best loss: ?]2019-08-10 16:25:58,848 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:26:00,552 epoch 9 - iter 0/277 - loss 0.00035888\n",
      "2019-08-10 16:26:06,912 epoch 9 - iter 27/277 - loss 0.00107597\n",
      "2019-08-10 16:26:13,417 epoch 9 - iter 54/277 - loss 0.00125543\n",
      "2019-08-10 16:26:19,950 epoch 9 - iter 81/277 - loss 0.00116626\n",
      "2019-08-10 16:26:26,384 epoch 9 - iter 108/277 - loss 0.00099550\n",
      "2019-08-10 16:26:32,519 epoch 9 - iter 135/277 - loss 0.00097831\n",
      "2019-08-10 16:26:38,987 epoch 9 - iter 162/277 - loss 0.00093140\n",
      "2019-08-10 16:26:45,265 epoch 9 - iter 189/277 - loss 0.00085903\n",
      "2019-08-10 16:26:51,614 epoch 9 - iter 216/277 - loss 0.00086239\n",
      "2019-08-10 16:26:58,141 epoch 9 - iter 243/277 - loss 0.00082350\n",
      "2019-08-10 16:27:06,905 epoch 9 - iter 270/277 - loss 0.00084675\n",
      "2019-08-10 16:27:08,846 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:27:08,848 EPOCH 9 done: loss 0.0008 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 16:27:17,853 DEV : loss 0.04751655459403992 - score 0.9856\n",
      "2019-08-10 16:27:17,856 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:27:19,589 epoch 10 - iter 0/277 - loss 0.00089291\n",
      "2019-08-10 16:27:26,305 epoch 10 - iter 27/277 - loss 0.00070754\n",
      "2019-08-10 16:27:32,577 epoch 10 - iter 54/277 - loss 0.00067936\n",
      "2019-08-10 16:27:38,771 epoch 10 - iter 81/277 - loss 0.00055322\n",
      "2019-08-10 16:27:44,926 epoch 10 - iter 108/277 - loss 0.00051603\n",
      "2019-08-10 16:27:51,529 epoch 10 - iter 135/277 - loss 0.00045345\n",
      "2019-08-10 16:27:58,040 epoch 10 - iter 162/277 - loss 0.00043065\n",
      "2019-08-10 16:28:04,209 epoch 10 - iter 189/277 - loss 0.00039017\n",
      "2019-08-10 16:28:10,555 epoch 10 - iter 216/277 - loss 0.00037751\n",
      "2019-08-10 16:28:16,928 epoch 10 - iter 243/277 - loss 0.00053868\n",
      "2019-08-10 16:28:23,560 epoch 10 - iter 270/277 - loss 0.00051817\n",
      "2019-08-10 16:28:25,611 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:28:25,613 EPOCH 10 done: loss 0.0005 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 16:28:34,730 DEV : loss 0.048209089785814285 - score 0.9838\n",
      "2019-08-10 16:28:34,733 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:28:34,736 Testing using best model ...\n",
      "2019-08-10 16:28:43,763 0.9856\t0.9856\t0.9856\n",
      "2019-08-10 16:28:43,766 \n",
      "MICRO_AVG: acc 0.9716 - f1-score 0.9856\n",
      "MACRO_AVG: acc 0.9411 - f1-score 0.96915\n",
      "ham        tp: 476 - fp: 5 - fn: 3 - tn: 71 - precision: 0.9896 - recall: 0.9937 - accuracy: 0.9835 - f1-score: 0.9916\n",
      "spam       tp: 71 - fp: 3 - fn: 5 - tn: 476 - precision: 0.9595 - recall: 0.9342 - accuracy: 0.8987 - f1-score: 0.9467\n",
      "2019-08-10 16:28:43,769 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:28:43,772 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:28:43,773 Training run: 3\n",
      "2019-08-10 16:28:44,094 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:28:44,097 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 16:28:45,181 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:28:46,942 epoch 1 - iter 0/277 - loss 0.71763790\n",
      "2019-08-10 16:28:53,500 epoch 1 - iter 27/277 - loss 0.20411338\n",
      "2019-08-10 16:29:00,069 epoch 1 - iter 54/277 - loss 0.13821679\n",
      "2019-08-10 16:29:09,230 epoch 1 - iter 81/277 - loss 0.11595375\n",
      "2019-08-10 16:29:15,412 epoch 1 - iter 108/277 - loss 0.10942089\n",
      "2019-08-10 16:29:21,511 epoch 1 - iter 135/277 - loss 0.09680365\n",
      "2019-08-10 16:29:27,910 epoch 1 - iter 162/277 - loss 0.09382480\n",
      "2019-08-10 16:29:34,228 epoch 1 - iter 189/277 - loss 0.09513338\n",
      "2019-08-10 16:29:40,694 epoch 1 - iter 216/277 - loss 0.08969676\n",
      "2019-08-10 16:29:47,062 epoch 1 - iter 243/277 - loss 0.08310429\n",
      "2019-08-10 16:29:53,559 epoch 1 - iter 270/277 - loss 0.07876559\n",
      "2019-08-10 16:29:55,525 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:29:55,528 EPOCH 1 done: loss 0.0785 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 16:30:04,683 DEV : loss 0.05052418261766434 - score 0.9856\n",
      "2019-08-10 16:30:04,687 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:30:06,553 epoch 2 - iter 0/277 - loss 0.00565963\n",
      "2019-08-10 16:30:12,994 epoch 2 - iter 27/277 - loss 0.04691543\n",
      "2019-08-10 16:30:19,419 epoch 2 - iter 54/277 - loss 0.06023648\n",
      "2019-08-10 16:30:25,948 epoch 2 - iter 81/277 - loss 0.05225032\n",
      "2019-08-10 16:30:32,680 epoch 2 - iter 108/277 - loss 0.05137263\n",
      "2019-08-10 16:30:38,868 epoch 2 - iter 135/277 - loss 0.04530886\n",
      "2019-08-10 16:30:45,178 epoch 2 - iter 162/277 - loss 0.04892439\n",
      "2019-08-10 16:30:51,447 epoch 2 - iter 189/277 - loss 0.04491932\n",
      "2019-08-10 16:30:58,042 epoch 2 - iter 216/277 - loss 0.04034076\n",
      "2019-08-10 16:31:06,868 epoch 2 - iter 243/277 - loss 0.03941004\n",
      "2019-08-10 16:31:13,100 epoch 2 - iter 270/277 - loss 0.04057975\n",
      "2019-08-10 16:31:15,030 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:31:15,033 EPOCH 2 done: loss 0.0398 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 16:31:24,082 DEV : loss 0.04621409997344017 - score 0.9856\n",
      "2019-08-10 16:31:24,085 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:31:25,755 epoch 3 - iter 0/277 - loss 0.29246497\n",
      "2019-08-10 16:31:32,262 epoch 3 - iter 27/277 - loss 0.02855040\n",
      "2019-08-10 16:31:38,667 epoch 3 - iter 54/277 - loss 0.01738491\n",
      "2019-08-10 16:31:45,085 epoch 3 - iter 81/277 - loss 0.02286097\n",
      "2019-08-10 16:31:51,564 epoch 3 - iter 108/277 - loss 0.02175736\n",
      "2019-08-10 16:31:57,952 epoch 3 - iter 135/277 - loss 0.02544156\n",
      "2019-08-10 16:32:04,811 epoch 3 - iter 162/277 - loss 0.03118337\n",
      "2019-08-10 16:32:11,096 epoch 3 - iter 189/277 - loss 0.02949558\n",
      "2019-08-10 16:32:17,344 epoch 3 - iter 216/277 - loss 0.03179379\n",
      "2019-08-10 16:32:23,942 epoch 3 - iter 243/277 - loss 0.03458857\n",
      "2019-08-10 16:32:30,448 epoch 3 - iter 270/277 - loss 0.03519116\n",
      "2019-08-10 16:32:32,341 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:32:32,344 EPOCH 3 done: loss 0.0346 - lr 0.2000 - bad epochs 1\n",
      "2019-08-10 16:32:41,464 DEV : loss 0.058653444051742554 - score 0.982\n",
      "2019-08-10 16:32:41,468 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:32:43,205 epoch 4 - iter 0/277 - loss 0.19109915\n",
      "2019-08-10 16:32:49,659 epoch 4 - iter 27/277 - loss 0.04411712\n",
      "2019-08-10 16:32:55,865 epoch 4 - iter 54/277 - loss 0.03526044\n",
      "2019-08-10 16:33:05,049 epoch 4 - iter 81/277 - loss 0.02553264\n",
      "2019-08-10 16:33:11,365 epoch 4 - iter 108/277 - loss 0.02479264\n",
      "2019-08-10 16:33:18,039 epoch 4 - iter 135/277 - loss 0.02394313\n",
      "2019-08-10 16:33:24,280 epoch 4 - iter 162/277 - loss 0.02547575\n",
      "2019-08-10 16:33:30,479 epoch 4 - iter 189/277 - loss 0.02287199\n",
      "2019-08-10 16:33:36,784 epoch 4 - iter 216/277 - loss 0.02163539\n",
      "2019-08-10 16:33:42,940 epoch 4 - iter 243/277 - loss 0.02231520\n",
      "2019-08-10 16:33:49,292 epoch 4 - iter 270/277 - loss 0.02379998\n",
      "2019-08-10 16:33:51,208 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:33:51,210 EPOCH 4 done: loss 0.0235 - lr 0.2000 - bad epochs 2\n",
      "2019-08-10 16:34:00,346 DEV : loss 0.041200555860996246 - score 0.9838\n",
      "2019-08-10 16:34:00,349 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:34:02,193 epoch 5 - iter 0/277 - loss 0.00073572\n",
      "2019-08-10 16:34:08,702 epoch 5 - iter 27/277 - loss 0.01712603\n",
      "2019-08-10 16:34:14,990 epoch 5 - iter 54/277 - loss 0.01162796\n",
      "2019-08-10 16:34:21,388 epoch 5 - iter 81/277 - loss 0.01105832\n",
      "2019-08-10 16:34:27,957 epoch 5 - iter 108/277 - loss 0.01125233\n",
      "2019-08-10 16:34:34,341 epoch 5 - iter 135/277 - loss 0.01314561\n",
      "2019-08-10 16:34:40,720 epoch 5 - iter 162/277 - loss 0.01155396\n",
      "2019-08-10 16:34:47,175 epoch 5 - iter 189/277 - loss 0.01270612\n",
      "2019-08-10 16:34:53,370 epoch 5 - iter 216/277 - loss 0.01264666\n",
      "2019-08-10 16:35:02,194 epoch 5 - iter 243/277 - loss 0.01373061\n",
      "2019-08-10 16:35:08,564 epoch 5 - iter 270/277 - loss 0.01471801\n",
      "2019-08-10 16:35:10,486 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:35:10,489 EPOCH 5 done: loss 0.0164 - lr 0.2000 - bad epochs 3\n",
      "2019-08-10 16:35:19,574 DEV : loss 0.878547191619873 - score 0.7135\n",
      "Epoch     4: reducing learning rate of group 0 to 1.0000e-01.\n",
      "  0%|          | 0/10 [32:58<?, ?it/s, best loss: ?]2019-08-10 16:35:19,584 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:35:21,383 epoch 6 - iter 0/277 - loss 0.51729608\n",
      "2019-08-10 16:35:27,842 epoch 6 - iter 27/277 - loss 0.03646872\n",
      "2019-08-10 16:35:33,952 epoch 6 - iter 54/277 - loss 0.02050135\n",
      "2019-08-10 16:35:40,229 epoch 6 - iter 81/277 - loss 0.01845346\n",
      "2019-08-10 16:35:46,341 epoch 6 - iter 108/277 - loss 0.01531943\n",
      "2019-08-10 16:35:52,822 epoch 6 - iter 135/277 - loss 0.01400972\n",
      "2019-08-10 16:35:59,258 epoch 6 - iter 162/277 - loss 0.01208186\n",
      "2019-08-10 16:36:06,058 epoch 6 - iter 189/277 - loss 0.01077988\n",
      "2019-08-10 16:36:12,550 epoch 6 - iter 216/277 - loss 0.01114252\n",
      "2019-08-10 16:36:18,928 epoch 6 - iter 243/277 - loss 0.01023965\n",
      "2019-08-10 16:36:25,350 epoch 6 - iter 270/277 - loss 0.01026910\n",
      "2019-08-10 16:36:27,201 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:36:27,206 EPOCH 6 done: loss 0.0102 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 16:36:36,381 DEV : loss 0.04331430792808533 - score 0.9892\n",
      "2019-08-10 16:36:36,384 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:36:38,150 epoch 7 - iter 0/277 - loss 0.00008619\n",
      "2019-08-10 16:36:44,623 epoch 7 - iter 27/277 - loss 0.00174460\n",
      "2019-08-10 16:36:50,961 epoch 7 - iter 54/277 - loss 0.00207200\n",
      "2019-08-10 16:37:00,332 epoch 7 - iter 81/277 - loss 0.00238159\n",
      "2019-08-10 16:37:06,773 epoch 7 - iter 108/277 - loss 0.00249216\n",
      "2019-08-10 16:37:12,993 epoch 7 - iter 135/277 - loss 0.00623193\n",
      "2019-08-10 16:37:19,398 epoch 7 - iter 162/277 - loss 0.00546797\n",
      "2019-08-10 16:37:25,885 epoch 7 - iter 189/277 - loss 0.00487248\n",
      "2019-08-10 16:37:32,308 epoch 7 - iter 216/277 - loss 0.00455309\n",
      "2019-08-10 16:37:38,418 epoch 7 - iter 243/277 - loss 0.00539895\n",
      "2019-08-10 16:37:44,775 epoch 7 - iter 270/277 - loss 0.00577727\n",
      "2019-08-10 16:37:46,757 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:37:46,760 EPOCH 7 done: loss 0.0057 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 16:37:55,843 DEV : loss 0.04047045111656189 - score 0.9856\n",
      "2019-08-10 16:37:55,846 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:37:57,566 epoch 8 - iter 0/277 - loss 0.00400721\n",
      "2019-08-10 16:38:04,054 epoch 8 - iter 27/277 - loss 0.00176477\n",
      "2019-08-10 16:38:10,373 epoch 8 - iter 54/277 - loss 0.00212239\n",
      "2019-08-10 16:38:16,811 epoch 8 - iter 81/277 - loss 0.00203922\n",
      "2019-08-10 16:38:23,037 epoch 8 - iter 108/277 - loss 0.00181042\n",
      "2019-08-10 16:38:29,574 epoch 8 - iter 135/277 - loss 0.00165409\n",
      "2019-08-10 16:38:35,938 epoch 8 - iter 162/277 - loss 0.00165345\n",
      "2019-08-10 16:38:42,055 epoch 8 - iter 189/277 - loss 0.00153866\n",
      "2019-08-10 16:38:48,527 epoch 8 - iter 216/277 - loss 0.00373430\n",
      "2019-08-10 16:38:57,138 epoch 8 - iter 243/277 - loss 0.00353327\n",
      "2019-08-10 16:39:03,330 epoch 8 - iter 270/277 - loss 0.00336544\n",
      "2019-08-10 16:39:05,218 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:39:05,222 EPOCH 8 done: loss 0.0033 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 16:39:14,259 DEV : loss 0.044443320482969284 - score 0.9856\n",
      "2019-08-10 16:39:14,262 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:39:16,159 epoch 9 - iter 0/277 - loss 0.00062400\n",
      "2019-08-10 16:39:22,449 epoch 9 - iter 27/277 - loss 0.00188419\n",
      "2019-08-10 16:39:28,843 epoch 9 - iter 54/277 - loss 0.00155723\n",
      "2019-08-10 16:39:35,318 epoch 9 - iter 81/277 - loss 0.00186367\n",
      "2019-08-10 16:39:41,908 epoch 9 - iter 108/277 - loss 0.00164937\n",
      "2019-08-10 16:39:48,235 epoch 9 - iter 135/277 - loss 0.00263577\n",
      "2019-08-10 16:39:54,584 epoch 9 - iter 162/277 - loss 0.00231325\n",
      "2019-08-10 16:40:01,045 epoch 9 - iter 189/277 - loss 0.00261425\n",
      "2019-08-10 16:40:07,325 epoch 9 - iter 216/277 - loss 0.00237875\n",
      "2019-08-10 16:40:13,560 epoch 9 - iter 243/277 - loss 0.00217545\n",
      "2019-08-10 16:40:19,912 epoch 9 - iter 270/277 - loss 0.00207247\n",
      "2019-08-10 16:40:21,886 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:40:21,889 EPOCH 9 done: loss 0.0020 - lr 0.1000 - bad epochs 2\n",
      "2019-08-10 16:40:31,035 DEV : loss 0.04625849798321724 - score 0.9838\n",
      "2019-08-10 16:40:31,038 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:40:32,728 epoch 10 - iter 0/277 - loss 0.00537479\n",
      "2019-08-10 16:40:39,186 epoch 10 - iter 27/277 - loss 0.00134488\n",
      "2019-08-10 16:40:45,382 epoch 10 - iter 54/277 - loss 0.00108924\n",
      "2019-08-10 16:40:51,781 epoch 10 - iter 81/277 - loss 0.00088344\n",
      "2019-08-10 16:41:00,913 epoch 10 - iter 108/277 - loss 0.00092437\n",
      "2019-08-10 16:41:07,312 epoch 10 - iter 135/277 - loss 0.00093156\n",
      "2019-08-10 16:41:13,774 epoch 10 - iter 162/277 - loss 0.00088208\n",
      "2019-08-10 16:41:20,139 epoch 10 - iter 189/277 - loss 0.00079642\n",
      "2019-08-10 16:41:26,610 epoch 10 - iter 216/277 - loss 0.00074845\n",
      "2019-08-10 16:41:32,843 epoch 10 - iter 243/277 - loss 0.00069508\n",
      "2019-08-10 16:41:39,109 epoch 10 - iter 270/277 - loss 0.00078869\n",
      "2019-08-10 16:41:40,991 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:41:40,993 EPOCH 10 done: loss 0.0008 - lr 0.1000 - bad epochs 3\n",
      "2019-08-10 16:41:50,144 DEV : loss 0.05087798088788986 - score 0.982\n",
      "Epoch     9: reducing learning rate of group 0 to 5.0000e-02.\n",
      "  0%|          | 0/10 [39:28<?, ?it/s, best loss: ?]2019-08-10 16:41:50,154 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:41:50,156 Testing using best model ...\n",
      "2019-08-10 16:41:59,269 0.9856\t0.9856\t0.9856\n",
      "2019-08-10 16:41:59,272 \n",
      "MICRO_AVG: acc 0.9716 - f1-score 0.9856\n",
      "MACRO_AVG: acc 0.9417 - f1-score 0.9695\n",
      "ham        tp: 475 - fp: 4 - fn: 4 - tn: 72 - precision: 0.9916 - recall: 0.9916 - accuracy: 0.9834 - f1-score: 0.9916\n",
      "spam       tp: 72 - fp: 4 - fn: 4 - tn: 475 - precision: 0.9474 - recall: 0.9474 - accuracy: 0.9000 - f1-score: 0.9474\n",
      "2019-08-10 16:41:59,275 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:41:59,279 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:41:59,280 Done evaluating parameter combination:\n",
      "2019-08-10 16:41:59,284 \tdropout: 0.10426696339723916\n",
      "2019-08-10 16:41:59,287 \tembeddings: /tmp/.flair/embeddings/news-forward-0.4.1.pt,/tmp/.flair/embeddings/news-backward-0.4.1.pt\n",
      "2019-08-10 16:41:59,290 \thidden_size: 128\n",
      "2019-08-10 16:41:59,292 \tlearning_rate: 0.2\n",
      "2019-08-10 16:41:59,294 \tmini_batch_size: 16\n",
      "2019-08-10 16:41:59,296 \trnn_layers: 2\n",
      "2019-08-10 16:41:59,299 score: 0.015599999999999984\n",
      "2019-08-10 16:41:59,301 variance: 1.2000000000000317e-06\n",
      "2019-08-10 16:41:59,305 test_score: 0.9856\n",
      "\n",
      "2019-08-10 16:41:59,308 ----------------------------------------------------------------------------------------------------\n",
      " 10%|█         | 1/10 [39:37<5:56:40, 2377.79s/it, best loss: 0.015599999999999984]2019-08-10 16:41:59,324 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:41:59,326 Evaluation run: 2\n",
      "2019-08-10 16:41:59,330 Evaluating parameter combination:\n",
      "2019-08-10 16:41:59,335 \tdropout: 0.22162824904388523\n",
      "2019-08-10 16:41:59,336 \tembeddings: /tmp/.flair/embeddings/news-forward-0.4.1.pt,/tmp/.flair/embeddings/news-backward-0.4.1.pt\n",
      "2019-08-10 16:41:59,339 \thidden_size: 128\n",
      "2019-08-10 16:41:59,344 \tlearning_rate: 0.1\n",
      "2019-08-10 16:41:59,346 \tmini_batch_size: 16\n",
      "2019-08-10 16:41:59,349 \trnn_layers: 2\n",
      "2019-08-10 16:41:59,351 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:42:02,083 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:42:02,085 Training run: 1\n",
      "2019-08-10 16:42:02,402 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:42:02,405 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 16:42:03,420 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:42:05,155 epoch 1 - iter 0/277 - loss 0.92233896\n",
      "2019-08-10 16:42:11,730 epoch 1 - iter 27/277 - loss 0.25164709\n",
      "2019-08-10 16:42:18,277 epoch 1 - iter 54/277 - loss 0.15852362\n",
      "2019-08-10 16:42:24,763 epoch 1 - iter 81/277 - loss 0.11850423\n",
      "2019-08-10 16:42:31,148 epoch 1 - iter 108/277 - loss 0.11240492\n",
      "2019-08-10 16:42:37,986 epoch 1 - iter 135/277 - loss 0.10665742\n",
      "2019-08-10 16:42:44,200 epoch 1 - iter 162/277 - loss 0.09394818\n",
      "2019-08-10 16:42:50,374 epoch 1 - iter 189/277 - loss 0.09297826\n",
      "2019-08-10 16:42:59,186 epoch 1 - iter 216/277 - loss 0.09051073\n",
      "2019-08-10 16:43:05,362 epoch 1 - iter 243/277 - loss 0.08273960\n",
      "2019-08-10 16:43:11,525 epoch 1 - iter 270/277 - loss 0.07992881\n",
      "2019-08-10 16:43:13,528 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:43:13,533 EPOCH 1 done: loss 0.0786 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 16:43:22,559 DEV : loss 0.04544086009263992 - score 0.9838\n",
      "2019-08-10 16:43:22,564 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:43:24,221 epoch 2 - iter 0/277 - loss 0.00739335\n",
      "2019-08-10 16:43:30,858 epoch 2 - iter 27/277 - loss 0.05329589\n",
      "2019-08-10 16:43:37,124 epoch 2 - iter 54/277 - loss 0.03351922\n",
      "2019-08-10 16:43:43,521 epoch 2 - iter 81/277 - loss 0.04220551\n",
      "2019-08-10 16:43:49,727 epoch 2 - iter 108/277 - loss 0.04142628\n",
      "2019-08-10 16:43:56,089 epoch 2 - iter 135/277 - loss 0.03976130\n",
      "2019-08-10 16:44:02,724 epoch 2 - iter 162/277 - loss 0.03803541\n",
      "2019-08-10 16:44:09,299 epoch 2 - iter 189/277 - loss 0.04280523\n",
      "2019-08-10 16:44:15,679 epoch 2 - iter 216/277 - loss 0.04236256\n",
      "2019-08-10 16:44:21,963 epoch 2 - iter 243/277 - loss 0.04001217\n",
      "2019-08-10 16:44:28,051 epoch 2 - iter 270/277 - loss 0.04224884\n",
      "2019-08-10 16:44:30,030 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:44:30,035 EPOCH 2 done: loss 0.0419 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 16:44:39,138 DEV : loss 0.04518008977174759 - score 0.9892\n",
      "2019-08-10 16:44:39,141 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:44:40,798 epoch 3 - iter 0/277 - loss 0.00078620\n",
      "2019-08-10 16:44:47,113 epoch 3 - iter 27/277 - loss 0.03052398\n",
      "2019-08-10 16:44:53,373 epoch 3 - iter 54/277 - loss 0.03167309\n",
      "2019-08-10 16:45:02,778 epoch 3 - iter 81/277 - loss 0.02881630\n",
      "2019-08-10 16:45:09,081 epoch 3 - iter 108/277 - loss 0.02360203\n",
      "2019-08-10 16:45:15,257 epoch 3 - iter 135/277 - loss 0.02762600\n",
      "2019-08-10 16:45:21,701 epoch 3 - iter 162/277 - loss 0.02844130\n",
      "2019-08-10 16:45:28,016 epoch 3 - iter 189/277 - loss 0.03746305\n",
      "2019-08-10 16:45:34,482 epoch 3 - iter 216/277 - loss 0.03974845\n",
      "2019-08-10 16:45:40,604 epoch 3 - iter 243/277 - loss 0.03671172\n",
      "2019-08-10 16:45:46,784 epoch 3 - iter 270/277 - loss 0.03514622\n",
      "2019-08-10 16:45:48,693 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:45:48,702 EPOCH 3 done: loss 0.0364 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 16:45:57,846 DEV : loss 0.28678226470947266 - score 0.8901\n",
      "2019-08-10 16:45:57,849 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:45:59,779 epoch 4 - iter 0/277 - loss 0.24199937\n",
      "2019-08-10 16:46:06,254 epoch 4 - iter 27/277 - loss 0.05814489\n",
      "2019-08-10 16:46:12,504 epoch 4 - iter 54/277 - loss 0.03784961\n",
      "2019-08-10 16:46:19,175 epoch 4 - iter 81/277 - loss 0.03392316\n",
      "2019-08-10 16:46:25,639 epoch 4 - iter 108/277 - loss 0.02825976\n",
      "2019-08-10 16:46:32,023 epoch 4 - iter 135/277 - loss 0.02733856\n",
      "2019-08-10 16:46:38,218 epoch 4 - iter 162/277 - loss 0.02781173\n",
      "2019-08-10 16:46:44,517 epoch 4 - iter 189/277 - loss 0.02887670\n",
      "2019-08-10 16:46:53,282 epoch 4 - iter 216/277 - loss 0.02729876\n",
      "2019-08-10 16:46:59,613 epoch 4 - iter 243/277 - loss 0.02581198\n",
      "2019-08-10 16:47:05,906 epoch 4 - iter 270/277 - loss 0.02623790\n",
      "2019-08-10 16:47:07,810 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:47:07,813 EPOCH 4 done: loss 0.0257 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 16:47:17,047 DEV : loss 0.044554632157087326 - score 0.9838\n",
      "2019-08-10 16:47:17,050 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:47:18,740 epoch 5 - iter 0/277 - loss 0.03223051\n",
      "2019-08-10 16:47:25,279 epoch 5 - iter 27/277 - loss 0.02810812\n",
      "2019-08-10 16:47:31,509 epoch 5 - iter 54/277 - loss 0.01906722\n",
      "2019-08-10 16:47:37,927 epoch 5 - iter 81/277 - loss 0.01926675\n",
      "2019-08-10 16:47:44,479 epoch 5 - iter 108/277 - loss 0.01957084\n",
      "2019-08-10 16:47:50,596 epoch 5 - iter 135/277 - loss 0.01724428\n",
      "2019-08-10 16:47:56,952 epoch 5 - iter 162/277 - loss 0.01627123\n",
      "2019-08-10 16:48:03,558 epoch 5 - iter 189/277 - loss 0.01752843\n",
      "2019-08-10 16:48:09,755 epoch 5 - iter 216/277 - loss 0.01855426\n",
      "2019-08-10 16:48:16,034 epoch 5 - iter 243/277 - loss 0.01862000\n",
      "2019-08-10 16:48:22,140 epoch 5 - iter 270/277 - loss 0.02216887\n",
      "2019-08-10 16:48:24,183 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:48:24,188 EPOCH 5 done: loss 0.0223 - lr 0.1000 - bad epochs 2\n",
      "2019-08-10 16:48:33,367 DEV : loss 0.04898973926901817 - score 0.9838\n",
      "2019-08-10 16:48:33,370 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:48:35,212 epoch 6 - iter 0/277 - loss 0.02766920\n",
      "2019-08-10 16:48:41,809 epoch 6 - iter 27/277 - loss 0.01679398\n",
      "2019-08-10 16:48:47,812 epoch 6 - iter 54/277 - loss 0.01085592\n",
      "2019-08-10 16:48:57,062 epoch 6 - iter 81/277 - loss 0.01180789\n",
      "2019-08-10 16:49:03,221 epoch 6 - iter 108/277 - loss 0.00967910\n",
      "2019-08-10 16:49:09,350 epoch 6 - iter 135/277 - loss 0.00856579\n",
      "2019-08-10 16:49:15,485 epoch 6 - iter 162/277 - loss 0.01648545\n",
      "2019-08-10 16:49:21,979 epoch 6 - iter 189/277 - loss 0.02208811\n",
      "2019-08-10 16:49:28,260 epoch 6 - iter 216/277 - loss 0.02252073\n",
      "2019-08-10 16:49:34,696 epoch 6 - iter 243/277 - loss 0.02075503\n",
      "2019-08-10 16:49:41,043 epoch 6 - iter 270/277 - loss 0.01981777\n",
      "2019-08-10 16:49:42,926 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:49:42,928 EPOCH 6 done: loss 0.0194 - lr 0.1000 - bad epochs 3\n",
      "2019-08-10 16:49:51,996 DEV : loss 0.03490836173295975 - score 0.9892\n",
      "Epoch     5: reducing learning rate of group 0 to 5.0000e-02.                      \n",
      " 10%|█         | 1/10 [47:30<5:56:40, 2377.79s/it, best loss: 0.015599999999999984]2019-08-10 16:49:52,006 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:49:53,687 epoch 7 - iter 0/277 - loss 0.00247687\n",
      "2019-08-10 16:50:00,091 epoch 7 - iter 27/277 - loss 0.00562297\n",
      "2019-08-10 16:50:06,370 epoch 7 - iter 54/277 - loss 0.01133790\n",
      "2019-08-10 16:50:12,663 epoch 7 - iter 81/277 - loss 0.01218193\n",
      "2019-08-10 16:50:19,205 epoch 7 - iter 108/277 - loss 0.00976027\n",
      "2019-08-10 16:50:25,552 epoch 7 - iter 135/277 - loss 0.01057131\n",
      "2019-08-10 16:50:31,901 epoch 7 - iter 162/277 - loss 0.00915797\n",
      "2019-08-10 16:50:38,382 epoch 7 - iter 189/277 - loss 0.00853019\n",
      "2019-08-10 16:50:47,279 epoch 7 - iter 216/277 - loss 0.00812407\n",
      "2019-08-10 16:50:53,601 epoch 7 - iter 243/277 - loss 0.00792919\n",
      "2019-08-10 16:50:59,593 epoch 7 - iter 270/277 - loss 0.00832013\n",
      "2019-08-10 16:51:01,606 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:51:01,608 EPOCH 7 done: loss 0.0082 - lr 0.0500 - bad epochs 0\n",
      "2019-08-10 16:51:10,603 DEV : loss 0.04098188132047653 - score 0.9874\n",
      "2019-08-10 16:51:10,606 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:51:12,277 epoch 8 - iter 0/277 - loss 0.00232244\n",
      "2019-08-10 16:51:18,439 epoch 8 - iter 27/277 - loss 0.01122418\n",
      "2019-08-10 16:51:24,613 epoch 8 - iter 54/277 - loss 0.00736256\n",
      "2019-08-10 16:51:31,041 epoch 8 - iter 81/277 - loss 0.00562126\n",
      "2019-08-10 16:51:37,450 epoch 8 - iter 108/277 - loss 0.00636318\n",
      "2019-08-10 16:51:43,870 epoch 8 - iter 135/277 - loss 0.00567964\n",
      "2019-08-10 16:51:50,270 epoch 8 - iter 162/277 - loss 0.00614365\n",
      "2019-08-10 16:51:56,835 epoch 8 - iter 189/277 - loss 0.00607179\n",
      "2019-08-10 16:52:03,167 epoch 8 - iter 216/277 - loss 0.00564158\n",
      "2019-08-10 16:52:09,438 epoch 8 - iter 243/277 - loss 0.00537500\n",
      "2019-08-10 16:52:15,896 epoch 8 - iter 270/277 - loss 0.00496648\n",
      "2019-08-10 16:52:17,948 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:52:17,951 EPOCH 8 done: loss 0.0049 - lr 0.0500 - bad epochs 1\n",
      "2019-08-10 16:52:27,098 DEV : loss 0.04429030790925026 - score 0.9856\n",
      "2019-08-10 16:52:27,101 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:52:28,880 epoch 9 - iter 0/277 - loss 0.00112972\n",
      "2019-08-10 16:52:35,363 epoch 9 - iter 27/277 - loss 0.00178460\n",
      "2019-08-10 16:52:41,580 epoch 9 - iter 54/277 - loss 0.00400844\n",
      "2019-08-10 16:52:50,838 epoch 9 - iter 81/277 - loss 0.00459398\n",
      "2019-08-10 16:52:57,116 epoch 9 - iter 108/277 - loss 0.00454490\n",
      "2019-08-10 16:53:03,460 epoch 9 - iter 135/277 - loss 0.00411819\n",
      "2019-08-10 16:53:09,746 epoch 9 - iter 162/277 - loss 0.00357988\n",
      "2019-08-10 16:53:16,267 epoch 9 - iter 189/277 - loss 0.00408117\n",
      "2019-08-10 16:53:22,357 epoch 9 - iter 216/277 - loss 0.00371502\n",
      "2019-08-10 16:53:28,832 epoch 9 - iter 243/277 - loss 0.00354445\n",
      "2019-08-10 16:53:35,063 epoch 9 - iter 270/277 - loss 0.00330835\n",
      "2019-08-10 16:53:37,091 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:53:37,094 EPOCH 9 done: loss 0.0032 - lr 0.0500 - bad epochs 2\n",
      "2019-08-10 16:53:46,095 DEV : loss 0.047494128346443176 - score 0.9856\n",
      "2019-08-10 16:53:46,099 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:53:47,771 epoch 10 - iter 0/277 - loss 0.00018954\n",
      "2019-08-10 16:53:54,151 epoch 10 - iter 27/277 - loss 0.00167433\n",
      "2019-08-10 16:54:00,773 epoch 10 - iter 54/277 - loss 0.00132362\n",
      "2019-08-10 16:54:07,233 epoch 10 - iter 81/277 - loss 0.00129789\n",
      "2019-08-10 16:54:13,501 epoch 10 - iter 108/277 - loss 0.00128258\n",
      "2019-08-10 16:54:19,733 epoch 10 - iter 135/277 - loss 0.00141397\n",
      "2019-08-10 16:54:26,200 epoch 10 - iter 162/277 - loss 0.00145528\n",
      "2019-08-10 16:54:32,400 epoch 10 - iter 189/277 - loss 0.00140323\n",
      "2019-08-10 16:54:38,942 epoch 10 - iter 216/277 - loss 0.00136927\n",
      "2019-08-10 16:54:47,772 epoch 10 - iter 243/277 - loss 0.00145162\n",
      "2019-08-10 16:54:53,948 epoch 10 - iter 270/277 - loss 0.00157425\n",
      "2019-08-10 16:54:55,887 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:54:55,890 EPOCH 10 done: loss 0.0016 - lr 0.0500 - bad epochs 3\n",
      "2019-08-10 16:55:04,912 DEV : loss 0.047377027571201324 - score 0.9838\n",
      "Epoch     9: reducing learning rate of group 0 to 2.5000e-02.                      \n",
      " 10%|█         | 1/10 [52:43<5:56:40, 2377.79s/it, best loss: 0.015599999999999984]2019-08-10 16:55:04,921 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:55:04,922 Testing using best model ...\n",
      "2019-08-10 16:55:13,857 0.9856\t0.9856\t0.9856\n",
      "2019-08-10 16:55:13,861 \n",
      "MICRO_AVG: acc 0.9716 - f1-score 0.9856\n",
      "MACRO_AVG: acc 0.9417 - f1-score 0.9695\n",
      "ham        tp: 475 - fp: 4 - fn: 4 - tn: 72 - precision: 0.9916 - recall: 0.9916 - accuracy: 0.9834 - f1-score: 0.9916\n",
      "spam       tp: 72 - fp: 4 - fn: 4 - tn: 475 - precision: 0.9474 - recall: 0.9474 - accuracy: 0.9000 - f1-score: 0.9474\n",
      "2019-08-10 16:55:13,864 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:55:13,867 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:55:13,869 Training run: 2\n",
      "2019-08-10 16:55:14,191 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:55:14,193 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 16:55:15,237 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:55:17,022 epoch 1 - iter 0/277 - loss 0.72195745\n",
      "2019-08-10 16:55:23,501 epoch 1 - iter 27/277 - loss 0.18541871\n",
      "2019-08-10 16:55:29,947 epoch 1 - iter 54/277 - loss 0.11509116\n",
      "2019-08-10 16:55:36,371 epoch 1 - iter 81/277 - loss 0.10930208\n",
      "2019-08-10 16:55:42,642 epoch 1 - iter 108/277 - loss 0.10200934\n",
      "2019-08-10 16:55:48,938 epoch 1 - iter 135/277 - loss 0.09236857\n",
      "2019-08-10 16:55:55,220 epoch 1 - iter 162/277 - loss 0.09205040\n",
      "2019-08-10 16:56:01,504 epoch 1 - iter 189/277 - loss 0.08871377\n",
      "2019-08-10 16:56:07,944 epoch 1 - iter 216/277 - loss 0.08123359\n",
      "2019-08-10 16:56:14,505 epoch 1 - iter 243/277 - loss 0.08160429\n",
      "2019-08-10 16:56:20,955 epoch 1 - iter 270/277 - loss 0.07876991\n",
      "2019-08-10 16:56:22,905 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:56:22,907 EPOCH 1 done: loss 0.0778 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 16:56:32,064 DEV : loss 0.08888942003250122 - score 0.9712\n",
      "2019-08-10 16:56:32,067 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:56:33,842 epoch 2 - iter 0/277 - loss 0.00772581\n",
      "2019-08-10 16:56:40,468 epoch 2 - iter 27/277 - loss 0.05759496\n",
      "2019-08-10 16:56:49,479 epoch 2 - iter 54/277 - loss 0.04821202\n",
      "2019-08-10 16:56:55,867 epoch 2 - iter 81/277 - loss 0.05296955\n",
      "2019-08-10 16:57:02,245 epoch 2 - iter 108/277 - loss 0.05331313\n",
      "2019-08-10 16:57:08,207 epoch 2 - iter 135/277 - loss 0.04506380\n",
      "2019-08-10 16:57:14,858 epoch 2 - iter 162/277 - loss 0.04648541\n",
      "2019-08-10 16:57:21,296 epoch 2 - iter 189/277 - loss 0.04856862\n",
      "2019-08-10 16:57:27,471 epoch 2 - iter 216/277 - loss 0.04557142\n",
      "2019-08-10 16:57:33,749 epoch 2 - iter 243/277 - loss 0.04678448\n",
      "2019-08-10 16:57:40,043 epoch 2 - iter 270/277 - loss 0.04608844\n",
      "2019-08-10 16:57:41,977 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:57:41,979 EPOCH 2 done: loss 0.0452 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 16:57:51,148 DEV : loss 0.047239962965250015 - score 0.9838\n",
      "2019-08-10 16:57:51,151 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:57:52,946 epoch 3 - iter 0/277 - loss 0.02009688\n",
      "2019-08-10 16:57:59,340 epoch 3 - iter 27/277 - loss 0.02461014\n",
      "2019-08-10 16:58:05,817 epoch 3 - iter 54/277 - loss 0.02323677\n",
      "2019-08-10 16:58:12,315 epoch 3 - iter 81/277 - loss 0.01959198\n",
      "2019-08-10 16:58:18,924 epoch 3 - iter 108/277 - loss 0.02625678\n",
      "2019-08-10 16:58:25,197 epoch 3 - iter 135/277 - loss 0.03118389\n",
      "2019-08-10 16:58:31,745 epoch 3 - iter 162/277 - loss 0.03045137\n",
      "2019-08-10 16:58:37,974 epoch 3 - iter 189/277 - loss 0.02935036\n",
      "2019-08-10 16:58:47,007 epoch 3 - iter 216/277 - loss 0.03046441\n",
      "2019-08-10 16:58:53,313 epoch 3 - iter 243/277 - loss 0.03187998\n",
      "2019-08-10 16:58:59,357 epoch 3 - iter 270/277 - loss 0.03308068\n",
      "2019-08-10 16:59:01,246 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:59:01,249 EPOCH 3 done: loss 0.0324 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 16:59:10,314 DEV : loss 0.050018906593322754 - score 0.9838\n",
      "2019-08-10 16:59:10,317 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 16:59:12,109 epoch 4 - iter 0/277 - loss 0.00206821\n",
      "2019-08-10 16:59:18,628 epoch 4 - iter 27/277 - loss 0.02081994\n",
      "2019-08-10 16:59:24,826 epoch 4 - iter 54/277 - loss 0.01301728\n",
      "2019-08-10 16:59:31,019 epoch 4 - iter 81/277 - loss 0.01777086\n",
      "2019-08-10 16:59:37,379 epoch 4 - iter 108/277 - loss 0.02308451\n",
      "2019-08-10 16:59:43,982 epoch 4 - iter 135/277 - loss 0.02357298\n",
      "2019-08-10 16:59:50,230 epoch 4 - iter 162/277 - loss 0.02410597\n",
      "2019-08-10 16:59:56,559 epoch 4 - iter 189/277 - loss 0.02440826\n",
      "2019-08-10 17:00:03,069 epoch 4 - iter 216/277 - loss 0.02394297\n",
      "2019-08-10 17:00:09,544 epoch 4 - iter 243/277 - loss 0.02340947\n",
      "2019-08-10 17:00:15,910 epoch 4 - iter 270/277 - loss 0.02555483\n",
      "2019-08-10 17:00:17,890 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:00:17,895 EPOCH 4 done: loss 0.0264 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 17:00:27,086 DEV : loss 0.1187611073255539 - score 0.9532\n",
      "2019-08-10 17:00:27,089 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:00:28,927 epoch 5 - iter 0/277 - loss 0.13178203\n",
      "2019-08-10 17:00:35,510 epoch 5 - iter 27/277 - loss 0.01514685\n",
      "2019-08-10 17:00:44,686 epoch 5 - iter 54/277 - loss 0.01949218\n",
      "2019-08-10 17:00:50,850 epoch 5 - iter 81/277 - loss 0.02062237\n",
      "2019-08-10 17:00:57,359 epoch 5 - iter 108/277 - loss 0.01889556\n",
      "2019-08-10 17:01:03,931 epoch 5 - iter 135/277 - loss 0.01867064\n",
      "2019-08-10 17:01:10,234 epoch 5 - iter 162/277 - loss 0.02053709\n",
      "2019-08-10 17:01:16,352 epoch 5 - iter 189/277 - loss 0.02108414\n",
      "2019-08-10 17:01:22,603 epoch 5 - iter 216/277 - loss 0.02037532\n",
      "2019-08-10 17:01:29,217 epoch 5 - iter 243/277 - loss 0.02223799\n",
      "2019-08-10 17:01:35,383 epoch 5 - iter 270/277 - loss 0.02319087\n",
      "2019-08-10 17:01:37,437 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:01:37,440 EPOCH 5 done: loss 0.0228 - lr 0.1000 - bad epochs 2\n",
      "2019-08-10 17:01:46,586 DEV : loss 0.05227794125676155 - score 0.9802\n",
      "2019-08-10 17:01:46,589 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:01:48,316 epoch 6 - iter 0/277 - loss 0.00122361\n",
      "2019-08-10 17:01:54,761 epoch 6 - iter 27/277 - loss 0.00559686\n",
      "2019-08-10 17:02:01,161 epoch 6 - iter 54/277 - loss 0.00771691\n",
      "2019-08-10 17:02:07,713 epoch 6 - iter 81/277 - loss 0.01161790\n",
      "2019-08-10 17:02:14,059 epoch 6 - iter 108/277 - loss 0.01077040\n",
      "2019-08-10 17:02:20,489 epoch 6 - iter 135/277 - loss 0.01367504\n",
      "2019-08-10 17:02:27,103 epoch 6 - iter 162/277 - loss 0.01223716\n",
      "2019-08-10 17:02:36,144 epoch 6 - iter 189/277 - loss 0.01159914\n",
      "2019-08-10 17:02:42,759 epoch 6 - iter 216/277 - loss 0.01577219\n",
      "2019-08-10 17:02:48,898 epoch 6 - iter 243/277 - loss 0.01435877\n",
      "2019-08-10 17:02:55,154 epoch 6 - iter 270/277 - loss 0.01490759\n",
      "2019-08-10 17:02:57,136 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:02:57,139 EPOCH 6 done: loss 0.0153 - lr 0.1000 - bad epochs 3\n",
      "2019-08-10 17:03:06,334 DEV : loss 0.03818122297525406 - score 0.9838\n",
      "Epoch     5: reducing learning rate of group 0 to 5.0000e-02.                      \n",
      " 10%|█         | 1/10 [1:00:44<5:56:40, 2377.79s/it, best loss: 0.015599999999999984]2019-08-10 17:03:06,345 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:03:08,158 epoch 7 - iter 0/277 - loss 0.00267939\n",
      "2019-08-10 17:03:14,546 epoch 7 - iter 27/277 - loss 0.00559027\n",
      "2019-08-10 17:03:20,998 epoch 7 - iter 54/277 - loss 0.01108605\n",
      "2019-08-10 17:03:27,544 epoch 7 - iter 81/277 - loss 0.01082034\n",
      "2019-08-10 17:03:34,220 epoch 7 - iter 108/277 - loss 0.00912886\n",
      "2019-08-10 17:03:40,680 epoch 7 - iter 135/277 - loss 0.01074997\n",
      "2019-08-10 17:03:46,958 epoch 7 - iter 162/277 - loss 0.00955459\n",
      "2019-08-10 17:03:53,316 epoch 7 - iter 189/277 - loss 0.00851883\n",
      "2019-08-10 17:03:59,506 epoch 7 - iter 216/277 - loss 0.00897219\n",
      "2019-08-10 17:04:05,628 epoch 7 - iter 243/277 - loss 0.00819609\n",
      "2019-08-10 17:04:12,214 epoch 7 - iter 270/277 - loss 0.00797820\n",
      "2019-08-10 17:04:14,192 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:04:14,194 EPOCH 7 done: loss 0.0078 - lr 0.0500 - bad epochs 0\n",
      "2019-08-10 17:04:23,341 DEV : loss 0.03807362914085388 - score 0.9856\n",
      "2019-08-10 17:04:23,345 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:04:25,033 epoch 8 - iter 0/277 - loss 0.00721765\n",
      "2019-08-10 17:04:31,454 epoch 8 - iter 27/277 - loss 0.00569735\n",
      "2019-08-10 17:04:37,877 epoch 8 - iter 54/277 - loss 0.00990000\n",
      "2019-08-10 17:04:47,227 epoch 8 - iter 81/277 - loss 0.00825935\n",
      "2019-08-10 17:04:53,365 epoch 8 - iter 108/277 - loss 0.00690287\n",
      "2019-08-10 17:04:59,691 epoch 8 - iter 135/277 - loss 0.00634167\n",
      "2019-08-10 17:05:05,934 epoch 8 - iter 162/277 - loss 0.00568131\n",
      "2019-08-10 17:05:12,436 epoch 8 - iter 189/277 - loss 0.00503456\n",
      "2019-08-10 17:05:18,854 epoch 8 - iter 216/277 - loss 0.00626476\n",
      "2019-08-10 17:05:25,232 epoch 8 - iter 243/277 - loss 0.00692823\n",
      "2019-08-10 17:05:31,452 epoch 8 - iter 270/277 - loss 0.00666619\n",
      "2019-08-10 17:05:33,450 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:05:33,455 EPOCH 8 done: loss 0.0066 - lr 0.0500 - bad epochs 0\n",
      "2019-08-10 17:05:42,535 DEV : loss 0.04178502410650253 - score 0.9838\n",
      "2019-08-10 17:05:42,539 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:05:44,198 epoch 9 - iter 0/277 - loss 0.00106567\n",
      "2019-08-10 17:05:50,408 epoch 9 - iter 27/277 - loss 0.00156885\n",
      "2019-08-10 17:05:56,832 epoch 9 - iter 54/277 - loss 0.00161949\n",
      "2019-08-10 17:06:03,071 epoch 9 - iter 81/277 - loss 0.00148368\n",
      "2019-08-10 17:06:09,228 epoch 9 - iter 108/277 - loss 0.00413470\n",
      "2019-08-10 17:06:15,581 epoch 9 - iter 135/277 - loss 0.00363062\n",
      "2019-08-10 17:06:22,302 epoch 9 - iter 162/277 - loss 0.00324562\n",
      "2019-08-10 17:06:28,701 epoch 9 - iter 189/277 - loss 0.00313639\n",
      "2019-08-10 17:06:37,571 epoch 9 - iter 216/277 - loss 0.00317657\n",
      "2019-08-10 17:06:43,916 epoch 9 - iter 243/277 - loss 0.00340719\n",
      "2019-08-10 17:06:50,147 epoch 9 - iter 270/277 - loss 0.00417702\n",
      "2019-08-10 17:06:52,075 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:06:52,078 EPOCH 9 done: loss 0.0042 - lr 0.0500 - bad epochs 1\n",
      "2019-08-10 17:07:01,178 DEV : loss 0.045982278883457184 - score 0.9838\n",
      "2019-08-10 17:07:01,181 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:07:03,053 epoch 10 - iter 0/277 - loss 0.00017576\n",
      "2019-08-10 17:07:09,285 epoch 10 - iter 27/277 - loss 0.00340267\n",
      "2019-08-10 17:07:15,667 epoch 10 - iter 54/277 - loss 0.00253814\n",
      "2019-08-10 17:07:22,085 epoch 10 - iter 81/277 - loss 0.00202343\n",
      "2019-08-10 17:07:28,595 epoch 10 - iter 108/277 - loss 0.00175234\n",
      "2019-08-10 17:07:34,945 epoch 10 - iter 135/277 - loss 0.00184046\n",
      "2019-08-10 17:07:41,018 epoch 10 - iter 162/277 - loss 0.00195440\n",
      "2019-08-10 17:07:47,373 epoch 10 - iter 189/277 - loss 0.00340577\n",
      "2019-08-10 17:07:53,782 epoch 10 - iter 216/277 - loss 0.00318863\n",
      "2019-08-10 17:08:00,213 epoch 10 - iter 243/277 - loss 0.00325066\n",
      "2019-08-10 17:08:06,556 epoch 10 - iter 270/277 - loss 0.00299008\n",
      "2019-08-10 17:08:08,588 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:08:08,590 EPOCH 10 done: loss 0.0029 - lr 0.0500 - bad epochs 2\n",
      "2019-08-10 17:08:17,731 DEV : loss 0.05293168127536774 - score 0.9874\n",
      "2019-08-10 17:08:17,734 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:08:17,737 Testing using best model ...\n",
      "2019-08-10 17:08:26,850 0.9856\t0.9856\t0.9856\n",
      "2019-08-10 17:08:26,853 \n",
      "MICRO_AVG: acc 0.9716 - f1-score 0.9856\n",
      "MACRO_AVG: acc 0.9411 - f1-score 0.96915\n",
      "ham        tp: 476 - fp: 5 - fn: 3 - tn: 71 - precision: 0.9896 - recall: 0.9937 - accuracy: 0.9835 - f1-score: 0.9916\n",
      "spam       tp: 71 - fp: 3 - fn: 5 - tn: 476 - precision: 0.9595 - recall: 0.9342 - accuracy: 0.8987 - f1-score: 0.9467\n",
      "2019-08-10 17:08:26,856 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:08:26,859 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:08:26,861 Training run: 3\n",
      "2019-08-10 17:08:27,178 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:08:27,181 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:08:28,235 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:08:29,951 epoch 1 - iter 0/277 - loss 0.76928014\n",
      "2019-08-10 17:08:36,232 epoch 1 - iter 27/277 - loss 0.17863878\n",
      "2019-08-10 17:08:45,536 epoch 1 - iter 54/277 - loss 0.13151944\n",
      "2019-08-10 17:08:51,714 epoch 1 - iter 81/277 - loss 0.11296446\n",
      "2019-08-10 17:08:58,096 epoch 1 - iter 108/277 - loss 0.09410751\n",
      "2019-08-10 17:09:04,169 epoch 1 - iter 135/277 - loss 0.09452321\n",
      "2019-08-10 17:09:10,581 epoch 1 - iter 162/277 - loss 0.09204323\n",
      "2019-08-10 17:09:16,825 epoch 1 - iter 189/277 - loss 0.08742917\n",
      "2019-08-10 17:09:23,046 epoch 1 - iter 216/277 - loss 0.08312429\n",
      "2019-08-10 17:09:29,518 epoch 1 - iter 243/277 - loss 0.07997673\n",
      "2019-08-10 17:09:35,757 epoch 1 - iter 270/277 - loss 0.07750430\n",
      "2019-08-10 17:09:37,685 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:09:37,688 EPOCH 1 done: loss 0.0770 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:09:46,837 DEV : loss 0.06228874251246452 - score 0.9766\n",
      "2019-08-10 17:09:46,841 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:09:48,600 epoch 2 - iter 0/277 - loss 0.01017144\n",
      "2019-08-10 17:09:55,254 epoch 2 - iter 27/277 - loss 0.02305055\n",
      "2019-08-10 17:10:01,611 epoch 2 - iter 54/277 - loss 0.03352700\n",
      "2019-08-10 17:10:07,831 epoch 2 - iter 81/277 - loss 0.04303687\n",
      "2019-08-10 17:10:14,264 epoch 2 - iter 108/277 - loss 0.04276151\n",
      "2019-08-10 17:10:20,736 epoch 2 - iter 135/277 - loss 0.04617548\n",
      "2019-08-10 17:10:26,998 epoch 2 - iter 162/277 - loss 0.05034697\n",
      "2019-08-10 17:10:35,927 epoch 2 - iter 189/277 - loss 0.04573228\n",
      "2019-08-10 17:10:42,184 epoch 2 - iter 216/277 - loss 0.04245008\n",
      "2019-08-10 17:10:48,683 epoch 2 - iter 243/277 - loss 0.04087586\n",
      "2019-08-10 17:10:54,815 epoch 2 - iter 270/277 - loss 0.03955319\n",
      "2019-08-10 17:10:56,782 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:10:56,785 EPOCH 2 done: loss 0.0390 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:11:05,867 DEV : loss 0.0497731976211071 - score 0.9856\n",
      "2019-08-10 17:11:05,870 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:11:07,565 epoch 3 - iter 0/277 - loss 0.00058950\n",
      "2019-08-10 17:11:13,824 epoch 3 - iter 27/277 - loss 0.02070967\n",
      "2019-08-10 17:11:19,972 epoch 3 - iter 54/277 - loss 0.01818469\n",
      "2019-08-10 17:11:26,250 epoch 3 - iter 81/277 - loss 0.03095526\n",
      "2019-08-10 17:11:32,829 epoch 3 - iter 108/277 - loss 0.03196566\n",
      "2019-08-10 17:11:39,293 epoch 3 - iter 135/277 - loss 0.03111617\n",
      "2019-08-10 17:11:45,799 epoch 3 - iter 162/277 - loss 0.03173156\n",
      "2019-08-10 17:11:52,109 epoch 3 - iter 189/277 - loss 0.02957469\n",
      "2019-08-10 17:11:58,493 epoch 3 - iter 216/277 - loss 0.03229389\n",
      "2019-08-10 17:12:05,126 epoch 3 - iter 243/277 - loss 0.03438361\n",
      "2019-08-10 17:12:11,473 epoch 3 - iter 270/277 - loss 0.03394028\n",
      "2019-08-10 17:12:13,374 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:12:13,377 EPOCH 3 done: loss 0.0349 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:12:22,569 DEV : loss 0.04789549857378006 - score 0.982\n",
      "2019-08-10 17:12:22,572 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:12:24,368 epoch 4 - iter 0/277 - loss 0.00102437\n",
      "2019-08-10 17:12:33,840 epoch 4 - iter 27/277 - loss 0.00718636\n",
      "2019-08-10 17:12:40,290 epoch 4 - iter 54/277 - loss 0.02601321\n",
      "2019-08-10 17:12:46,675 epoch 4 - iter 81/277 - loss 0.02909743\n",
      "2019-08-10 17:12:52,776 epoch 4 - iter 108/277 - loss 0.02486272\n",
      "2019-08-10 17:12:59,207 epoch 4 - iter 135/277 - loss 0.02734631\n",
      "2019-08-10 17:13:05,305 epoch 4 - iter 162/277 - loss 0.02545094\n",
      "2019-08-10 17:13:11,519 epoch 4 - iter 189/277 - loss 0.02296340\n",
      "2019-08-10 17:13:17,634 epoch 4 - iter 216/277 - loss 0.02366354\n",
      "2019-08-10 17:13:24,113 epoch 4 - iter 243/277 - loss 0.02665753\n",
      "2019-08-10 17:13:30,191 epoch 4 - iter 270/277 - loss 0.02747340\n",
      "2019-08-10 17:13:32,298 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:13:32,300 EPOCH 4 done: loss 0.0273 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 17:13:41,363 DEV : loss 0.07764364033937454 - score 0.9766\n",
      "2019-08-10 17:13:41,366 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:13:43,040 epoch 5 - iter 0/277 - loss 0.00037433\n",
      "2019-08-10 17:13:49,553 epoch 5 - iter 27/277 - loss 0.00980982\n",
      "2019-08-10 17:13:55,812 epoch 5 - iter 54/277 - loss 0.00781997\n",
      "2019-08-10 17:14:02,148 epoch 5 - iter 81/277 - loss 0.01113410\n",
      "2019-08-10 17:14:08,603 epoch 5 - iter 108/277 - loss 0.01527665\n",
      "2019-08-10 17:14:14,839 epoch 5 - iter 135/277 - loss 0.01528064\n",
      "2019-08-10 17:14:21,432 epoch 5 - iter 162/277 - loss 0.01576253\n",
      "2019-08-10 17:14:30,294 epoch 5 - iter 189/277 - loss 0.01761613\n",
      "2019-08-10 17:14:36,693 epoch 5 - iter 216/277 - loss 0.02042677\n",
      "2019-08-10 17:14:42,971 epoch 5 - iter 243/277 - loss 0.02145873\n",
      "2019-08-10 17:14:48,918 epoch 5 - iter 270/277 - loss 0.02060921\n",
      "2019-08-10 17:14:50,861 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:14:50,863 EPOCH 5 done: loss 0.0216 - lr 0.1000 - bad epochs 2\n",
      "2019-08-10 17:14:59,942 DEV : loss 0.045705877244472504 - score 0.9874\n",
      "2019-08-10 17:14:59,946 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:15:01,742 epoch 6 - iter 0/277 - loss 0.00097273\n",
      "2019-08-10 17:15:08,379 epoch 6 - iter 27/277 - loss 0.00607495\n",
      "2019-08-10 17:15:14,710 epoch 6 - iter 54/277 - loss 0.00824282\n",
      "2019-08-10 17:15:21,021 epoch 6 - iter 81/277 - loss 0.00985459\n",
      "2019-08-10 17:15:26,997 epoch 6 - iter 108/277 - loss 0.01147150\n",
      "2019-08-10 17:15:33,384 epoch 6 - iter 135/277 - loss 0.01844910\n",
      "2019-08-10 17:15:39,784 epoch 6 - iter 162/277 - loss 0.01712383\n",
      "2019-08-10 17:15:46,386 epoch 6 - iter 189/277 - loss 0.01609595\n",
      "2019-08-10 17:15:52,855 epoch 6 - iter 216/277 - loss 0.01954766\n",
      "2019-08-10 17:15:59,364 epoch 6 - iter 243/277 - loss 0.01851381\n",
      "2019-08-10 17:16:05,550 epoch 6 - iter 270/277 - loss 0.01765576\n",
      "2019-08-10 17:16:07,421 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:16:07,423 EPOCH 6 done: loss 0.0180 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:16:16,511 DEV : loss 0.045677974820137024 - score 0.9802\n",
      "2019-08-10 17:16:16,515 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:16:18,160 epoch 7 - iter 0/277 - loss 0.01004483\n",
      "2019-08-10 17:16:24,576 epoch 7 - iter 27/277 - loss 0.00347539\n",
      "2019-08-10 17:16:33,644 epoch 7 - iter 54/277 - loss 0.00488582\n",
      "2019-08-10 17:16:40,147 epoch 7 - iter 81/277 - loss 0.00434664\n",
      "2019-08-10 17:16:46,659 epoch 7 - iter 108/277 - loss 0.00428921\n",
      "2019-08-10 17:16:52,825 epoch 7 - iter 135/277 - loss 0.00731072\n",
      "2019-08-10 17:16:59,011 epoch 7 - iter 162/277 - loss 0.00688042\n",
      "2019-08-10 17:17:05,176 epoch 7 - iter 189/277 - loss 0.00670949\n",
      "2019-08-10 17:17:11,613 epoch 7 - iter 216/277 - loss 0.01202438\n",
      "2019-08-10 17:17:17,834 epoch 7 - iter 243/277 - loss 0.01124254\n",
      "2019-08-10 17:17:24,118 epoch 7 - iter 270/277 - loss 0.01044771\n",
      "2019-08-10 17:17:26,137 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:17:26,139 EPOCH 7 done: loss 0.0105 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 17:17:35,316 DEV : loss 0.04590091481804848 - score 0.9838\n",
      "2019-08-10 17:17:35,319 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:17:37,024 epoch 8 - iter 0/277 - loss 0.00152724\n",
      "2019-08-10 17:17:43,164 epoch 8 - iter 27/277 - loss 0.00126888\n",
      "2019-08-10 17:17:49,429 epoch 8 - iter 54/277 - loss 0.00404354\n",
      "2019-08-10 17:17:55,739 epoch 8 - iter 81/277 - loss 0.00739070\n",
      "2019-08-10 17:18:02,288 epoch 8 - iter 108/277 - loss 0.00623483\n",
      "2019-08-10 17:18:08,623 epoch 8 - iter 135/277 - loss 0.00534765\n",
      "2019-08-10 17:18:14,793 epoch 8 - iter 162/277 - loss 0.00677462\n",
      "2019-08-10 17:18:23,656 epoch 8 - iter 189/277 - loss 0.00602986\n",
      "2019-08-10 17:18:29,846 epoch 8 - iter 216/277 - loss 0.00549806\n",
      "2019-08-10 17:18:36,142 epoch 8 - iter 243/277 - loss 0.00530465\n",
      "2019-08-10 17:18:42,380 epoch 8 - iter 270/277 - loss 0.00492482\n",
      "2019-08-10 17:18:44,337 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:18:44,345 EPOCH 8 done: loss 0.0048 - lr 0.1000 - bad epochs 2\n",
      "2019-08-10 17:18:53,362 DEV : loss 0.04986899346113205 - score 0.9856\n",
      "2019-08-10 17:18:53,366 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:18:55,009 epoch 9 - iter 0/277 - loss 0.00002050\n",
      "2019-08-10 17:19:01,312 epoch 9 - iter 27/277 - loss 0.00159762\n",
      "2019-08-10 17:19:07,928 epoch 9 - iter 54/277 - loss 0.00167929\n",
      "2019-08-10 17:19:14,083 epoch 9 - iter 81/277 - loss 0.00133651\n",
      "2019-08-10 17:19:20,337 epoch 9 - iter 108/277 - loss 0.00129482\n",
      "2019-08-10 17:19:26,685 epoch 9 - iter 135/277 - loss 0.00196888\n",
      "2019-08-10 17:19:33,109 epoch 9 - iter 162/277 - loss 0.00195980\n",
      "2019-08-10 17:19:39,394 epoch 9 - iter 189/277 - loss 0.00192563\n",
      "2019-08-10 17:19:46,051 epoch 9 - iter 216/277 - loss 0.00185253\n",
      "2019-08-10 17:19:52,234 epoch 9 - iter 243/277 - loss 0.00283093\n",
      "2019-08-10 17:19:58,545 epoch 9 - iter 270/277 - loss 0.00259232\n",
      "2019-08-10 17:20:00,405 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:20:00,410 EPOCH 9 done: loss 0.0026 - lr 0.1000 - bad epochs 3\n",
      "2019-08-10 17:20:09,485 DEV : loss 0.055460259318351746 - score 0.9856\n",
      "Epoch     8: reducing learning rate of group 0 to 5.0000e-02.                        \n",
      " 10%|█         | 1/10 [1:17:47<5:56:40, 2377.79s/it, best loss: 0.015599999999999984]2019-08-10 17:20:09,495 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:20:11,260 epoch 10 - iter 0/277 - loss 0.00003453\n",
      "2019-08-10 17:20:17,768 epoch 10 - iter 27/277 - loss 0.00053304\n",
      "2019-08-10 17:20:26,909 epoch 10 - iter 54/277 - loss 0.00045853\n",
      "2019-08-10 17:20:33,329 epoch 10 - iter 81/277 - loss 0.00054738\n",
      "2019-08-10 17:20:39,737 epoch 10 - iter 108/277 - loss 0.00061615\n",
      "2019-08-10 17:20:45,774 epoch 10 - iter 135/277 - loss 0.00086837\n",
      "2019-08-10 17:20:51,987 epoch 10 - iter 162/277 - loss 0.00090701\n",
      "2019-08-10 17:20:58,029 epoch 10 - iter 189/277 - loss 0.00092761\n",
      "2019-08-10 17:21:04,525 epoch 10 - iter 216/277 - loss 0.00093180\n",
      "2019-08-10 17:21:10,504 epoch 10 - iter 243/277 - loss 0.00102609\n",
      "2019-08-10 17:21:16,730 epoch 10 - iter 270/277 - loss 0.00097369\n",
      "2019-08-10 17:21:18,648 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:21:18,652 EPOCH 10 done: loss 0.0010 - lr 0.0500 - bad epochs 0\n",
      "2019-08-10 17:21:27,647 DEV : loss 0.05860867351293564 - score 0.9874\n",
      "2019-08-10 17:21:27,651 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:21:27,654 Testing using best model ...\n",
      "2019-08-10 17:21:36,569 0.9892\t0.9892\t0.9892\n",
      "2019-08-10 17:21:36,575 \n",
      "MICRO_AVG: acc 0.9786 - f1-score 0.9892\n",
      "MACRO_AVG: acc 0.9559 - f1-score 0.9771000000000001\n",
      "ham        tp: 476 - fp: 3 - fn: 3 - tn: 73 - precision: 0.9937 - recall: 0.9937 - accuracy: 0.9876 - f1-score: 0.9937\n",
      "spam       tp: 73 - fp: 3 - fn: 3 - tn: 476 - precision: 0.9605 - recall: 0.9605 - accuracy: 0.9241 - f1-score: 0.9605\n",
      "2019-08-10 17:21:36,577 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:21:36,580 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:21:36,582 Done evaluating parameter combination:\n",
      "2019-08-10 17:21:36,584 \tdropout: 0.22162824904388523\n",
      "2019-08-10 17:21:36,587 \tembeddings: /tmp/.flair/embeddings/news-forward-0.4.1.pt,/tmp/.flair/embeddings/news-backward-0.4.1.pt\n",
      "2019-08-10 17:21:36,590 \thidden_size: 128\n",
      "2019-08-10 17:21:36,593 \tlearning_rate: 0.1\n",
      "2019-08-10 17:21:36,596 \tmini_batch_size: 16\n",
      "2019-08-10 17:21:36,597 \trnn_layers: 2\n",
      "2019-08-10 17:21:36,600 score: 0.014599999999999972\n",
      "2019-08-10 17:21:36,602 variance: 1.440000000000038e-06\n",
      "2019-08-10 17:21:36,604 test_score: 0.9892\n",
      "\n",
      "2019-08-10 17:21:36,605 ----------------------------------------------------------------------------------------------------\n",
      " 20%|██        | 2/10 [1:19:15<5:17:01, 2377.64s/it, best loss: 0.014599999999999972]2019-08-10 17:21:36,614 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:21:36,616 Evaluation run: 3\n",
      "2019-08-10 17:21:36,618 Evaluating parameter combination:\n",
      "2019-08-10 17:21:36,620 \tdropout: 0.3161060888854863\n",
      "2019-08-10 17:21:36,622 \tembeddings: /tmp/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-08-10 17:21:36,625 \thidden_size: 128\n",
      "2019-08-10 17:21:36,628 \tlearning_rate: 0.15\n",
      "2019-08-10 17:21:36,633 \tmini_batch_size: 32\n",
      "2019-08-10 17:21:36,634 \trnn_layers: 1\n",
      "2019-08-10 17:21:36,638 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:21:39,285 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:21:39,288 Training run: 1\n",
      "2019-08-10 17:21:39,296 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:21:39,298 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:21:40,305 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:21:41,885 epoch 1 - iter 0/139 - loss 0.65149432\n",
      "2019-08-10 17:21:42,643 epoch 1 - iter 13/139 - loss 0.38665041\n",
      "2019-08-10 17:21:43,226 epoch 1 - iter 26/139 - loss 0.36822423\n",
      "2019-08-10 17:21:43,912 epoch 1 - iter 39/139 - loss 0.35629605\n",
      "2019-08-10 17:21:44,575 epoch 1 - iter 52/139 - loss 0.34017589\n",
      "2019-08-10 17:21:45,211 epoch 1 - iter 65/139 - loss 0.33444493\n",
      "2019-08-10 17:21:45,860 epoch 1 - iter 78/139 - loss 0.32470768\n",
      "2019-08-10 17:21:48,860 epoch 1 - iter 91/139 - loss 0.31558440\n",
      "2019-08-10 17:21:49,467 epoch 1 - iter 104/139 - loss 0.30369273\n",
      "2019-08-10 17:21:50,076 epoch 1 - iter 117/139 - loss 0.29419432\n",
      "2019-08-10 17:21:50,591 epoch 1 - iter 130/139 - loss 0.29205591\n",
      "2019-08-10 17:21:51,491 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:21:51,493 EPOCH 1 done: loss 0.2874 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:21:53,249 DEV : loss 0.20204247534275055 - score 0.9117\n",
      "2019-08-10 17:21:53,252 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:21:54,804 epoch 2 - iter 0/139 - loss 0.10691159\n",
      "2019-08-10 17:21:55,509 epoch 2 - iter 13/139 - loss 0.18322012\n",
      "2019-08-10 17:21:56,118 epoch 2 - iter 26/139 - loss 0.18044283\n",
      "2019-08-10 17:21:56,726 epoch 2 - iter 39/139 - loss 0.17332450\n",
      "2019-08-10 17:21:57,315 epoch 2 - iter 52/139 - loss 0.17531847\n",
      "2019-08-10 17:21:57,913 epoch 2 - iter 65/139 - loss 0.17878134\n",
      "2019-08-10 17:21:58,516 epoch 2 - iter 78/139 - loss 0.16986034\n",
      "2019-08-10 17:21:59,100 epoch 2 - iter 91/139 - loss 0.19011739\n",
      "2019-08-10 17:21:59,696 epoch 2 - iter 104/139 - loss 0.18199722\n",
      "2019-08-10 17:22:00,295 epoch 2 - iter 117/139 - loss 0.18438267\n",
      "2019-08-10 17:22:00,790 epoch 2 - iter 130/139 - loss 0.17764047\n",
      "2019-08-10 17:22:01,581 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:22:01,583 EPOCH 2 done: loss 0.1736 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:22:03,363 DEV : loss 0.11236148327589035 - score 0.9622\n",
      "2019-08-10 17:22:03,366 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:22:04,989 epoch 3 - iter 0/139 - loss 0.17270589\n",
      "2019-08-10 17:22:05,621 epoch 3 - iter 13/139 - loss 0.11090867\n",
      "2019-08-10 17:22:06,201 epoch 3 - iter 26/139 - loss 0.15877743\n",
      "2019-08-10 17:22:08,747 epoch 3 - iter 39/139 - loss 0.14122330\n",
      "2019-08-10 17:22:09,326 epoch 3 - iter 52/139 - loss 0.13112720\n",
      "2019-08-10 17:22:09,905 epoch 3 - iter 65/139 - loss 0.12423730\n",
      "2019-08-10 17:22:10,483 epoch 3 - iter 78/139 - loss 0.12216292\n",
      "2019-08-10 17:22:11,069 epoch 3 - iter 91/139 - loss 0.12195104\n",
      "2019-08-10 17:22:11,674 epoch 3 - iter 104/139 - loss 0.11523165\n",
      "2019-08-10 17:22:12,228 epoch 3 - iter 117/139 - loss 0.14042201\n",
      "2019-08-10 17:22:12,736 epoch 3 - iter 130/139 - loss 0.13661740\n",
      "2019-08-10 17:22:13,571 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:22:13,573 EPOCH 3 done: loss 0.1329 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:22:15,333 DEV : loss 0.10998416692018509 - score 0.9622\n",
      "2019-08-10 17:22:15,339 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:22:17,007 epoch 4 - iter 0/139 - loss 0.05314719\n",
      "2019-08-10 17:22:17,633 epoch 4 - iter 13/139 - loss 0.07607026\n",
      "2019-08-10 17:22:18,246 epoch 4 - iter 26/139 - loss 0.11252861\n",
      "2019-08-10 17:22:18,839 epoch 4 - iter 39/139 - loss 0.10389149\n",
      "2019-08-10 17:22:19,457 epoch 4 - iter 52/139 - loss 0.09977715\n",
      "2019-08-10 17:22:20,106 epoch 4 - iter 65/139 - loss 0.10017340\n",
      "2019-08-10 17:22:20,702 epoch 4 - iter 78/139 - loss 0.09792509\n",
      "2019-08-10 17:22:21,294 epoch 4 - iter 91/139 - loss 0.09476761\n",
      "2019-08-10 17:22:21,873 epoch 4 - iter 104/139 - loss 0.09535685\n",
      "2019-08-10 17:22:22,499 epoch 4 - iter 117/139 - loss 0.10267526\n",
      "2019-08-10 17:22:23,014 epoch 4 - iter 130/139 - loss 0.10163069\n",
      "2019-08-10 17:22:23,807 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:22:23,811 EPOCH 4 done: loss 0.1007 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:22:27,599 DEV : loss 0.753411591053009 - score 0.8505\n",
      "2019-08-10 17:22:27,602 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:22:29,244 epoch 5 - iter 0/139 - loss 0.79249012\n",
      "2019-08-10 17:22:29,849 epoch 5 - iter 13/139 - loss 0.13971070\n",
      "2019-08-10 17:22:30,509 epoch 5 - iter 26/139 - loss 0.10862395\n",
      "2019-08-10 17:22:31,081 epoch 5 - iter 39/139 - loss 0.10426374\n",
      "2019-08-10 17:22:31,709 epoch 5 - iter 52/139 - loss 0.09499523\n",
      "2019-08-10 17:22:32,305 epoch 5 - iter 65/139 - loss 0.09967066\n",
      "2019-08-10 17:22:32,892 epoch 5 - iter 78/139 - loss 0.10103590\n",
      "2019-08-10 17:22:33,518 epoch 5 - iter 91/139 - loss 0.09517773\n",
      "2019-08-10 17:22:34,070 epoch 5 - iter 104/139 - loss 0.09103706\n",
      "2019-08-10 17:22:35,107 epoch 5 - iter 117/139 - loss 0.09686740\n",
      "2019-08-10 17:22:35,647 epoch 5 - iter 130/139 - loss 0.09478227\n",
      "2019-08-10 17:22:36,473 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:22:36,476 EPOCH 5 done: loss 0.1007 - lr 0.1500 - bad epochs 2\n",
      "2019-08-10 17:22:38,257 DEV : loss 0.08542408049106598 - score 0.973\n",
      "2019-08-10 17:22:38,260 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:22:39,872 epoch 6 - iter 0/139 - loss 0.03140014\n",
      "2019-08-10 17:22:40,522 epoch 6 - iter 13/139 - loss 0.04590436\n",
      "2019-08-10 17:22:41,155 epoch 6 - iter 26/139 - loss 0.08376878\n",
      "2019-08-10 17:22:41,724 epoch 6 - iter 39/139 - loss 0.07914399\n",
      "2019-08-10 17:22:42,334 epoch 6 - iter 52/139 - loss 0.07714283\n",
      "2019-08-10 17:22:42,955 epoch 6 - iter 65/139 - loss 0.07907156\n",
      "2019-08-10 17:22:43,537 epoch 6 - iter 78/139 - loss 0.07343457\n",
      "2019-08-10 17:22:46,019 epoch 6 - iter 91/139 - loss 0.07689931\n",
      "2019-08-10 17:22:46,574 epoch 6 - iter 104/139 - loss 0.07489764\n",
      "2019-08-10 17:22:47,178 epoch 6 - iter 117/139 - loss 0.07409550\n",
      "2019-08-10 17:22:47,644 epoch 6 - iter 130/139 - loss 0.07371911\n",
      "2019-08-10 17:22:48,413 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:22:48,416 EPOCH 6 done: loss 0.0716 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:22:50,183 DEV : loss 0.06588412821292877 - score 0.9784\n",
      "2019-08-10 17:22:50,186 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:22:51,823 epoch 7 - iter 0/139 - loss 0.27231240\n",
      "2019-08-10 17:22:52,462 epoch 7 - iter 13/139 - loss 0.07587502\n",
      "2019-08-10 17:22:53,061 epoch 7 - iter 26/139 - loss 0.08035884\n",
      "2019-08-10 17:22:53,655 epoch 7 - iter 39/139 - loss 0.08175061\n",
      "2019-08-10 17:22:54,258 epoch 7 - iter 52/139 - loss 0.07701971\n",
      "2019-08-10 17:22:54,850 epoch 7 - iter 65/139 - loss 0.07263667\n",
      "2019-08-10 17:22:55,446 epoch 7 - iter 78/139 - loss 0.07072537\n",
      "2019-08-10 17:22:56,012 epoch 7 - iter 91/139 - loss 0.06378489\n",
      "2019-08-10 17:22:56,609 epoch 7 - iter 104/139 - loss 0.06078553\n",
      "2019-08-10 17:22:57,204 epoch 7 - iter 117/139 - loss 0.06922500\n",
      "2019-08-10 17:22:57,700 epoch 7 - iter 130/139 - loss 0.06975878\n",
      "2019-08-10 17:22:58,491 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:22:58,493 EPOCH 7 done: loss 0.0702 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:23:00,253 DEV : loss 0.06088145449757576 - score 0.982\n",
      "2019-08-10 17:23:00,257 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:23:01,827 epoch 8 - iter 0/139 - loss 0.01462247\n",
      "2019-08-10 17:23:02,496 epoch 8 - iter 13/139 - loss 0.03537041\n",
      "2019-08-10 17:23:03,086 epoch 8 - iter 26/139 - loss 0.04523810\n",
      "2019-08-10 17:23:05,663 epoch 8 - iter 39/139 - loss 0.04307237\n",
      "2019-08-10 17:23:06,227 epoch 8 - iter 52/139 - loss 0.04247082\n",
      "2019-08-10 17:23:06,803 epoch 8 - iter 65/139 - loss 0.04814374\n",
      "2019-08-10 17:23:07,375 epoch 8 - iter 78/139 - loss 0.06813649\n",
      "2019-08-10 17:23:07,948 epoch 8 - iter 91/139 - loss 0.06906519\n",
      "2019-08-10 17:23:08,550 epoch 8 - iter 104/139 - loss 0.06842275\n",
      "2019-08-10 17:23:09,132 epoch 8 - iter 117/139 - loss 0.06841664\n",
      "2019-08-10 17:23:09,605 epoch 8 - iter 130/139 - loss 0.06972920\n",
      "2019-08-10 17:23:10,395 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:23:10,397 EPOCH 8 done: loss 0.0686 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:23:12,115 DEV : loss 0.07492044568061829 - score 0.9694\n",
      "2019-08-10 17:23:12,120 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:23:13,749 epoch 9 - iter 0/139 - loss 0.04095950\n",
      "2019-08-10 17:23:14,365 epoch 9 - iter 13/139 - loss 0.06330290\n",
      "2019-08-10 17:23:14,931 epoch 9 - iter 26/139 - loss 0.06507215\n",
      "2019-08-10 17:23:15,556 epoch 9 - iter 39/139 - loss 0.05748975\n",
      "2019-08-10 17:23:16,154 epoch 9 - iter 52/139 - loss 0.08584063\n",
      "2019-08-10 17:23:16,725 epoch 9 - iter 65/139 - loss 0.07529047\n",
      "2019-08-10 17:23:17,327 epoch 9 - iter 78/139 - loss 0.07024254\n",
      "2019-08-10 17:23:17,978 epoch 9 - iter 91/139 - loss 0.07421653\n",
      "2019-08-10 17:23:18,558 epoch 9 - iter 104/139 - loss 0.08380449\n",
      "2019-08-10 17:23:19,146 epoch 9 - iter 117/139 - loss 0.07701764\n",
      "2019-08-10 17:23:19,672 epoch 9 - iter 130/139 - loss 0.07799103\n",
      "2019-08-10 17:23:20,437 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:23:20,439 EPOCH 9 done: loss 0.0781 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:23:29,615 DEV : loss 0.05650389939546585 - score 0.982\n",
      "2019-08-10 17:23:29,617 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:23:31,212 epoch 10 - iter 0/139 - loss 0.23533078\n",
      "2019-08-10 17:23:31,851 epoch 10 - iter 13/139 - loss 0.11006656\n",
      "2019-08-10 17:23:32,460 epoch 10 - iter 26/139 - loss 0.10763369\n",
      "2019-08-10 17:23:33,054 epoch 10 - iter 39/139 - loss 0.08216795\n",
      "2019-08-10 17:23:33,626 epoch 10 - iter 52/139 - loss 0.07171998\n",
      "2019-08-10 17:23:34,217 epoch 10 - iter 65/139 - loss 0.07139782\n",
      "2019-08-10 17:23:34,791 epoch 10 - iter 78/139 - loss 0.06657388\n",
      "2019-08-10 17:23:35,403 epoch 10 - iter 91/139 - loss 0.05971164\n",
      "2019-08-10 17:23:35,958 epoch 10 - iter 104/139 - loss 0.05832028\n",
      "2019-08-10 17:23:36,568 epoch 10 - iter 117/139 - loss 0.05704379\n",
      "2019-08-10 17:23:37,107 epoch 10 - iter 130/139 - loss 0.06009493\n",
      "2019-08-10 17:23:37,918 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:23:37,923 EPOCH 10 done: loss 0.0580 - lr 0.1500 - bad epochs 2\n",
      "2019-08-10 17:23:39,656 DEV : loss 0.048592064529657364 - score 0.9802\n",
      "2019-08-10 17:23:39,660 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:23:39,662 Testing using best model ...\n",
      "2019-08-10 17:23:41,436 0.9784\t0.9784\t0.9784\n",
      "2019-08-10 17:23:41,440 \n",
      "MICRO_AVG: acc 0.9577 - f1-score 0.9784\n",
      "MACRO_AVG: acc 0.9145 - f1-score 0.9543\n",
      "ham        tp: 473 - fp: 6 - fn: 6 - tn: 70 - precision: 0.9875 - recall: 0.9875 - accuracy: 0.9753 - f1-score: 0.9875\n",
      "spam       tp: 70 - fp: 6 - fn: 6 - tn: 473 - precision: 0.9211 - recall: 0.9211 - accuracy: 0.8537 - f1-score: 0.9211\n",
      "2019-08-10 17:23:41,443 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:23:41,446 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:23:41,448 Training run: 2\n",
      "2019-08-10 17:23:41,458 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:23:41,460 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:23:42,460 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:23:43,928 epoch 1 - iter 0/139 - loss 0.62257254\n",
      "2019-08-10 17:23:44,715 epoch 1 - iter 13/139 - loss 0.41156922\n",
      "2019-08-10 17:23:45,309 epoch 1 - iter 26/139 - loss 0.37380905\n",
      "2019-08-10 17:23:45,953 epoch 1 - iter 39/139 - loss 0.35182225\n",
      "2019-08-10 17:23:46,547 epoch 1 - iter 52/139 - loss 0.33523270\n",
      "2019-08-10 17:23:47,148 epoch 1 - iter 65/139 - loss 0.32167794\n",
      "2019-08-10 17:23:49,640 epoch 1 - iter 78/139 - loss 0.31166052\n",
      "2019-08-10 17:23:50,273 epoch 1 - iter 91/139 - loss 0.30043429\n",
      "2019-08-10 17:23:50,814 epoch 1 - iter 104/139 - loss 0.28812184\n",
      "2019-08-10 17:23:51,438 epoch 1 - iter 117/139 - loss 0.27869585\n",
      "2019-08-10 17:23:51,939 epoch 1 - iter 130/139 - loss 0.26915118\n",
      "2019-08-10 17:23:52,794 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:23:52,797 EPOCH 1 done: loss 0.2631 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:23:54,560 DEV : loss 0.3057398498058319 - score 0.8937\n",
      "2019-08-10 17:23:54,564 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:23:56,172 epoch 2 - iter 0/139 - loss 0.42911386\n",
      "2019-08-10 17:23:56,824 epoch 2 - iter 13/139 - loss 0.30435962\n",
      "2019-08-10 17:23:57,455 epoch 2 - iter 26/139 - loss 0.22503063\n",
      "2019-08-10 17:23:58,059 epoch 2 - iter 39/139 - loss 0.25753407\n",
      "2019-08-10 17:23:58,644 epoch 2 - iter 52/139 - loss 0.23792473\n",
      "2019-08-10 17:23:59,207 epoch 2 - iter 65/139 - loss 0.20737837\n",
      "2019-08-10 17:23:59,833 epoch 2 - iter 78/139 - loss 0.21703561\n",
      "2019-08-10 17:24:00,427 epoch 2 - iter 91/139 - loss 0.20381883\n",
      "2019-08-10 17:24:01,019 epoch 2 - iter 104/139 - loss 0.19585240\n",
      "2019-08-10 17:24:01,667 epoch 2 - iter 117/139 - loss 0.19754666\n",
      "2019-08-10 17:24:02,149 epoch 2 - iter 130/139 - loss 0.18992333\n",
      "2019-08-10 17:24:02,935 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:24:02,938 EPOCH 2 done: loss 0.1820 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:24:04,632 DEV : loss 0.12310273200273514 - score 0.9586\n",
      "2019-08-10 17:24:04,635 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:24:06,157 epoch 3 - iter 0/139 - loss 0.10665325\n",
      "2019-08-10 17:24:08,746 epoch 3 - iter 13/139 - loss 0.19108155\n",
      "2019-08-10 17:24:09,293 epoch 3 - iter 26/139 - loss 0.14525909\n",
      "2019-08-10 17:24:09,921 epoch 3 - iter 39/139 - loss 0.11759406\n",
      "2019-08-10 17:24:10,459 epoch 3 - iter 52/139 - loss 0.11693940\n",
      "2019-08-10 17:24:11,046 epoch 3 - iter 65/139 - loss 0.11964587\n",
      "2019-08-10 17:24:11,638 epoch 3 - iter 78/139 - loss 0.10780639\n",
      "2019-08-10 17:24:12,215 epoch 3 - iter 91/139 - loss 0.10066452\n",
      "2019-08-10 17:24:12,811 epoch 3 - iter 104/139 - loss 0.10969233\n",
      "2019-08-10 17:24:13,389 epoch 3 - iter 117/139 - loss 0.11043901\n",
      "2019-08-10 17:24:13,886 epoch 3 - iter 130/139 - loss 0.11538853\n",
      "2019-08-10 17:24:14,664 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:24:14,668 EPOCH 3 done: loss 0.1181 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:24:16,398 DEV : loss 0.273997038602829 - score 0.8793\n",
      "2019-08-10 17:24:16,401 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:24:17,986 epoch 4 - iter 0/139 - loss 0.11998661\n",
      "2019-08-10 17:24:18,603 epoch 4 - iter 13/139 - loss 0.07728559\n",
      "2019-08-10 17:24:19,212 epoch 4 - iter 26/139 - loss 0.09976200\n",
      "2019-08-10 17:24:19,809 epoch 4 - iter 39/139 - loss 0.09308193\n",
      "2019-08-10 17:24:20,387 epoch 4 - iter 52/139 - loss 0.09964111\n",
      "2019-08-10 17:24:21,016 epoch 4 - iter 65/139 - loss 0.10093765\n",
      "2019-08-10 17:24:21,605 epoch 4 - iter 78/139 - loss 0.10204002\n",
      "2019-08-10 17:24:22,203 epoch 4 - iter 91/139 - loss 0.11451246\n",
      "2019-08-10 17:24:22,789 epoch 4 - iter 104/139 - loss 0.10785043\n",
      "2019-08-10 17:24:23,421 epoch 4 - iter 117/139 - loss 0.10480016\n",
      "2019-08-10 17:24:25,813 epoch 4 - iter 130/139 - loss 0.10300429\n",
      "2019-08-10 17:24:26,585 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:24:26,590 EPOCH 4 done: loss 0.0993 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:24:28,307 DEV : loss 0.0724351555109024 - score 0.9766\n",
      "2019-08-10 17:24:28,311 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:24:29,849 epoch 5 - iter 0/139 - loss 0.02033549\n",
      "2019-08-10 17:24:30,480 epoch 5 - iter 13/139 - loss 0.06787462\n",
      "2019-08-10 17:24:31,073 epoch 5 - iter 26/139 - loss 0.07875719\n",
      "2019-08-10 17:24:31,684 epoch 5 - iter 39/139 - loss 0.07037851\n",
      "2019-08-10 17:24:32,286 epoch 5 - iter 52/139 - loss 0.07956016\n",
      "2019-08-10 17:24:32,893 epoch 5 - iter 65/139 - loss 0.07627657\n",
      "2019-08-10 17:24:33,515 epoch 5 - iter 78/139 - loss 0.09249774\n",
      "2019-08-10 17:24:34,113 epoch 5 - iter 91/139 - loss 0.09223862\n",
      "2019-08-10 17:24:34,691 epoch 5 - iter 104/139 - loss 0.08855258\n",
      "2019-08-10 17:24:35,271 epoch 5 - iter 117/139 - loss 0.09596467\n",
      "2019-08-10 17:24:35,813 epoch 5 - iter 130/139 - loss 0.09314420\n",
      "2019-08-10 17:24:36,615 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:24:36,620 EPOCH 5 done: loss 0.0906 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:24:38,351 DEV : loss 0.07442653924226761 - score 0.9712\n",
      "2019-08-10 17:24:38,355 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:24:39,892 epoch 6 - iter 0/139 - loss 0.00985388\n",
      "2019-08-10 17:24:40,524 epoch 6 - iter 13/139 - loss 0.05376036\n",
      "2019-08-10 17:24:41,108 epoch 6 - iter 26/139 - loss 0.09764099\n",
      "2019-08-10 17:24:41,756 epoch 6 - iter 39/139 - loss 0.10005684\n",
      "2019-08-10 17:24:42,354 epoch 6 - iter 52/139 - loss 0.08805147\n",
      "2019-08-10 17:24:42,921 epoch 6 - iter 65/139 - loss 0.07924034\n",
      "2019-08-10 17:24:45,441 epoch 6 - iter 78/139 - loss 0.07178411\n",
      "2019-08-10 17:24:46,045 epoch 6 - iter 91/139 - loss 0.08245103\n",
      "2019-08-10 17:24:46,623 epoch 6 - iter 104/139 - loss 0.07802299\n",
      "2019-08-10 17:24:47,233 epoch 6 - iter 117/139 - loss 0.08028405\n",
      "2019-08-10 17:24:47,720 epoch 6 - iter 130/139 - loss 0.07835736\n",
      "2019-08-10 17:24:48,493 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:24:48,496 EPOCH 6 done: loss 0.0795 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:24:50,252 DEV : loss 0.08581255376338959 - score 0.9712\n",
      "2019-08-10 17:24:50,256 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:24:51,839 epoch 7 - iter 0/139 - loss 0.15157238\n",
      "2019-08-10 17:24:52,461 epoch 7 - iter 13/139 - loss 0.08238097\n",
      "2019-08-10 17:24:53,060 epoch 7 - iter 26/139 - loss 0.07536454\n",
      "2019-08-10 17:24:53,643 epoch 7 - iter 39/139 - loss 0.08220140\n",
      "2019-08-10 17:24:54,226 epoch 7 - iter 52/139 - loss 0.08395642\n",
      "2019-08-10 17:24:54,865 epoch 7 - iter 65/139 - loss 0.08047725\n",
      "2019-08-10 17:24:55,434 epoch 7 - iter 78/139 - loss 0.07226358\n",
      "2019-08-10 17:24:56,028 epoch 7 - iter 91/139 - loss 0.07081365\n",
      "2019-08-10 17:24:56,644 epoch 7 - iter 104/139 - loss 0.07252699\n",
      "2019-08-10 17:24:57,262 epoch 7 - iter 117/139 - loss 0.07507586\n",
      "2019-08-10 17:24:57,769 epoch 7 - iter 130/139 - loss 0.07047861\n",
      "2019-08-10 17:24:58,537 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:24:58,539 EPOCH 7 done: loss 0.0687 - lr 0.1500 - bad epochs 2\n",
      "2019-08-10 17:25:00,298 DEV : loss 0.05674015358090401 - score 0.982\n",
      "2019-08-10 17:25:00,301 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:25:01,864 epoch 8 - iter 0/139 - loss 0.00830284\n",
      "2019-08-10 17:25:04,543 epoch 8 - iter 13/139 - loss 0.05502638\n",
      "2019-08-10 17:25:05,128 epoch 8 - iter 26/139 - loss 0.05975429\n",
      "2019-08-10 17:25:05,724 epoch 8 - iter 39/139 - loss 0.06035825\n",
      "2019-08-10 17:25:06,299 epoch 8 - iter 52/139 - loss 0.05861219\n",
      "2019-08-10 17:25:06,896 epoch 8 - iter 65/139 - loss 0.05914160\n",
      "2019-08-10 17:25:07,487 epoch 8 - iter 78/139 - loss 0.05307053\n",
      "2019-08-10 17:25:08,082 epoch 8 - iter 91/139 - loss 0.05637677\n",
      "2019-08-10 17:25:08,663 epoch 8 - iter 104/139 - loss 0.05446421\n",
      "2019-08-10 17:25:09,253 epoch 8 - iter 117/139 - loss 0.05510951\n",
      "2019-08-10 17:25:09,735 epoch 8 - iter 130/139 - loss 0.06497469\n",
      "2019-08-10 17:25:10,566 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:25:10,569 EPOCH 8 done: loss 0.0702 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:25:12,305 DEV : loss 0.15998263657093048 - score 0.9514\n",
      "2019-08-10 17:25:12,308 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:25:13,888 epoch 9 - iter 0/139 - loss 0.02086964\n",
      "2019-08-10 17:25:14,510 epoch 9 - iter 13/139 - loss 0.05014037\n",
      "2019-08-10 17:25:15,118 epoch 9 - iter 26/139 - loss 0.04028700\n",
      "2019-08-10 17:25:15,733 epoch 9 - iter 39/139 - loss 0.04533557\n",
      "2019-08-10 17:25:16,324 epoch 9 - iter 52/139 - loss 0.05477264\n",
      "2019-08-10 17:25:16,925 epoch 9 - iter 65/139 - loss 0.05728778\n",
      "2019-08-10 17:25:17,517 epoch 9 - iter 78/139 - loss 0.05915916\n",
      "2019-08-10 17:25:18,141 epoch 9 - iter 91/139 - loss 0.05772908\n",
      "2019-08-10 17:25:18,714 epoch 9 - iter 104/139 - loss 0.05801497\n",
      "2019-08-10 17:25:21,260 epoch 9 - iter 117/139 - loss 0.05496908\n",
      "2019-08-10 17:25:21,761 epoch 9 - iter 130/139 - loss 0.06151211\n",
      "2019-08-10 17:25:22,529 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:25:22,534 EPOCH 9 done: loss 0.0617 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:25:24,232 DEV : loss 0.055624764412641525 - score 0.9802\n",
      "2019-08-10 17:25:24,235 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:25:25,757 epoch 10 - iter 0/139 - loss 0.01788397\n",
      "2019-08-10 17:25:26,424 epoch 10 - iter 13/139 - loss 0.08180698\n",
      "2019-08-10 17:25:27,027 epoch 10 - iter 26/139 - loss 0.05687897\n",
      "2019-08-10 17:25:27,621 epoch 10 - iter 39/139 - loss 0.05318034\n",
      "2019-08-10 17:25:28,210 epoch 10 - iter 52/139 - loss 0.05328504\n",
      "2019-08-10 17:25:28,789 epoch 10 - iter 65/139 - loss 0.06358538\n",
      "2019-08-10 17:25:29,389 epoch 10 - iter 78/139 - loss 0.06359776\n",
      "2019-08-10 17:25:29,978 epoch 10 - iter 91/139 - loss 0.07090573\n",
      "2019-08-10 17:25:30,580 epoch 10 - iter 104/139 - loss 0.06806802\n",
      "2019-08-10 17:25:31,158 epoch 10 - iter 117/139 - loss 0.06756533\n",
      "2019-08-10 17:25:31,680 epoch 10 - iter 130/139 - loss 0.06501870\n",
      "2019-08-10 17:25:32,450 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:25:32,454 EPOCH 10 done: loss 0.0621 - lr 0.1500 - bad epochs 2\n",
      "2019-08-10 17:25:34,193 DEV : loss 0.052658308297395706 - score 0.982\n",
      "2019-08-10 17:25:34,196 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:25:34,199 Testing using best model ...\n",
      "2019-08-10 17:25:35,950 0.9802\t0.9802\t0.9802\n",
      "2019-08-10 17:25:35,953 \n",
      "MICRO_AVG: acc 0.9611 - f1-score 0.9802\n",
      "MACRO_AVG: acc 0.9216 - f1-score 0.9583\n",
      "ham        tp: 473 - fp: 5 - fn: 6 - tn: 71 - precision: 0.9895 - recall: 0.9875 - accuracy: 0.9773 - f1-score: 0.9885\n",
      "spam       tp: 71 - fp: 6 - fn: 5 - tn: 473 - precision: 0.9221 - recall: 0.9342 - accuracy: 0.8659 - f1-score: 0.9281\n",
      "2019-08-10 17:25:35,956 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:25:35,959 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:25:35,961 Training run: 3\n",
      "2019-08-10 17:25:35,971 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:25:35,973 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:25:36,977 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:25:38,603 epoch 1 - iter 0/139 - loss 0.75393051\n",
      "2019-08-10 17:25:39,229 epoch 1 - iter 13/139 - loss 0.39895157\n",
      "2019-08-10 17:25:39,818 epoch 1 - iter 26/139 - loss 0.38967533\n",
      "2019-08-10 17:25:42,339 epoch 1 - iter 39/139 - loss 0.36292825\n",
      "2019-08-10 17:25:42,942 epoch 1 - iter 52/139 - loss 0.35772424\n",
      "2019-08-10 17:25:43,508 epoch 1 - iter 65/139 - loss 0.34373347\n",
      "2019-08-10 17:25:44,053 epoch 1 - iter 78/139 - loss 0.33365454\n",
      "2019-08-10 17:25:44,644 epoch 1 - iter 91/139 - loss 0.31816441\n",
      "2019-08-10 17:25:45,254 epoch 1 - iter 104/139 - loss 0.30946062\n",
      "2019-08-10 17:25:45,814 epoch 1 - iter 117/139 - loss 0.29046019\n",
      "2019-08-10 17:25:46,297 epoch 1 - iter 130/139 - loss 0.27967005\n",
      "2019-08-10 17:25:47,069 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:25:47,074 EPOCH 1 done: loss 0.2773 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:25:48,821 DEV : loss 0.16183486580848694 - score 0.9495\n",
      "2019-08-10 17:25:48,824 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:25:50,398 epoch 2 - iter 0/139 - loss 0.18966484\n",
      "2019-08-10 17:25:51,036 epoch 2 - iter 13/139 - loss 0.19789847\n",
      "2019-08-10 17:25:51,640 epoch 2 - iter 26/139 - loss 0.20828751\n",
      "2019-08-10 17:25:52,215 epoch 2 - iter 39/139 - loss 0.19789364\n",
      "2019-08-10 17:25:52,843 epoch 2 - iter 52/139 - loss 0.20369329\n",
      "2019-08-10 17:25:53,446 epoch 2 - iter 65/139 - loss 0.20251112\n",
      "2019-08-10 17:25:54,044 epoch 2 - iter 78/139 - loss 0.19992777\n",
      "2019-08-10 17:25:54,640 epoch 2 - iter 91/139 - loss 0.19066929\n",
      "2019-08-10 17:25:55,222 epoch 2 - iter 104/139 - loss 0.18386447\n",
      "2019-08-10 17:25:55,818 epoch 2 - iter 117/139 - loss 0.18497941\n",
      "2019-08-10 17:25:56,331 epoch 2 - iter 130/139 - loss 0.17989160\n",
      "2019-08-10 17:25:57,096 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:25:57,098 EPOCH 2 done: loss 0.1754 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:26:00,857 DEV : loss 0.09811072051525116 - score 0.9658\n",
      "2019-08-10 17:26:00,860 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:26:02,475 epoch 3 - iter 0/139 - loss 0.10499439\n",
      "2019-08-10 17:26:03,101 epoch 3 - iter 13/139 - loss 0.09693092\n",
      "2019-08-10 17:26:03,713 epoch 3 - iter 26/139 - loss 0.14501463\n",
      "2019-08-10 17:26:04,283 epoch 3 - iter 39/139 - loss 0.11742141\n",
      "2019-08-10 17:26:04,909 epoch 3 - iter 52/139 - loss 0.10947433\n",
      "2019-08-10 17:26:05,507 epoch 3 - iter 65/139 - loss 0.11187125\n",
      "2019-08-10 17:26:06,084 epoch 3 - iter 78/139 - loss 0.13163175\n",
      "2019-08-10 17:26:06,685 epoch 3 - iter 91/139 - loss 0.12892084\n",
      "2019-08-10 17:26:07,243 epoch 3 - iter 104/139 - loss 0.12757499\n",
      "2019-08-10 17:26:07,843 epoch 3 - iter 117/139 - loss 0.12581776\n",
      "2019-08-10 17:26:08,366 epoch 3 - iter 130/139 - loss 0.13646435\n",
      "2019-08-10 17:26:09,121 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:26:09,123 EPOCH 3 done: loss 0.1346 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:26:10,874 DEV : loss 0.3965586721897125 - score 0.7982\n",
      "2019-08-10 17:26:10,877 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:26:12,469 epoch 4 - iter 0/139 - loss 0.60420239\n",
      "2019-08-10 17:26:13,118 epoch 4 - iter 13/139 - loss 0.20609827\n",
      "2019-08-10 17:26:13,754 epoch 4 - iter 26/139 - loss 0.15772384\n",
      "2019-08-10 17:26:14,304 epoch 4 - iter 39/139 - loss 0.12982092\n",
      "2019-08-10 17:26:14,892 epoch 4 - iter 52/139 - loss 0.11089922\n",
      "2019-08-10 17:26:15,477 epoch 4 - iter 65/139 - loss 0.10605745\n",
      "2019-08-10 17:26:16,047 epoch 4 - iter 78/139 - loss 0.10510964\n",
      "2019-08-10 17:26:16,634 epoch 4 - iter 91/139 - loss 0.09988922\n",
      "2019-08-10 17:26:19,168 epoch 4 - iter 104/139 - loss 0.09596975\n",
      "2019-08-10 17:26:19,731 epoch 4 - iter 117/139 - loss 0.09668452\n",
      "2019-08-10 17:26:20,249 epoch 4 - iter 130/139 - loss 0.09648511\n",
      "2019-08-10 17:26:21,051 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:26:21,053 EPOCH 4 done: loss 0.0944 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:26:22,782 DEV : loss 0.16903109848499298 - score 0.9459\n",
      "2019-08-10 17:26:22,785 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:26:24,336 epoch 5 - iter 0/139 - loss 0.11177094\n",
      "2019-08-10 17:26:24,988 epoch 5 - iter 13/139 - loss 0.06765006\n",
      "2019-08-10 17:26:25,625 epoch 5 - iter 26/139 - loss 0.12089908\n",
      "2019-08-10 17:26:26,240 epoch 5 - iter 39/139 - loss 0.10674255\n",
      "2019-08-10 17:26:26,840 epoch 5 - iter 52/139 - loss 0.10669007\n",
      "2019-08-10 17:26:27,482 epoch 5 - iter 65/139 - loss 0.09889003\n",
      "2019-08-10 17:26:28,061 epoch 5 - iter 78/139 - loss 0.09792845\n",
      "2019-08-10 17:26:28,681 epoch 5 - iter 91/139 - loss 0.09437144\n",
      "2019-08-10 17:26:29,307 epoch 5 - iter 104/139 - loss 0.09135046\n",
      "2019-08-10 17:26:29,853 epoch 5 - iter 117/139 - loss 0.08813647\n",
      "2019-08-10 17:26:30,393 epoch 5 - iter 130/139 - loss 0.08828219\n",
      "2019-08-10 17:26:31,128 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:26:31,131 EPOCH 5 done: loss 0.0957 - lr 0.1500 - bad epochs 2\n",
      "2019-08-10 17:26:32,908 DEV : loss 0.3287774622440338 - score 0.8414\n",
      "2019-08-10 17:26:32,912 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:26:34,526 epoch 6 - iter 0/139 - loss 0.16368775\n",
      "2019-08-10 17:26:35,122 epoch 6 - iter 13/139 - loss 0.07664006\n",
      "2019-08-10 17:26:35,750 epoch 6 - iter 26/139 - loss 0.07693823\n",
      "2019-08-10 17:26:38,285 epoch 6 - iter 39/139 - loss 0.07878031\n",
      "2019-08-10 17:26:38,858 epoch 6 - iter 52/139 - loss 0.07765136\n",
      "2019-08-10 17:26:39,418 epoch 6 - iter 65/139 - loss 0.07377290\n",
      "2019-08-10 17:26:40,022 epoch 6 - iter 78/139 - loss 0.07861781\n",
      "2019-08-10 17:26:40,598 epoch 6 - iter 91/139 - loss 0.07473241\n",
      "2019-08-10 17:26:41,151 epoch 6 - iter 104/139 - loss 0.07128453\n",
      "2019-08-10 17:26:41,738 epoch 6 - iter 117/139 - loss 0.06986467\n",
      "2019-08-10 17:26:42,259 epoch 6 - iter 130/139 - loss 0.06615191\n",
      "2019-08-10 17:26:43,089 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:26:43,092 EPOCH 6 done: loss 0.0703 - lr 0.1500 - bad epochs 3\n",
      "2019-08-10 17:26:44,842 DEV : loss 0.20698517560958862 - score 0.9387\n",
      "Epoch     5: reducing learning rate of group 0 to 7.5000e-02.                        \n",
      " 20%|██        | 2/10 [1:24:23<5:17:01, 2377.64s/it, best loss: 0.014599999999999972]2019-08-10 17:26:44,851 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:26:46,473 epoch 7 - iter 0/139 - loss 0.22293565\n",
      "2019-08-10 17:26:47,101 epoch 7 - iter 13/139 - loss 0.12188092\n",
      "2019-08-10 17:26:47,708 epoch 7 - iter 26/139 - loss 0.09535897\n",
      "2019-08-10 17:26:48,285 epoch 7 - iter 39/139 - loss 0.07629557\n",
      "2019-08-10 17:26:48,884 epoch 7 - iter 52/139 - loss 0.07290452\n",
      "2019-08-10 17:26:49,474 epoch 7 - iter 65/139 - loss 0.06907699\n",
      "2019-08-10 17:26:50,099 epoch 7 - iter 78/139 - loss 0.06551467\n",
      "2019-08-10 17:26:50,680 epoch 7 - iter 91/139 - loss 0.06458592\n",
      "2019-08-10 17:26:51,317 epoch 7 - iter 104/139 - loss 0.06261462\n",
      "2019-08-10 17:26:51,948 epoch 7 - iter 117/139 - loss 0.06026393\n",
      "2019-08-10 17:26:52,469 epoch 7 - iter 130/139 - loss 0.05560993\n",
      "2019-08-10 17:26:53,317 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:26:53,322 EPOCH 7 done: loss 0.0552 - lr 0.0750 - bad epochs 0\n",
      "2019-08-10 17:26:57,117 DEV : loss 0.06238557770848274 - score 0.9766\n",
      "2019-08-10 17:26:57,120 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:26:58,693 epoch 8 - iter 0/139 - loss 0.00440228\n",
      "2019-08-10 17:26:59,342 epoch 8 - iter 13/139 - loss 0.05288481\n",
      "2019-08-10 17:26:59,908 epoch 8 - iter 26/139 - loss 0.04807179\n",
      "2019-08-10 17:27:00,540 epoch 8 - iter 39/139 - loss 0.05336343\n",
      "2019-08-10 17:27:01,093 epoch 8 - iter 52/139 - loss 0.05202263\n",
      "2019-08-10 17:27:01,715 epoch 8 - iter 65/139 - loss 0.04737309\n",
      "2019-08-10 17:27:02,303 epoch 8 - iter 78/139 - loss 0.05068272\n",
      "2019-08-10 17:27:02,921 epoch 8 - iter 91/139 - loss 0.04916720\n",
      "2019-08-10 17:27:03,475 epoch 8 - iter 104/139 - loss 0.04817787\n",
      "2019-08-10 17:27:04,064 epoch 8 - iter 117/139 - loss 0.04848285\n",
      "2019-08-10 17:27:04,588 epoch 8 - iter 130/139 - loss 0.04767149\n",
      "2019-08-10 17:27:05,345 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:27:05,348 EPOCH 8 done: loss 0.0486 - lr 0.0750 - bad epochs 0\n",
      "2019-08-10 17:27:07,119 DEV : loss 0.057415083050727844 - score 0.9784\n",
      "2019-08-10 17:27:07,123 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:27:08,712 epoch 9 - iter 0/139 - loss 0.03015867\n",
      "2019-08-10 17:27:09,320 epoch 9 - iter 13/139 - loss 0.03969970\n",
      "2019-08-10 17:27:09,942 epoch 9 - iter 26/139 - loss 0.05178496\n",
      "2019-08-10 17:27:10,516 epoch 9 - iter 39/139 - loss 0.04887968\n",
      "2019-08-10 17:27:11,116 epoch 9 - iter 52/139 - loss 0.04541724\n",
      "2019-08-10 17:27:11,730 epoch 9 - iter 65/139 - loss 0.04637133\n",
      "2019-08-10 17:27:12,297 epoch 9 - iter 78/139 - loss 0.04693998\n",
      "2019-08-10 17:27:14,811 epoch 9 - iter 91/139 - loss 0.04580775\n",
      "2019-08-10 17:27:15,406 epoch 9 - iter 104/139 - loss 0.04496954\n",
      "2019-08-10 17:27:15,983 epoch 9 - iter 117/139 - loss 0.04157493\n",
      "2019-08-10 17:27:16,486 epoch 9 - iter 130/139 - loss 0.04407326\n",
      "2019-08-10 17:27:17,295 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:27:17,297 EPOCH 9 done: loss 0.0469 - lr 0.0750 - bad epochs 0\n",
      "2019-08-10 17:27:19,066 DEV : loss 0.05652587488293648 - score 0.982\n",
      "2019-08-10 17:27:19,069 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:27:20,681 epoch 10 - iter 0/139 - loss 0.08348604\n",
      "2019-08-10 17:27:21,328 epoch 10 - iter 13/139 - loss 0.03611212\n",
      "2019-08-10 17:27:21,889 epoch 10 - iter 26/139 - loss 0.03699149\n",
      "2019-08-10 17:27:22,474 epoch 10 - iter 39/139 - loss 0.03386562\n",
      "2019-08-10 17:27:23,086 epoch 10 - iter 52/139 - loss 0.04004845\n",
      "2019-08-10 17:27:23,705 epoch 10 - iter 65/139 - loss 0.03538018\n",
      "2019-08-10 17:27:24,323 epoch 10 - iter 78/139 - loss 0.03663168\n",
      "2019-08-10 17:27:24,890 epoch 10 - iter 91/139 - loss 0.03792720\n",
      "2019-08-10 17:27:25,497 epoch 10 - iter 104/139 - loss 0.04470477\n",
      "2019-08-10 17:27:26,060 epoch 10 - iter 117/139 - loss 0.04515920\n",
      "2019-08-10 17:27:26,571 epoch 10 - iter 130/139 - loss 0.04188331\n",
      "2019-08-10 17:27:27,345 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:27:27,348 EPOCH 10 done: loss 0.0417 - lr 0.0750 - bad epochs 0\n",
      "2019-08-10 17:27:29,081 DEV : loss 0.049353357404470444 - score 0.982\n",
      "2019-08-10 17:27:29,085 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:27:29,088 Testing using best model ...\n",
      "2019-08-10 17:27:30,815 0.9802\t0.9802\t0.9802\n",
      "2019-08-10 17:27:30,821 \n",
      "MICRO_AVG: acc 0.9611 - f1-score 0.9802\n",
      "MACRO_AVG: acc 0.9207 - f1-score 0.9578500000000001\n",
      "ham        tp: 474 - fp: 6 - fn: 5 - tn: 70 - precision: 0.9875 - recall: 0.9896 - accuracy: 0.9773 - f1-score: 0.9885\n",
      "spam       tp: 70 - fp: 5 - fn: 6 - tn: 474 - precision: 0.9333 - recall: 0.9211 - accuracy: 0.8642 - f1-score: 0.9272\n",
      "2019-08-10 17:27:30,823 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:27:30,826 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:27:30,828 Done evaluating parameter combination:\n",
      "2019-08-10 17:27:30,831 \tdropout: 0.3161060888854863\n",
      "2019-08-10 17:27:30,834 \tembeddings: /tmp/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-08-10 17:27:30,836 \thidden_size: 128\n",
      "2019-08-10 17:27:30,840 \tlearning_rate: 0.15\n",
      "2019-08-10 17:27:30,842 \tmini_batch_size: 32\n",
      "2019-08-10 17:27:30,846 \trnn_layers: 1\n",
      "2019-08-10 17:27:30,848 score: 0.0236\n",
      "2019-08-10 17:27:30,850 variance: 7.679999999999963e-05\n",
      "2019-08-10 17:27:30,854 test_score: 0.9802\n",
      "\n",
      "2019-08-10 17:27:30,856 ----------------------------------------------------------------------------------------------------\n",
      " 30%|███       | 3/10 [1:25:09<3:26:34, 1770.63s/it, best loss: 0.014599999999999972]2019-08-10 17:27:30,870 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:27:30,873 Evaluation run: 4\n",
      "2019-08-10 17:27:30,877 Evaluating parameter combination:\n",
      "2019-08-10 17:27:30,880 \tdropout: 0.1837011674443803\n",
      "2019-08-10 17:27:30,884 \tembeddings: /tmp/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-08-10 17:27:30,886 \thidden_size: 64\n",
      "2019-08-10 17:27:30,889 \tlearning_rate: 0.2\n",
      "2019-08-10 17:27:30,892 \tmini_batch_size: 8\n",
      "2019-08-10 17:27:30,894 \trnn_layers: 2\n",
      "2019-08-10 17:27:30,896 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:27:33,552 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:27:33,554 Training run: 1\n",
      "2019-08-10 17:27:33,564 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:27:33,566 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:27:34,565 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:27:35,917 epoch 1 - iter 0/553 - loss 0.69054604\n",
      "2019-08-10 17:27:36,825 epoch 1 - iter 55/553 - loss 0.35071971\n",
      "2019-08-10 17:27:40,065 epoch 1 - iter 110/553 - loss 0.32436461\n",
      "2019-08-10 17:27:40,988 epoch 1 - iter 165/553 - loss 0.30562862\n",
      "2019-08-10 17:27:41,874 epoch 1 - iter 220/553 - loss 0.27733800\n",
      "2019-08-10 17:27:42,775 epoch 1 - iter 275/553 - loss 0.26119373\n",
      "2019-08-10 17:27:43,608 epoch 1 - iter 330/553 - loss 0.25320267\n",
      "2019-08-10 17:27:44,490 epoch 1 - iter 385/553 - loss 0.23906978\n",
      "2019-08-10 17:27:45,393 epoch 1 - iter 440/553 - loss 0.22639743\n",
      "2019-08-10 17:27:46,280 epoch 1 - iter 495/553 - loss 0.21670321\n",
      "2019-08-10 17:27:47,120 epoch 1 - iter 550/553 - loss 0.20729752\n",
      "2019-08-10 17:27:47,653 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:27:47,658 EPOCH 1 done: loss 0.2066 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:27:49,531 DEV : loss 0.11857873201370239 - score 0.9568\n",
      "2019-08-10 17:27:49,535 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:27:50,950 epoch 2 - iter 0/553 - loss 0.53625524\n",
      "2019-08-10 17:27:51,835 epoch 2 - iter 55/553 - loss 0.09657755\n",
      "2019-08-10 17:27:52,766 epoch 2 - iter 110/553 - loss 0.09893597\n",
      "2019-08-10 17:27:53,638 epoch 2 - iter 165/553 - loss 0.08790387\n",
      "2019-08-10 17:27:54,518 epoch 2 - iter 220/553 - loss 0.10943785\n",
      "2019-08-10 17:27:55,402 epoch 2 - iter 275/553 - loss 0.10764065\n",
      "2019-08-10 17:27:56,271 epoch 2 - iter 330/553 - loss 0.10633898\n",
      "2019-08-10 17:27:57,158 epoch 2 - iter 385/553 - loss 0.10360346\n",
      "2019-08-10 17:27:58,040 epoch 2 - iter 440/553 - loss 0.10564606\n",
      "2019-08-10 17:27:58,893 epoch 2 - iter 495/553 - loss 0.10360758\n",
      "2019-08-10 17:27:59,750 epoch 2 - iter 550/553 - loss 0.10240851\n",
      "2019-08-10 17:28:00,279 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:28:00,282 EPOCH 2 done: loss 0.1021 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:28:02,123 DEV : loss 0.10025649517774582 - score 0.964\n",
      "2019-08-10 17:28:02,127 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:28:03,522 epoch 3 - iter 0/553 - loss 0.00670907\n",
      "2019-08-10 17:28:04,416 epoch 3 - iter 55/553 - loss 0.07591927\n",
      "2019-08-10 17:28:05,288 epoch 3 - iter 110/553 - loss 0.07099812\n",
      "2019-08-10 17:28:06,152 epoch 3 - iter 165/553 - loss 0.08081822\n",
      "2019-08-10 17:28:07,027 epoch 3 - iter 220/553 - loss 0.07694918\n",
      "2019-08-10 17:28:07,949 epoch 3 - iter 275/553 - loss 0.07496722\n",
      "2019-08-10 17:28:08,837 epoch 3 - iter 330/553 - loss 0.06750511\n",
      "2019-08-10 17:28:09,701 epoch 3 - iter 385/553 - loss 0.06988886\n",
      "2019-08-10 17:28:10,570 epoch 3 - iter 440/553 - loss 0.07470089\n",
      "2019-08-10 17:28:11,431 epoch 3 - iter 495/553 - loss 0.07559727\n",
      "2019-08-10 17:28:12,265 epoch 3 - iter 550/553 - loss 0.07218067\n",
      "2019-08-10 17:28:12,822 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:28:12,827 EPOCH 3 done: loss 0.0719 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:28:14,632 DEV : loss 0.06233144551515579 - score 0.982\n",
      "2019-08-10 17:28:14,635 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:28:16,008 epoch 4 - iter 0/553 - loss 0.00462040\n",
      "2019-08-10 17:28:16,955 epoch 4 - iter 55/553 - loss 0.06311198\n",
      "2019-08-10 17:28:17,818 epoch 4 - iter 110/553 - loss 0.05839895\n",
      "2019-08-10 17:28:18,706 epoch 4 - iter 165/553 - loss 0.06413965\n",
      "2019-08-10 17:28:21,581 epoch 4 - iter 220/553 - loss 0.05659292\n",
      "2019-08-10 17:28:22,450 epoch 4 - iter 275/553 - loss 0.05310481\n",
      "2019-08-10 17:28:23,313 epoch 4 - iter 330/553 - loss 0.05653656\n",
      "2019-08-10 17:28:24,165 epoch 4 - iter 385/553 - loss 0.06085061\n",
      "2019-08-10 17:28:25,058 epoch 4 - iter 440/553 - loss 0.05993415\n",
      "2019-08-10 17:28:25,864 epoch 4 - iter 495/553 - loss 0.05670756\n",
      "2019-08-10 17:28:26,697 epoch 4 - iter 550/553 - loss 0.05542914\n",
      "2019-08-10 17:28:27,236 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:28:27,240 EPOCH 4 done: loss 0.0553 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:28:29,072 DEV : loss 0.04911087080836296 - score 0.982\n",
      "2019-08-10 17:28:29,075 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:28:30,534 epoch 5 - iter 0/553 - loss 0.00367701\n",
      "2019-08-10 17:28:31,452 epoch 5 - iter 55/553 - loss 0.03561240\n",
      "2019-08-10 17:28:32,308 epoch 5 - iter 110/553 - loss 0.02831238\n",
      "2019-08-10 17:28:33,172 epoch 5 - iter 165/553 - loss 0.03126545\n",
      "2019-08-10 17:28:34,061 epoch 5 - iter 220/553 - loss 0.03284920\n",
      "2019-08-10 17:28:34,953 epoch 5 - iter 275/553 - loss 0.03581187\n",
      "2019-08-10 17:28:35,810 epoch 5 - iter 330/553 - loss 0.04324274\n",
      "2019-08-10 17:28:36,696 epoch 5 - iter 385/553 - loss 0.04640003\n",
      "2019-08-10 17:28:37,557 epoch 5 - iter 440/553 - loss 0.05087128\n",
      "2019-08-10 17:28:38,420 epoch 5 - iter 495/553 - loss 0.04862910\n",
      "2019-08-10 17:28:39,270 epoch 5 - iter 550/553 - loss 0.05174666\n",
      "2019-08-10 17:28:39,805 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:28:39,807 EPOCH 5 done: loss 0.0516 - lr 0.2000 - bad epochs 1\n",
      "2019-08-10 17:28:41,657 DEV : loss 0.061153434216976166 - score 0.9748\n",
      "2019-08-10 17:28:41,660 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:28:43,060 epoch 6 - iter 0/553 - loss 0.00203580\n",
      "2019-08-10 17:28:43,987 epoch 6 - iter 55/553 - loss 0.05779439\n",
      "2019-08-10 17:28:44,877 epoch 6 - iter 110/553 - loss 0.04559602\n",
      "2019-08-10 17:28:45,776 epoch 6 - iter 165/553 - loss 0.04309271\n",
      "2019-08-10 17:28:46,637 epoch 6 - iter 220/553 - loss 0.03916559\n",
      "2019-08-10 17:28:47,507 epoch 6 - iter 275/553 - loss 0.03642087\n",
      "2019-08-10 17:28:48,376 epoch 6 - iter 330/553 - loss 0.03752209\n",
      "2019-08-10 17:28:49,257 epoch 6 - iter 385/553 - loss 0.03554405\n",
      "2019-08-10 17:28:50,139 epoch 6 - iter 440/553 - loss 0.03588596\n",
      "2019-08-10 17:28:51,029 epoch 6 - iter 495/553 - loss 0.03519084\n",
      "2019-08-10 17:28:51,867 epoch 6 - iter 550/553 - loss 0.03831017\n",
      "2019-08-10 17:28:52,410 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:28:52,413 EPOCH 6 done: loss 0.0383 - lr 0.2000 - bad epochs 2\n",
      "2019-08-10 17:28:54,239 DEV : loss 0.03785381838679314 - score 0.9874\n",
      "2019-08-10 17:28:54,243 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:28:55,630 epoch 7 - iter 0/553 - loss 0.00158292\n",
      "2019-08-10 17:28:56,548 epoch 7 - iter 55/553 - loss 0.04205737\n",
      "2019-08-10 17:28:57,445 epoch 7 - iter 110/553 - loss 0.04586556\n",
      "2019-08-10 17:28:58,316 epoch 7 - iter 165/553 - loss 0.03965484\n",
      "2019-08-10 17:29:01,247 epoch 7 - iter 220/553 - loss 0.04099356\n",
      "2019-08-10 17:29:02,162 epoch 7 - iter 275/553 - loss 0.03716911\n",
      "2019-08-10 17:29:03,052 epoch 7 - iter 330/553 - loss 0.03655635\n",
      "2019-08-10 17:29:03,933 epoch 7 - iter 385/553 - loss 0.03343545\n",
      "2019-08-10 17:29:04,840 epoch 7 - iter 440/553 - loss 0.03000987\n",
      "2019-08-10 17:29:05,731 epoch 7 - iter 495/553 - loss 0.03444762\n",
      "2019-08-10 17:29:06,604 epoch 7 - iter 550/553 - loss 0.03498240\n",
      "2019-08-10 17:29:07,154 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:29:07,157 EPOCH 7 done: loss 0.0349 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:29:09,035 DEV : loss 0.0345841608941555 - score 0.9874\n",
      "2019-08-10 17:29:09,039 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:29:10,425 epoch 8 - iter 0/553 - loss 0.00535433\n",
      "2019-08-10 17:29:11,344 epoch 8 - iter 55/553 - loss 0.04278061\n",
      "2019-08-10 17:29:12,218 epoch 8 - iter 110/553 - loss 0.03076714\n",
      "2019-08-10 17:29:13,108 epoch 8 - iter 165/553 - loss 0.03324644\n",
      "2019-08-10 17:29:13,987 epoch 8 - iter 220/553 - loss 0.03235336\n",
      "2019-08-10 17:29:14,837 epoch 8 - iter 275/553 - loss 0.03210200\n",
      "2019-08-10 17:29:15,710 epoch 8 - iter 330/553 - loss 0.03525287\n",
      "2019-08-10 17:29:16,584 epoch 8 - iter 385/553 - loss 0.03078832\n",
      "2019-08-10 17:29:17,452 epoch 8 - iter 440/553 - loss 0.03271415\n",
      "2019-08-10 17:29:18,343 epoch 8 - iter 495/553 - loss 0.03163372\n",
      "2019-08-10 17:29:19,193 epoch 8 - iter 550/553 - loss 0.03310594\n",
      "2019-08-10 17:29:19,691 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:29:19,695 EPOCH 8 done: loss 0.0332 - lr 0.2000 - bad epochs 1\n",
      "2019-08-10 17:29:21,497 DEV : loss 0.03505634143948555 - score 0.991\n",
      "2019-08-10 17:29:21,503 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:29:22,870 epoch 9 - iter 0/553 - loss 0.00108930\n",
      "2019-08-10 17:29:23,804 epoch 9 - iter 55/553 - loss 0.05691874\n",
      "2019-08-10 17:29:24,655 epoch 9 - iter 110/553 - loss 0.03458819\n",
      "2019-08-10 17:29:25,527 epoch 9 - iter 165/553 - loss 0.03700763\n",
      "2019-08-10 17:29:26,415 epoch 9 - iter 220/553 - loss 0.03046356\n",
      "2019-08-10 17:29:27,286 epoch 9 - iter 275/553 - loss 0.02636436\n",
      "2019-08-10 17:29:28,153 epoch 9 - iter 330/553 - loss 0.02828363\n",
      "2019-08-10 17:29:29,019 epoch 9 - iter 385/553 - loss 0.02458872\n",
      "2019-08-10 17:29:29,912 epoch 9 - iter 440/553 - loss 0.02221579\n",
      "2019-08-10 17:29:30,797 epoch 9 - iter 495/553 - loss 0.02561873\n",
      "2019-08-10 17:29:31,642 epoch 9 - iter 550/553 - loss 0.02449473\n",
      "2019-08-10 17:29:32,190 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:29:32,192 EPOCH 9 done: loss 0.0244 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:29:34,060 DEV : loss 0.033301692456007004 - score 0.9874\n",
      "2019-08-10 17:29:34,064 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:29:35,465 epoch 10 - iter 0/553 - loss 0.03484032\n",
      "2019-08-10 17:29:36,367 epoch 10 - iter 55/553 - loss 0.03253180\n",
      "2019-08-10 17:29:37,256 epoch 10 - iter 110/553 - loss 0.01829554\n",
      "2019-08-10 17:29:40,164 epoch 10 - iter 165/553 - loss 0.01862027\n",
      "2019-08-10 17:29:41,042 epoch 10 - iter 220/553 - loss 0.01676618\n",
      "2019-08-10 17:29:41,905 epoch 10 - iter 275/553 - loss 0.01400250\n",
      "2019-08-10 17:29:42,773 epoch 10 - iter 330/553 - loss 0.01247073\n",
      "2019-08-10 17:29:43,617 epoch 10 - iter 385/553 - loss 0.01095292\n",
      "2019-08-10 17:29:44,477 epoch 10 - iter 440/553 - loss 0.01506381\n",
      "2019-08-10 17:29:45,353 epoch 10 - iter 495/553 - loss 0.01595837\n",
      "2019-08-10 17:29:46,182 epoch 10 - iter 550/553 - loss 0.01730163\n",
      "2019-08-10 17:29:46,719 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:29:46,728 EPOCH 10 done: loss 0.0172 - lr 0.2000 - bad epochs 1\n",
      "2019-08-10 17:29:48,571 DEV : loss 0.031754761934280396 - score 0.991\n",
      "2019-08-10 17:29:48,575 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:29:48,577 Testing using best model ...\n",
      "2019-08-10 17:29:50,418 0.9784\t0.9784\t0.9784\n",
      "2019-08-10 17:29:50,422 \n",
      "MICRO_AVG: acc 0.9577 - f1-score 0.9784\n",
      "MACRO_AVG: acc 0.9162 - f1-score 0.95525\n",
      "ham        tp: 471 - fp: 4 - fn: 8 - tn: 72 - precision: 0.9916 - recall: 0.9833 - accuracy: 0.9752 - f1-score: 0.9874\n",
      "spam       tp: 72 - fp: 8 - fn: 4 - tn: 471 - precision: 0.9000 - recall: 0.9474 - accuracy: 0.8571 - f1-score: 0.9231\n",
      "2019-08-10 17:29:50,425 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:29:50,428 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:29:50,430 Training run: 2\n",
      "2019-08-10 17:29:50,439 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:29:50,442 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:29:51,446 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:29:52,838 epoch 1 - iter 0/553 - loss 0.68001664\n",
      "2019-08-10 17:29:53,780 epoch 1 - iter 55/553 - loss 0.33785344\n",
      "2019-08-10 17:29:54,667 epoch 1 - iter 110/553 - loss 0.29465445\n",
      "2019-08-10 17:29:55,540 epoch 1 - iter 165/553 - loss 0.27925806\n",
      "2019-08-10 17:29:56,441 epoch 1 - iter 220/553 - loss 0.26992561\n",
      "2019-08-10 17:29:57,316 epoch 1 - iter 275/553 - loss 0.24141675\n",
      "2019-08-10 17:29:58,197 epoch 1 - iter 330/553 - loss 0.22408280\n",
      "2019-08-10 17:29:59,037 epoch 1 - iter 385/553 - loss 0.21782691\n",
      "2019-08-10 17:29:59,911 epoch 1 - iter 440/553 - loss 0.20839154\n",
      "2019-08-10 17:30:00,807 epoch 1 - iter 495/553 - loss 0.20493750\n",
      "2019-08-10 17:30:01,656 epoch 1 - iter 550/553 - loss 0.19341251\n",
      "2019-08-10 17:30:02,162 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:30:02,165 EPOCH 1 done: loss 0.1929 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:30:03,997 DEV : loss 0.1424226611852646 - score 0.9604\n",
      "2019-08-10 17:30:04,001 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:30:05,450 epoch 2 - iter 0/553 - loss 0.00611849\n",
      "2019-08-10 17:30:06,344 epoch 2 - iter 55/553 - loss 0.13875810\n",
      "2019-08-10 17:30:07,192 epoch 2 - iter 110/553 - loss 0.14003475\n",
      "2019-08-10 17:30:08,070 epoch 2 - iter 165/553 - loss 0.12582959\n",
      "2019-08-10 17:30:08,919 epoch 2 - iter 220/553 - loss 0.11337331\n",
      "2019-08-10 17:30:09,809 epoch 2 - iter 275/553 - loss 0.11024468\n",
      "2019-08-10 17:30:10,675 epoch 2 - iter 330/553 - loss 0.11378949\n",
      "2019-08-10 17:30:11,581 epoch 2 - iter 385/553 - loss 0.11361526\n",
      "2019-08-10 17:30:12,437 epoch 2 - iter 440/553 - loss 0.10572792\n",
      "2019-08-10 17:30:13,314 epoch 2 - iter 495/553 - loss 0.10569936\n",
      "2019-08-10 17:30:14,149 epoch 2 - iter 550/553 - loss 0.10355352\n",
      "2019-08-10 17:30:14,709 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:30:14,711 EPOCH 2 done: loss 0.1032 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:30:16,521 DEV : loss 0.06739248335361481 - score 0.9712\n",
      "2019-08-10 17:30:16,524 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:30:17,903 epoch 3 - iter 0/553 - loss 0.01257123\n",
      "2019-08-10 17:30:18,853 epoch 3 - iter 55/553 - loss 0.06119506\n",
      "2019-08-10 17:30:21,706 epoch 3 - iter 110/553 - loss 0.05894842\n",
      "2019-08-10 17:30:22,581 epoch 3 - iter 165/553 - loss 0.05666342\n",
      "2019-08-10 17:30:23,414 epoch 3 - iter 220/553 - loss 0.05579471\n",
      "2019-08-10 17:30:24,322 epoch 3 - iter 275/553 - loss 0.06746411\n",
      "2019-08-10 17:30:25,188 epoch 3 - iter 330/553 - loss 0.06596711\n",
      "2019-08-10 17:30:26,046 epoch 3 - iter 385/553 - loss 0.06608757\n",
      "2019-08-10 17:30:26,904 epoch 3 - iter 440/553 - loss 0.06896628\n",
      "2019-08-10 17:30:27,782 epoch 3 - iter 495/553 - loss 0.06750525\n",
      "2019-08-10 17:30:28,620 epoch 3 - iter 550/553 - loss 0.06771082\n",
      "2019-08-10 17:30:29,170 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:30:29,173 EPOCH 3 done: loss 0.0675 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:30:31,034 DEV : loss 0.059176329523324966 - score 0.9712\n",
      "2019-08-10 17:30:31,038 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:30:32,428 epoch 4 - iter 0/553 - loss 0.01053992\n",
      "2019-08-10 17:30:33,366 epoch 4 - iter 55/553 - loss 0.05506430\n",
      "2019-08-10 17:30:34,229 epoch 4 - iter 110/553 - loss 0.05930503\n",
      "2019-08-10 17:30:35,109 epoch 4 - iter 165/553 - loss 0.06395370\n",
      "2019-08-10 17:30:35,975 epoch 4 - iter 220/553 - loss 0.05907485\n",
      "2019-08-10 17:30:36,838 epoch 4 - iter 275/553 - loss 0.06305416\n",
      "2019-08-10 17:30:37,720 epoch 4 - iter 330/553 - loss 0.05605817\n",
      "2019-08-10 17:30:38,569 epoch 4 - iter 385/553 - loss 0.05351651\n",
      "2019-08-10 17:30:39,423 epoch 4 - iter 440/553 - loss 0.05539129\n",
      "2019-08-10 17:30:40,328 epoch 4 - iter 495/553 - loss 0.05548670\n",
      "2019-08-10 17:30:41,162 epoch 4 - iter 550/553 - loss 0.05643495\n",
      "2019-08-10 17:30:41,699 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:30:41,702 EPOCH 4 done: loss 0.0564 - lr 0.2000 - bad epochs 1\n",
      "2019-08-10 17:30:43,521 DEV : loss 0.05584198981523514 - score 0.9802\n",
      "2019-08-10 17:30:43,525 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:30:44,894 epoch 5 - iter 0/553 - loss 0.00382885\n",
      "2019-08-10 17:30:45,856 epoch 5 - iter 55/553 - loss 0.01976457\n",
      "2019-08-10 17:30:46,707 epoch 5 - iter 110/553 - loss 0.02210969\n",
      "2019-08-10 17:30:47,572 epoch 5 - iter 165/553 - loss 0.01743375\n",
      "2019-08-10 17:30:48,464 epoch 5 - iter 220/553 - loss 0.02234187\n",
      "2019-08-10 17:30:49,340 epoch 5 - iter 275/553 - loss 0.02443077\n",
      "2019-08-10 17:30:50,239 epoch 5 - iter 330/553 - loss 0.02807315\n",
      "2019-08-10 17:30:51,118 epoch 5 - iter 385/553 - loss 0.02942352\n",
      "2019-08-10 17:30:51,993 epoch 5 - iter 440/553 - loss 0.03601415\n",
      "2019-08-10 17:30:52,863 epoch 5 - iter 495/553 - loss 0.03788376\n",
      "2019-08-10 17:30:53,709 epoch 5 - iter 550/553 - loss 0.04227479\n",
      "2019-08-10 17:30:54,244 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:30:54,248 EPOCH 5 done: loss 0.0421 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:30:56,108 DEV : loss 0.0654631033539772 - score 0.973\n",
      "2019-08-10 17:30:56,113 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:30:57,506 epoch 6 - iter 0/553 - loss 0.01216674\n",
      "2019-08-10 17:30:58,406 epoch 6 - iter 55/553 - loss 0.02669336\n",
      "2019-08-10 17:30:59,275 epoch 6 - iter 110/553 - loss 0.01954571\n",
      "2019-08-10 17:31:00,125 epoch 6 - iter 165/553 - loss 0.03485768\n",
      "2019-08-10 17:31:03,015 epoch 6 - iter 220/553 - loss 0.03164481\n",
      "2019-08-10 17:31:03,906 epoch 6 - iter 275/553 - loss 0.02794801\n",
      "2019-08-10 17:31:04,772 epoch 6 - iter 330/553 - loss 0.02903840\n",
      "2019-08-10 17:31:05,638 epoch 6 - iter 385/553 - loss 0.03295695\n",
      "2019-08-10 17:31:06,492 epoch 6 - iter 440/553 - loss 0.03333271\n",
      "2019-08-10 17:31:07,357 epoch 6 - iter 495/553 - loss 0.03480529\n",
      "2019-08-10 17:31:08,182 epoch 6 - iter 550/553 - loss 0.03609284\n",
      "2019-08-10 17:31:08,741 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:31:08,747 EPOCH 6 done: loss 0.0360 - lr 0.2000 - bad epochs 1\n",
      "2019-08-10 17:31:10,583 DEV : loss 0.05895175784826279 - score 0.9766\n",
      "2019-08-10 17:31:10,586 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:31:11,975 epoch 7 - iter 0/553 - loss 0.01588036\n",
      "2019-08-10 17:31:12,896 epoch 7 - iter 55/553 - loss 0.02419082\n",
      "2019-08-10 17:31:13,803 epoch 7 - iter 110/553 - loss 0.03267185\n",
      "2019-08-10 17:31:14,691 epoch 7 - iter 165/553 - loss 0.03204579\n",
      "2019-08-10 17:31:15,549 epoch 7 - iter 220/553 - loss 0.03456185\n",
      "2019-08-10 17:31:16,444 epoch 7 - iter 275/553 - loss 0.03179976\n",
      "2019-08-10 17:31:17,313 epoch 7 - iter 330/553 - loss 0.03705331\n",
      "2019-08-10 17:31:18,175 epoch 7 - iter 385/553 - loss 0.03595472\n",
      "2019-08-10 17:31:19,048 epoch 7 - iter 440/553 - loss 0.03339694\n",
      "2019-08-10 17:31:19,949 epoch 7 - iter 495/553 - loss 0.03319880\n",
      "2019-08-10 17:31:20,770 epoch 7 - iter 550/553 - loss 0.03395253\n",
      "2019-08-10 17:31:21,308 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:31:21,311 EPOCH 7 done: loss 0.0339 - lr 0.2000 - bad epochs 2\n",
      "2019-08-10 17:31:23,126 DEV : loss 0.04331127181649208 - score 0.9874\n",
      "2019-08-10 17:31:23,130 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:31:24,508 epoch 8 - iter 0/553 - loss 0.00046095\n",
      "2019-08-10 17:31:25,428 epoch 8 - iter 55/553 - loss 0.03068024\n",
      "2019-08-10 17:31:26,316 epoch 8 - iter 110/553 - loss 0.02173712\n",
      "2019-08-10 17:31:27,167 epoch 8 - iter 165/553 - loss 0.02081406\n",
      "2019-08-10 17:31:28,018 epoch 8 - iter 220/553 - loss 0.02503459\n",
      "2019-08-10 17:31:28,901 epoch 8 - iter 275/553 - loss 0.02343987\n",
      "2019-08-10 17:31:29,745 epoch 8 - iter 330/553 - loss 0.02720464\n",
      "2019-08-10 17:31:30,643 epoch 8 - iter 385/553 - loss 0.02625396\n",
      "2019-08-10 17:31:31,539 epoch 8 - iter 440/553 - loss 0.02626583\n",
      "2019-08-10 17:31:32,416 epoch 8 - iter 495/553 - loss 0.02541090\n",
      "2019-08-10 17:31:33,240 epoch 8 - iter 550/553 - loss 0.02829310\n",
      "2019-08-10 17:31:33,818 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:31:33,823 EPOCH 8 done: loss 0.0282 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:31:35,652 DEV : loss 0.04968424513936043 - score 0.9838\n",
      "2019-08-10 17:31:35,655 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:31:37,029 epoch 9 - iter 0/553 - loss 0.00186580\n",
      "2019-08-10 17:31:37,937 epoch 9 - iter 55/553 - loss 0.01076008\n",
      "2019-08-10 17:31:38,819 epoch 9 - iter 110/553 - loss 0.01453122\n",
      "2019-08-10 17:31:39,722 epoch 9 - iter 165/553 - loss 0.01792378\n",
      "2019-08-10 17:31:42,593 epoch 9 - iter 220/553 - loss 0.01532178\n",
      "2019-08-10 17:31:43,457 epoch 9 - iter 275/553 - loss 0.01494561\n",
      "2019-08-10 17:31:44,319 epoch 9 - iter 330/553 - loss 0.01447141\n",
      "2019-08-10 17:31:45,228 epoch 9 - iter 385/553 - loss 0.01667389\n",
      "2019-08-10 17:31:46,087 epoch 9 - iter 440/553 - loss 0.01846834\n",
      "2019-08-10 17:31:46,968 epoch 9 - iter 495/553 - loss 0.01962901\n",
      "2019-08-10 17:31:47,796 epoch 9 - iter 550/553 - loss 0.01968191\n",
      "2019-08-10 17:31:48,347 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:31:48,350 EPOCH 9 done: loss 0.0196 - lr 0.2000 - bad epochs 1\n",
      "2019-08-10 17:31:50,180 DEV : loss 0.04199730232357979 - score 0.9874\n",
      "2019-08-10 17:31:50,184 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:31:51,565 epoch 10 - iter 0/553 - loss 0.00133017\n",
      "2019-08-10 17:31:52,480 epoch 10 - iter 55/553 - loss 0.00293796\n",
      "2019-08-10 17:31:53,363 epoch 10 - iter 110/553 - loss 0.01211447\n",
      "2019-08-10 17:31:54,230 epoch 10 - iter 165/553 - loss 0.01208015\n",
      "2019-08-10 17:31:55,127 epoch 10 - iter 220/553 - loss 0.00969399\n",
      "2019-08-10 17:31:56,033 epoch 10 - iter 275/553 - loss 0.01988784\n",
      "2019-08-10 17:31:56,952 epoch 10 - iter 330/553 - loss 0.01868087\n",
      "2019-08-10 17:31:57,874 epoch 10 - iter 385/553 - loss 0.02035974\n",
      "2019-08-10 17:31:58,785 epoch 10 - iter 440/553 - loss 0.02109888\n",
      "2019-08-10 17:31:59,726 epoch 10 - iter 495/553 - loss 0.01923695\n",
      "2019-08-10 17:32:00,576 epoch 10 - iter 550/553 - loss 0.01806158\n",
      "2019-08-10 17:32:01,089 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:32:01,091 EPOCH 10 done: loss 0.0180 - lr 0.2000 - bad epochs 2\n",
      "2019-08-10 17:32:02,934 DEV : loss 0.061609867960214615 - score 0.9802\n",
      "2019-08-10 17:32:02,941 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:32:02,943 Testing using best model ...\n",
      "2019-08-10 17:32:04,773 0.9856\t0.9856\t0.9856\n",
      "2019-08-10 17:32:04,776 \n",
      "MICRO_AVG: acc 0.9716 - f1-score 0.9856\n",
      "MACRO_AVG: acc 0.9405 - f1-score 0.96885\n",
      "ham        tp: 477 - fp: 6 - fn: 2 - tn: 70 - precision: 0.9876 - recall: 0.9958 - accuracy: 0.9835 - f1-score: 0.9917\n",
      "spam       tp: 70 - fp: 2 - fn: 6 - tn: 477 - precision: 0.9722 - recall: 0.9211 - accuracy: 0.8974 - f1-score: 0.9460\n",
      "2019-08-10 17:32:04,779 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:32:04,782 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:32:04,784 Training run: 3\n",
      "2019-08-10 17:32:04,794 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:32:04,796 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:32:05,762 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:32:07,137 epoch 1 - iter 0/553 - loss 0.69881380\n",
      "2019-08-10 17:32:08,049 epoch 1 - iter 55/553 - loss 0.34951389\n",
      "2019-08-10 17:32:08,920 epoch 1 - iter 110/553 - loss 0.32938357\n",
      "2019-08-10 17:32:09,805 epoch 1 - iter 165/553 - loss 0.28633737\n",
      "2019-08-10 17:32:10,685 epoch 1 - iter 220/553 - loss 0.27809085\n",
      "2019-08-10 17:32:11,555 epoch 1 - iter 275/553 - loss 0.26425626\n",
      "2019-08-10 17:32:12,419 epoch 1 - iter 330/553 - loss 0.24457836\n",
      "2019-08-10 17:32:13,308 epoch 1 - iter 385/553 - loss 0.23021593\n",
      "2019-08-10 17:32:14,177 epoch 1 - iter 440/553 - loss 0.21948565\n",
      "2019-08-10 17:32:15,051 epoch 1 - iter 495/553 - loss 0.21493171\n",
      "2019-08-10 17:32:15,899 epoch 1 - iter 550/553 - loss 0.20827311\n",
      "2019-08-10 17:32:16,422 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:32:16,427 EPOCH 1 done: loss 0.2076 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:32:18,258 DEV : loss 0.11986321210861206 - score 0.964\n",
      "2019-08-10 17:32:18,261 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:32:19,615 epoch 2 - iter 0/553 - loss 0.03443763\n",
      "2019-08-10 17:32:20,534 epoch 2 - iter 55/553 - loss 0.07688506\n",
      "2019-08-10 17:32:21,444 epoch 2 - iter 110/553 - loss 0.09969699\n",
      "2019-08-10 17:32:22,317 epoch 2 - iter 165/553 - loss 0.11373715\n",
      "2019-08-10 17:32:25,177 epoch 2 - iter 220/553 - loss 0.10027721\n",
      "2019-08-10 17:32:26,066 epoch 2 - iter 275/553 - loss 0.11588303\n",
      "2019-08-10 17:32:26,919 epoch 2 - iter 330/553 - loss 0.11929997\n",
      "2019-08-10 17:32:27,772 epoch 2 - iter 385/553 - loss 0.11913683\n",
      "2019-08-10 17:32:28,636 epoch 2 - iter 440/553 - loss 0.10818736\n",
      "2019-08-10 17:32:29,476 epoch 2 - iter 495/553 - loss 0.11051671\n",
      "2019-08-10 17:32:30,321 epoch 2 - iter 550/553 - loss 0.10441389\n",
      "2019-08-10 17:32:30,892 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:32:30,895 EPOCH 2 done: loss 0.1043 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:32:32,706 DEV : loss 0.21022266149520874 - score 0.9532\n",
      "2019-08-10 17:32:32,710 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:32:34,085 epoch 3 - iter 0/553 - loss 0.00175625\n",
      "2019-08-10 17:32:34,975 epoch 3 - iter 55/553 - loss 0.06811071\n",
      "2019-08-10 17:32:35,853 epoch 3 - iter 110/553 - loss 0.08586106\n",
      "2019-08-10 17:32:36,733 epoch 3 - iter 165/553 - loss 0.08584520\n",
      "2019-08-10 17:32:37,621 epoch 3 - iter 220/553 - loss 0.07209185\n",
      "2019-08-10 17:32:38,496 epoch 3 - iter 275/553 - loss 0.07977676\n",
      "2019-08-10 17:32:39,409 epoch 3 - iter 330/553 - loss 0.07576534\n",
      "2019-08-10 17:32:40,275 epoch 3 - iter 385/553 - loss 0.07931639\n",
      "2019-08-10 17:32:41,376 epoch 3 - iter 440/553 - loss 0.07801195\n",
      "2019-08-10 17:32:42,419 epoch 3 - iter 495/553 - loss 0.07687397\n",
      "2019-08-10 17:32:43,309 epoch 3 - iter 550/553 - loss 0.07727340\n",
      "2019-08-10 17:32:43,842 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:32:43,845 EPOCH 3 done: loss 0.0771 - lr 0.2000 - bad epochs 1\n",
      "2019-08-10 17:32:45,717 DEV : loss 0.057884931564331055 - score 0.9748\n",
      "2019-08-10 17:32:45,723 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:32:47,101 epoch 4 - iter 0/553 - loss 0.02548775\n",
      "2019-08-10 17:32:48,082 epoch 4 - iter 55/553 - loss 0.08573066\n",
      "2019-08-10 17:32:48,962 epoch 4 - iter 110/553 - loss 0.08683036\n",
      "2019-08-10 17:32:49,848 epoch 4 - iter 165/553 - loss 0.08160105\n",
      "2019-08-10 17:32:50,728 epoch 4 - iter 220/553 - loss 0.06685488\n",
      "2019-08-10 17:32:51,597 epoch 4 - iter 275/553 - loss 0.05975129\n",
      "2019-08-10 17:32:52,445 epoch 4 - iter 330/553 - loss 0.05956274\n",
      "2019-08-10 17:32:53,341 epoch 4 - iter 385/553 - loss 0.06179595\n",
      "2019-08-10 17:32:54,211 epoch 4 - iter 440/553 - loss 0.05872786\n",
      "2019-08-10 17:32:55,095 epoch 4 - iter 495/553 - loss 0.05718422\n",
      "2019-08-10 17:32:55,897 epoch 4 - iter 550/553 - loss 0.05966115\n",
      "2019-08-10 17:32:56,443 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:32:56,446 EPOCH 4 done: loss 0.0595 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:32:58,260 DEV : loss 0.05507360398769379 - score 0.9766\n",
      "2019-08-10 17:32:58,264 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:32:59,635 epoch 5 - iter 0/553 - loss 0.00613698\n",
      "2019-08-10 17:33:00,541 epoch 5 - iter 55/553 - loss 0.05027473\n",
      "2019-08-10 17:33:01,449 epoch 5 - iter 110/553 - loss 0.03623973\n",
      "2019-08-10 17:33:02,318 epoch 5 - iter 165/553 - loss 0.02787061\n",
      "2019-08-10 17:33:05,150 epoch 5 - iter 220/553 - loss 0.03276879\n",
      "2019-08-10 17:33:06,018 epoch 5 - iter 275/553 - loss 0.03382042\n",
      "2019-08-10 17:33:06,899 epoch 5 - iter 330/553 - loss 0.03724785\n",
      "2019-08-10 17:33:07,785 epoch 5 - iter 385/553 - loss 0.03747085\n",
      "2019-08-10 17:33:08,658 epoch 5 - iter 440/553 - loss 0.04127087\n",
      "2019-08-10 17:33:09,532 epoch 5 - iter 495/553 - loss 0.04282678\n",
      "2019-08-10 17:33:10,374 epoch 5 - iter 550/553 - loss 0.04616356\n",
      "2019-08-10 17:33:10,944 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:33:10,947 EPOCH 5 done: loss 0.0461 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:33:12,770 DEV : loss 0.058740515261888504 - score 0.9802\n",
      "2019-08-10 17:33:12,776 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:33:14,160 epoch 6 - iter 0/553 - loss 0.02238517\n",
      "2019-08-10 17:33:15,082 epoch 6 - iter 55/553 - loss 0.04117792\n",
      "2019-08-10 17:33:15,962 epoch 6 - iter 110/553 - loss 0.03892277\n",
      "2019-08-10 17:33:16,848 epoch 6 - iter 165/553 - loss 0.03845936\n",
      "2019-08-10 17:33:17,706 epoch 6 - iter 220/553 - loss 0.04383336\n",
      "2019-08-10 17:33:18,584 epoch 6 - iter 275/553 - loss 0.03867832\n",
      "2019-08-10 17:33:19,510 epoch 6 - iter 330/553 - loss 0.04767302\n",
      "2019-08-10 17:33:20,411 epoch 6 - iter 385/553 - loss 0.04301431\n",
      "2019-08-10 17:33:21,259 epoch 6 - iter 440/553 - loss 0.04591234\n",
      "2019-08-10 17:33:22,141 epoch 6 - iter 495/553 - loss 0.04634685\n",
      "2019-08-10 17:33:22,986 epoch 6 - iter 550/553 - loss 0.04675648\n",
      "2019-08-10 17:33:23,526 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:33:23,529 EPOCH 6 done: loss 0.0471 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:33:25,357 DEV : loss 0.5428439974784851 - score 0.8739\n",
      "2019-08-10 17:33:25,360 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:33:26,731 epoch 7 - iter 0/553 - loss 0.81766665\n",
      "2019-08-10 17:33:27,656 epoch 7 - iter 55/553 - loss 0.04103419\n",
      "2019-08-10 17:33:28,554 epoch 7 - iter 110/553 - loss 0.05070321\n",
      "2019-08-10 17:33:29,413 epoch 7 - iter 165/553 - loss 0.03744365\n",
      "2019-08-10 17:33:30,278 epoch 7 - iter 220/553 - loss 0.03209932\n",
      "2019-08-10 17:33:31,186 epoch 7 - iter 275/553 - loss 0.03473612\n",
      "2019-08-10 17:33:32,051 epoch 7 - iter 330/553 - loss 0.03674038\n",
      "2019-08-10 17:33:32,926 epoch 7 - iter 385/553 - loss 0.03545201\n",
      "2019-08-10 17:33:33,816 epoch 7 - iter 440/553 - loss 0.03724602\n",
      "2019-08-10 17:33:34,669 epoch 7 - iter 495/553 - loss 0.03718676\n",
      "2019-08-10 17:33:35,487 epoch 7 - iter 550/553 - loss 0.03398661\n",
      "2019-08-10 17:33:36,009 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:33:36,011 EPOCH 7 done: loss 0.0339 - lr 0.2000 - bad epochs 1\n",
      "2019-08-10 17:33:37,853 DEV : loss 0.03506147116422653 - score 0.9838\n",
      "2019-08-10 17:33:37,857 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:33:39,227 epoch 8 - iter 0/553 - loss 0.00143141\n",
      "2019-08-10 17:33:40,159 epoch 8 - iter 55/553 - loss 0.01815688\n",
      "2019-08-10 17:33:41,050 epoch 8 - iter 110/553 - loss 0.03440256\n",
      "2019-08-10 17:33:43,922 epoch 8 - iter 165/553 - loss 0.03586346\n",
      "2019-08-10 17:33:44,812 epoch 8 - iter 220/553 - loss 0.03107173\n",
      "2019-08-10 17:33:45,678 epoch 8 - iter 275/553 - loss 0.03629684\n",
      "2019-08-10 17:33:46,542 epoch 8 - iter 330/553 - loss 0.03226101\n",
      "2019-08-10 17:33:47,399 epoch 8 - iter 385/553 - loss 0.03310732\n",
      "2019-08-10 17:33:48,256 epoch 8 - iter 440/553 - loss 0.03279395\n",
      "2019-08-10 17:33:49,141 epoch 8 - iter 495/553 - loss 0.03216706\n",
      "2019-08-10 17:33:49,958 epoch 8 - iter 550/553 - loss 0.03300411\n",
      "2019-08-10 17:33:50,515 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:33:50,520 EPOCH 8 done: loss 0.0329 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:33:52,349 DEV : loss 0.03790416195988655 - score 0.9892\n",
      "2019-08-10 17:33:52,353 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:33:53,732 epoch 9 - iter 0/553 - loss 0.00262156\n",
      "2019-08-10 17:33:54,685 epoch 9 - iter 55/553 - loss 0.02404215\n",
      "2019-08-10 17:33:55,571 epoch 9 - iter 110/553 - loss 0.02041430\n",
      "2019-08-10 17:33:56,446 epoch 9 - iter 165/553 - loss 0.02373967\n",
      "2019-08-10 17:33:57,352 epoch 9 - iter 220/553 - loss 0.02428240\n",
      "2019-08-10 17:33:58,251 epoch 9 - iter 275/553 - loss 0.02377696\n",
      "2019-08-10 17:33:59,110 epoch 9 - iter 330/553 - loss 0.02455242\n",
      "2019-08-10 17:33:59,946 epoch 9 - iter 385/553 - loss 0.02205286\n",
      "2019-08-10 17:34:00,840 epoch 9 - iter 440/553 - loss 0.02019471\n",
      "2019-08-10 17:34:01,727 epoch 9 - iter 495/553 - loss 0.02031580\n",
      "2019-08-10 17:34:02,554 epoch 9 - iter 550/553 - loss 0.02533385\n",
      "2019-08-10 17:34:03,077 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:03,082 EPOCH 9 done: loss 0.0253 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:34:04,952 DEV : loss 0.028707047924399376 - score 0.991\n",
      "2019-08-10 17:34:04,957 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:06,356 epoch 10 - iter 0/553 - loss 0.00154412\n",
      "2019-08-10 17:34:07,268 epoch 10 - iter 55/553 - loss 0.01966197\n",
      "2019-08-10 17:34:08,148 epoch 10 - iter 110/553 - loss 0.02083455\n",
      "2019-08-10 17:34:09,050 epoch 10 - iter 165/553 - loss 0.01867193\n",
      "2019-08-10 17:34:09,961 epoch 10 - iter 220/553 - loss 0.01928797\n",
      "2019-08-10 17:34:10,868 epoch 10 - iter 275/553 - loss 0.02283539\n",
      "2019-08-10 17:34:11,762 epoch 10 - iter 330/553 - loss 0.02456439\n",
      "2019-08-10 17:34:12,681 epoch 10 - iter 385/553 - loss 0.02353518\n",
      "2019-08-10 17:34:13,561 epoch 10 - iter 440/553 - loss 0.02334948\n",
      "2019-08-10 17:34:14,459 epoch 10 - iter 495/553 - loss 0.02330967\n",
      "2019-08-10 17:34:15,316 epoch 10 - iter 550/553 - loss 0.02282444\n",
      "2019-08-10 17:34:15,863 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:15,866 EPOCH 10 done: loss 0.0230 - lr 0.2000 - bad epochs 0\n",
      "2019-08-10 17:34:17,748 DEV : loss 0.03234841674566269 - score 0.9928\n",
      "2019-08-10 17:34:17,753 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:17,756 Testing using best model ...\n",
      "2019-08-10 17:34:19,626 0.9838\t0.9838\t0.9838\n",
      "2019-08-10 17:34:19,630 \n",
      "MICRO_AVG: acc 0.9681 - f1-score 0.9838\n",
      "MACRO_AVG: acc 0.9365 - f1-score 0.96665\n",
      "ham        tp: 472 - fp: 2 - fn: 7 - tn: 74 - precision: 0.9958 - recall: 0.9854 - accuracy: 0.9813 - f1-score: 0.9906\n",
      "spam       tp: 74 - fp: 7 - fn: 2 - tn: 472 - precision: 0.9136 - recall: 0.9737 - accuracy: 0.8916 - f1-score: 0.9427\n",
      "2019-08-10 17:34:19,633 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:19,636 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:19,637 Done evaluating parameter combination:\n",
      "2019-08-10 17:34:19,641 \tdropout: 0.1837011674443803\n",
      "2019-08-10 17:34:19,644 \tembeddings: /tmp/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-08-10 17:34:19,648 \thidden_size: 64\n",
      "2019-08-10 17:34:19,651 \tlearning_rate: 0.2\n",
      "2019-08-10 17:34:19,654 \tmini_batch_size: 8\n",
      "2019-08-10 17:34:19,657 \trnn_layers: 2\n",
      "2019-08-10 17:34:19,660 score: 0.011799999999999996\n",
      "2019-08-10 17:34:19,663 variance: 4.560000000000061e-06\n",
      "2019-08-10 17:34:19,665 test_score: 0.9838\n",
      "\n",
      "2019-08-10 17:34:19,668 ----------------------------------------------------------------------------------------------------\n",
      " 40%|████      | 4/10 [1:31:58<2:16:12, 1362.08s/it, best loss: 0.011799999999999996]2019-08-10 17:34:19,678 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:19,680 Evaluation run: 5\n",
      "2019-08-10 17:34:19,684 Evaluating parameter combination:\n",
      "2019-08-10 17:34:19,687 \tdropout: 0.3063031897430457\n",
      "2019-08-10 17:34:19,689 \tembeddings: /tmp/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-08-10 17:34:19,692 \thidden_size: 64\n",
      "2019-08-10 17:34:19,696 \tlearning_rate: 0.1\n",
      "2019-08-10 17:34:19,698 \tmini_batch_size: 16\n",
      "2019-08-10 17:34:19,700 \trnn_layers: 1\n",
      "2019-08-10 17:34:19,703 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:22,385 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:22,387 Training run: 1\n",
      "2019-08-10 17:34:22,396 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:22,398 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:34:23,382 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:24,820 epoch 1 - iter 0/277 - loss 0.64348710\n",
      "2019-08-10 17:34:25,549 epoch 1 - iter 27/277 - loss 0.39853287\n",
      "2019-08-10 17:34:28,205 epoch 1 - iter 54/277 - loss 0.38310279\n",
      "2019-08-10 17:34:28,861 epoch 1 - iter 81/277 - loss 0.34394318\n",
      "2019-08-10 17:34:29,505 epoch 1 - iter 108/277 - loss 0.32652569\n",
      "2019-08-10 17:34:30,199 epoch 1 - iter 135/277 - loss 0.30238412\n",
      "2019-08-10 17:34:30,834 epoch 1 - iter 162/277 - loss 0.28249624\n",
      "2019-08-10 17:34:31,505 epoch 1 - iter 189/277 - loss 0.27210105\n",
      "2019-08-10 17:34:32,149 epoch 1 - iter 216/277 - loss 0.25805833\n",
      "2019-08-10 17:34:32,842 epoch 1 - iter 243/277 - loss 0.25348125\n",
      "2019-08-10 17:34:33,447 epoch 1 - iter 270/277 - loss 0.24754331\n",
      "2019-08-10 17:34:34,113 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:34,115 EPOCH 1 done: loss 0.2474 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:34:35,833 DEV : loss 0.16381683945655823 - score 0.9423\n",
      "2019-08-10 17:34:35,837 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:37,322 epoch 2 - iter 0/277 - loss 0.11161102\n",
      "2019-08-10 17:34:38,013 epoch 2 - iter 27/277 - loss 0.15617058\n",
      "2019-08-10 17:34:38,706 epoch 2 - iter 54/277 - loss 0.13283816\n",
      "2019-08-10 17:34:39,349 epoch 2 - iter 81/277 - loss 0.11150700\n",
      "2019-08-10 17:34:40,055 epoch 2 - iter 108/277 - loss 0.12482769\n",
      "2019-08-10 17:34:40,726 epoch 2 - iter 135/277 - loss 0.15022277\n",
      "2019-08-10 17:34:41,389 epoch 2 - iter 162/277 - loss 0.15061283\n",
      "2019-08-10 17:34:42,069 epoch 2 - iter 189/277 - loss 0.13985233\n",
      "2019-08-10 17:34:42,737 epoch 2 - iter 216/277 - loss 0.14184172\n",
      "2019-08-10 17:34:43,393 epoch 2 - iter 243/277 - loss 0.13473258\n",
      "2019-08-10 17:34:44,028 epoch 2 - iter 270/277 - loss 0.12984400\n",
      "2019-08-10 17:34:44,688 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:44,692 EPOCH 2 done: loss 0.1291 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:34:46,440 DEV : loss 0.0790884792804718 - score 0.9658\n",
      "2019-08-10 17:34:46,443 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:47,877 epoch 3 - iter 0/277 - loss 0.00635226\n",
      "2019-08-10 17:34:50,580 epoch 3 - iter 27/277 - loss 0.09481832\n",
      "2019-08-10 17:34:51,255 epoch 3 - iter 54/277 - loss 0.08070496\n",
      "2019-08-10 17:34:51,934 epoch 3 - iter 81/277 - loss 0.10852623\n",
      "2019-08-10 17:34:52,572 epoch 3 - iter 108/277 - loss 0.10476364\n",
      "2019-08-10 17:34:53,260 epoch 3 - iter 135/277 - loss 0.09932679\n",
      "2019-08-10 17:34:53,881 epoch 3 - iter 162/277 - loss 0.09850460\n",
      "2019-08-10 17:34:54,525 epoch 3 - iter 189/277 - loss 0.09555441\n",
      "2019-08-10 17:34:55,178 epoch 3 - iter 216/277 - loss 0.09303454\n",
      "2019-08-10 17:34:55,811 epoch 3 - iter 243/277 - loss 0.09196095\n",
      "2019-08-10 17:34:56,422 epoch 3 - iter 270/277 - loss 0.09112933\n",
      "2019-08-10 17:34:57,048 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:34:57,051 EPOCH 3 done: loss 0.0916 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:34:58,791 DEV : loss 0.09036527574062347 - score 0.9694\n",
      "2019-08-10 17:34:58,794 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:35:00,241 epoch 4 - iter 0/277 - loss 0.16570102\n",
      "2019-08-10 17:35:00,950 epoch 4 - iter 27/277 - loss 0.08340947\n",
      "2019-08-10 17:35:01,644 epoch 4 - iter 54/277 - loss 0.09054980\n",
      "2019-08-10 17:35:02,329 epoch 4 - iter 81/277 - loss 0.08185597\n",
      "2019-08-10 17:35:02,988 epoch 4 - iter 108/277 - loss 0.07717194\n",
      "2019-08-10 17:35:03,661 epoch 4 - iter 135/277 - loss 0.08339782\n",
      "2019-08-10 17:35:04,355 epoch 4 - iter 162/277 - loss 0.08327518\n",
      "2019-08-10 17:35:05,006 epoch 4 - iter 189/277 - loss 0.08480844\n",
      "2019-08-10 17:35:05,687 epoch 4 - iter 216/277 - loss 0.08130863\n",
      "2019-08-10 17:35:06,336 epoch 4 - iter 243/277 - loss 0.07927478\n",
      "2019-08-10 17:35:06,943 epoch 4 - iter 270/277 - loss 0.07916575\n",
      "2019-08-10 17:35:07,621 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:35:07,624 EPOCH 4 done: loss 0.0798 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:35:09,356 DEV : loss 0.0732518881559372 - score 0.9694\n",
      "2019-08-10 17:35:09,360 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:35:10,791 epoch 5 - iter 0/277 - loss 0.01433973\n",
      "2019-08-10 17:35:13,489 epoch 5 - iter 27/277 - loss 0.06756873\n",
      "2019-08-10 17:35:14,135 epoch 5 - iter 54/277 - loss 0.07571281\n",
      "2019-08-10 17:35:14,786 epoch 5 - iter 81/277 - loss 0.05940493\n",
      "2019-08-10 17:35:15,429 epoch 5 - iter 108/277 - loss 0.05839794\n",
      "2019-08-10 17:35:16,074 epoch 5 - iter 135/277 - loss 0.06380512\n",
      "2019-08-10 17:35:16,745 epoch 5 - iter 162/277 - loss 0.06410622\n",
      "2019-08-10 17:35:17,386 epoch 5 - iter 189/277 - loss 0.07232329\n",
      "2019-08-10 17:35:18,052 epoch 5 - iter 216/277 - loss 0.07072772\n",
      "2019-08-10 17:35:18,710 epoch 5 - iter 243/277 - loss 0.06937919\n",
      "2019-08-10 17:35:19,314 epoch 5 - iter 270/277 - loss 0.06969402\n",
      "2019-08-10 17:35:19,956 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:35:19,959 EPOCH 5 done: loss 0.0696 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 17:35:21,704 DEV : loss 0.060066550970077515 - score 0.9802\n",
      "2019-08-10 17:35:21,707 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:35:23,132 epoch 6 - iter 0/277 - loss 0.05336470\n",
      "2019-08-10 17:35:23,858 epoch 6 - iter 27/277 - loss 0.04187143\n",
      "2019-08-10 17:35:24,525 epoch 6 - iter 54/277 - loss 0.06764743\n",
      "2019-08-10 17:35:25,188 epoch 6 - iter 81/277 - loss 0.06814798\n",
      "2019-08-10 17:35:25,860 epoch 6 - iter 108/277 - loss 0.07089556\n",
      "2019-08-10 17:35:26,527 epoch 6 - iter 135/277 - loss 0.07115501\n",
      "2019-08-10 17:35:27,204 epoch 6 - iter 162/277 - loss 0.07190233\n",
      "2019-08-10 17:35:27,866 epoch 6 - iter 189/277 - loss 0.07478172\n",
      "2019-08-10 17:35:28,555 epoch 6 - iter 216/277 - loss 0.06917669\n",
      "2019-08-10 17:35:29,218 epoch 6 - iter 243/277 - loss 0.06707263\n",
      "2019-08-10 17:35:29,822 epoch 6 - iter 270/277 - loss 0.06492168\n",
      "2019-08-10 17:35:30,454 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:35:30,457 EPOCH 6 done: loss 0.0645 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:35:34,215 DEV : loss 0.061930879950523376 - score 0.973\n",
      "2019-08-10 17:35:34,218 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:35:35,665 epoch 7 - iter 0/277 - loss 0.48062757\n",
      "2019-08-10 17:35:36,381 epoch 7 - iter 27/277 - loss 0.04953205\n",
      "2019-08-10 17:35:37,025 epoch 7 - iter 54/277 - loss 0.04752600\n",
      "2019-08-10 17:35:37,727 epoch 7 - iter 81/277 - loss 0.06172608\n",
      "2019-08-10 17:35:38,376 epoch 7 - iter 108/277 - loss 0.05693813\n",
      "2019-08-10 17:35:39,034 epoch 7 - iter 135/277 - loss 0.06657419\n",
      "2019-08-10 17:35:39,696 epoch 7 - iter 162/277 - loss 0.06479678\n",
      "2019-08-10 17:35:40,368 epoch 7 - iter 189/277 - loss 0.06228561\n",
      "2019-08-10 17:35:41,022 epoch 7 - iter 216/277 - loss 0.06000490\n",
      "2019-08-10 17:35:41,717 epoch 7 - iter 243/277 - loss 0.06089774\n",
      "2019-08-10 17:35:42,328 epoch 7 - iter 270/277 - loss 0.05939659\n",
      "2019-08-10 17:35:42,973 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:35:42,976 EPOCH 7 done: loss 0.0586 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 17:35:44,712 DEV : loss 0.059622667729854584 - score 0.9802\n",
      "2019-08-10 17:35:44,717 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:35:46,225 epoch 8 - iter 0/277 - loss 0.00293541\n",
      "2019-08-10 17:35:46,943 epoch 8 - iter 27/277 - loss 0.02572730\n",
      "2019-08-10 17:35:47,602 epoch 8 - iter 54/277 - loss 0.03499916\n",
      "2019-08-10 17:35:48,300 epoch 8 - iter 81/277 - loss 0.04970322\n",
      "2019-08-10 17:35:48,948 epoch 8 - iter 108/277 - loss 0.04702150\n",
      "2019-08-10 17:35:49,600 epoch 8 - iter 135/277 - loss 0.04802785\n",
      "2019-08-10 17:35:50,303 epoch 8 - iter 162/277 - loss 0.04570139\n",
      "2019-08-10 17:35:50,963 epoch 8 - iter 189/277 - loss 0.04864016\n",
      "2019-08-10 17:35:51,635 epoch 8 - iter 216/277 - loss 0.04583067\n",
      "2019-08-10 17:35:52,338 epoch 8 - iter 243/277 - loss 0.04489245\n",
      "2019-08-10 17:35:54,823 epoch 8 - iter 270/277 - loss 0.04790844\n",
      "2019-08-10 17:35:55,472 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:35:55,476 EPOCH 8 done: loss 0.0484 - lr 0.1000 - bad epochs 2\n",
      "2019-08-10 17:35:57,189 DEV : loss 0.048637550324201584 - score 0.9802\n",
      "2019-08-10 17:35:57,194 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:35:58,624 epoch 9 - iter 0/277 - loss 0.01484516\n",
      "2019-08-10 17:35:59,323 epoch 9 - iter 27/277 - loss 0.07542348\n",
      "2019-08-10 17:35:59,990 epoch 9 - iter 54/277 - loss 0.05385097\n",
      "2019-08-10 17:36:00,648 epoch 9 - iter 81/277 - loss 0.05496277\n",
      "2019-08-10 17:36:01,332 epoch 9 - iter 108/277 - loss 0.04637316\n",
      "2019-08-10 17:36:02,013 epoch 9 - iter 135/277 - loss 0.04422940\n",
      "2019-08-10 17:36:02,684 epoch 9 - iter 162/277 - loss 0.04242821\n",
      "2019-08-10 17:36:03,342 epoch 9 - iter 189/277 - loss 0.04398143\n",
      "2019-08-10 17:36:04,004 epoch 9 - iter 216/277 - loss 0.04415223\n",
      "2019-08-10 17:36:04,687 epoch 9 - iter 243/277 - loss 0.04398319\n",
      "2019-08-10 17:36:05,299 epoch 9 - iter 270/277 - loss 0.04910788\n",
      "2019-08-10 17:36:05,892 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:36:05,895 EPOCH 9 done: loss 0.0484 - lr 0.1000 - bad epochs 3\n",
      "2019-08-10 17:36:07,647 DEV : loss 0.04368998482823372 - score 0.9838\n",
      "2019-08-10 17:36:07,651 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:36:09,063 epoch 10 - iter 0/277 - loss 0.01833196\n",
      "2019-08-10 17:36:09,777 epoch 10 - iter 27/277 - loss 0.03495225\n",
      "2019-08-10 17:36:10,461 epoch 10 - iter 54/277 - loss 0.02799284\n",
      "2019-08-10 17:36:11,117 epoch 10 - iter 81/277 - loss 0.03104543\n",
      "2019-08-10 17:36:11,795 epoch 10 - iter 108/277 - loss 0.02849238\n",
      "2019-08-10 17:36:12,461 epoch 10 - iter 135/277 - loss 0.02799579\n",
      "2019-08-10 17:36:13,160 epoch 10 - iter 162/277 - loss 0.03164624\n",
      "2019-08-10 17:36:13,829 epoch 10 - iter 189/277 - loss 0.03101878\n",
      "2019-08-10 17:36:14,457 epoch 10 - iter 216/277 - loss 0.03119278\n",
      "2019-08-10 17:36:17,049 epoch 10 - iter 243/277 - loss 0.03361416\n",
      "2019-08-10 17:36:17,638 epoch 10 - iter 270/277 - loss 0.03809115\n",
      "2019-08-10 17:36:18,277 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:36:18,281 EPOCH 10 done: loss 0.0377 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:36:20,037 DEV : loss 0.09880778938531876 - score 0.9622\n",
      "2019-08-10 17:36:20,041 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:36:20,043 Testing using best model ...\n",
      "2019-08-10 17:36:21,795 0.9712\t0.9712\t0.9712\n",
      "2019-08-10 17:36:21,801 \n",
      "MICRO_AVG: acc 0.944 - f1-score 0.9712\n",
      "MACRO_AVG: acc 0.8799 - f1-score 0.9338\n",
      "ham        tp: 478 - fp: 15 - fn: 1 - tn: 61 - precision: 0.9696 - recall: 0.9979 - accuracy: 0.9676 - f1-score: 0.9835\n",
      "spam       tp: 61 - fp: 1 - fn: 15 - tn: 478 - precision: 0.9839 - recall: 0.8026 - accuracy: 0.7922 - f1-score: 0.8841\n",
      "2019-08-10 17:36:21,805 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:36:21,809 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:36:21,815 Training run: 2\n",
      "2019-08-10 17:36:21,822 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:36:21,825 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:36:22,779 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:36:24,216 epoch 1 - iter 0/277 - loss 0.60501915\n",
      "2019-08-10 17:36:24,955 epoch 1 - iter 27/277 - loss 0.40208586\n",
      "2019-08-10 17:36:25,633 epoch 1 - iter 54/277 - loss 0.37548505\n",
      "2019-08-10 17:36:26,313 epoch 1 - iter 81/277 - loss 0.34498414\n",
      "2019-08-10 17:36:27,002 epoch 1 - iter 108/277 - loss 0.31429012\n",
      "2019-08-10 17:36:27,636 epoch 1 - iter 135/277 - loss 0.29742402\n",
      "2019-08-10 17:36:28,332 epoch 1 - iter 162/277 - loss 0.28518381\n",
      "2019-08-10 17:36:28,978 epoch 1 - iter 189/277 - loss 0.27527183\n",
      "2019-08-10 17:36:29,650 epoch 1 - iter 216/277 - loss 0.26726435\n",
      "2019-08-10 17:36:30,303 epoch 1 - iter 243/277 - loss 0.26019362\n",
      "2019-08-10 17:36:30,916 epoch 1 - iter 270/277 - loss 0.25810792\n",
      "2019-08-10 17:36:31,535 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:36:31,538 EPOCH 1 done: loss 0.2539 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:36:33,245 DEV : loss 0.13916011154651642 - score 0.955\n",
      "2019-08-10 17:36:33,251 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:36:34,703 epoch 2 - iter 0/277 - loss 0.03089426\n",
      "2019-08-10 17:36:35,408 epoch 2 - iter 27/277 - loss 0.13744593\n",
      "2019-08-10 17:36:36,064 epoch 2 - iter 54/277 - loss 0.16782417\n",
      "2019-08-10 17:36:36,789 epoch 2 - iter 81/277 - loss 0.16147721\n",
      "2019-08-10 17:36:37,439 epoch 2 - iter 108/277 - loss 0.15485726\n",
      "2019-08-10 17:36:38,121 epoch 2 - iter 135/277 - loss 0.15105040\n",
      "2019-08-10 17:36:40,726 epoch 2 - iter 162/277 - loss 0.14371573\n",
      "2019-08-10 17:36:41,379 epoch 2 - iter 189/277 - loss 0.14646158\n",
      "2019-08-10 17:36:42,037 epoch 2 - iter 216/277 - loss 0.13622056\n",
      "2019-08-10 17:36:42,668 epoch 2 - iter 243/277 - loss 0.13579809\n",
      "2019-08-10 17:36:43,282 epoch 2 - iter 270/277 - loss 0.13755261\n",
      "2019-08-10 17:36:43,964 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:36:43,968 EPOCH 2 done: loss 0.1357 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:36:45,742 DEV : loss 0.10172467678785324 - score 0.9658\n",
      "2019-08-10 17:36:45,746 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:36:47,184 epoch 3 - iter 0/277 - loss 0.00839523\n",
      "2019-08-10 17:36:47,883 epoch 3 - iter 27/277 - loss 0.15253818\n",
      "2019-08-10 17:36:48,544 epoch 3 - iter 54/277 - loss 0.14117897\n",
      "2019-08-10 17:36:49,228 epoch 3 - iter 81/277 - loss 0.13696258\n",
      "2019-08-10 17:36:49,895 epoch 3 - iter 108/277 - loss 0.13239903\n",
      "2019-08-10 17:36:50,579 epoch 3 - iter 135/277 - loss 0.12318294\n",
      "2019-08-10 17:36:51,284 epoch 3 - iter 162/277 - loss 0.11060646\n",
      "2019-08-10 17:36:51,973 epoch 3 - iter 189/277 - loss 0.10381739\n",
      "2019-08-10 17:36:52,619 epoch 3 - iter 216/277 - loss 0.10742898\n",
      "2019-08-10 17:36:53,325 epoch 3 - iter 243/277 - loss 0.10203443\n",
      "2019-08-10 17:36:53,940 epoch 3 - iter 270/277 - loss 0.09743420\n",
      "2019-08-10 17:36:54,539 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:36:54,544 EPOCH 3 done: loss 0.1016 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:36:56,275 DEV : loss 0.18744203448295593 - score 0.9369\n",
      "2019-08-10 17:36:56,279 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:36:57,763 epoch 4 - iter 0/277 - loss 0.27550611\n",
      "2019-08-10 17:36:58,466 epoch 4 - iter 27/277 - loss 0.07689562\n",
      "2019-08-10 17:36:59,121 epoch 4 - iter 54/277 - loss 0.09354526\n",
      "2019-08-10 17:36:59,785 epoch 4 - iter 81/277 - loss 0.08686492\n",
      "2019-08-10 17:37:00,464 epoch 4 - iter 108/277 - loss 0.07925398\n",
      "2019-08-10 17:37:03,164 epoch 4 - iter 135/277 - loss 0.07665117\n",
      "2019-08-10 17:37:03,856 epoch 4 - iter 162/277 - loss 0.08095699\n",
      "2019-08-10 17:37:04,519 epoch 4 - iter 189/277 - loss 0.08292440\n",
      "2019-08-10 17:37:05,192 epoch 4 - iter 216/277 - loss 0.08093667\n",
      "2019-08-10 17:37:05,861 epoch 4 - iter 243/277 - loss 0.08071296\n",
      "2019-08-10 17:37:06,501 epoch 4 - iter 270/277 - loss 0.08340344\n",
      "2019-08-10 17:37:07,135 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:37:07,138 EPOCH 4 done: loss 0.0820 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 17:37:08,894 DEV : loss 0.06758860498666763 - score 0.9712\n",
      "2019-08-10 17:37:08,899 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:37:10,385 epoch 5 - iter 0/277 - loss 0.00557497\n",
      "2019-08-10 17:37:11,099 epoch 5 - iter 27/277 - loss 0.06634349\n",
      "2019-08-10 17:37:11,813 epoch 5 - iter 54/277 - loss 0.07035712\n",
      "2019-08-10 17:37:12,475 epoch 5 - iter 81/277 - loss 0.06297928\n",
      "2019-08-10 17:37:13,177 epoch 5 - iter 108/277 - loss 0.05972105\n",
      "2019-08-10 17:37:13,855 epoch 5 - iter 135/277 - loss 0.07696364\n",
      "2019-08-10 17:37:14,537 epoch 5 - iter 162/277 - loss 0.07830366\n",
      "2019-08-10 17:37:15,201 epoch 5 - iter 189/277 - loss 0.07824184\n",
      "2019-08-10 17:37:15,909 epoch 5 - iter 216/277 - loss 0.07945903\n",
      "2019-08-10 17:37:16,560 epoch 5 - iter 243/277 - loss 0.07857873\n",
      "2019-08-10 17:37:17,177 epoch 5 - iter 270/277 - loss 0.07430633\n",
      "2019-08-10 17:37:17,809 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:37:17,814 EPOCH 5 done: loss 0.0733 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:37:19,571 DEV : loss 0.0807989090681076 - score 0.9694\n",
      "2019-08-10 17:37:19,575 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:37:21,032 epoch 6 - iter 0/277 - loss 0.03078739\n",
      "2019-08-10 17:37:21,765 epoch 6 - iter 27/277 - loss 0.04855778\n",
      "2019-08-10 17:37:22,435 epoch 6 - iter 54/277 - loss 0.05540120\n",
      "2019-08-10 17:37:23,132 epoch 6 - iter 81/277 - loss 0.06259260\n",
      "2019-08-10 17:37:23,766 epoch 6 - iter 108/277 - loss 0.06789896\n",
      "2019-08-10 17:37:26,397 epoch 6 - iter 135/277 - loss 0.06503578\n",
      "2019-08-10 17:37:27,048 epoch 6 - iter 162/277 - loss 0.06385693\n",
      "2019-08-10 17:37:27,696 epoch 6 - iter 189/277 - loss 0.07061974\n",
      "2019-08-10 17:37:28,381 epoch 6 - iter 216/277 - loss 0.07497577\n",
      "2019-08-10 17:37:29,030 epoch 6 - iter 243/277 - loss 0.07160201\n",
      "2019-08-10 17:37:29,633 epoch 6 - iter 270/277 - loss 0.06881068\n",
      "2019-08-10 17:37:30,278 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:37:30,280 EPOCH 6 done: loss 0.0699 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 17:37:32,023 DEV : loss 0.11218639463186264 - score 0.964\n",
      "2019-08-10 17:37:32,027 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:37:33,495 epoch 7 - iter 0/277 - loss 0.00119981\n",
      "2019-08-10 17:37:34,188 epoch 7 - iter 27/277 - loss 0.02773506\n",
      "2019-08-10 17:37:34,904 epoch 7 - iter 54/277 - loss 0.04560926\n",
      "2019-08-10 17:37:35,610 epoch 7 - iter 81/277 - loss 0.04477068\n",
      "2019-08-10 17:37:36,266 epoch 7 - iter 108/277 - loss 0.04774551\n",
      "2019-08-10 17:37:36,953 epoch 7 - iter 135/277 - loss 0.05694033\n",
      "2019-08-10 17:37:37,636 epoch 7 - iter 162/277 - loss 0.05647500\n",
      "2019-08-10 17:37:38,319 epoch 7 - iter 189/277 - loss 0.05905408\n",
      "2019-08-10 17:37:38,997 epoch 7 - iter 216/277 - loss 0.06379425\n",
      "2019-08-10 17:37:39,671 epoch 7 - iter 243/277 - loss 0.05964847\n",
      "2019-08-10 17:37:40,276 epoch 7 - iter 270/277 - loss 0.05572539\n",
      "2019-08-10 17:37:40,891 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:37:40,896 EPOCH 7 done: loss 0.0551 - lr 0.1000 - bad epochs 2\n",
      "2019-08-10 17:37:42,650 DEV : loss 0.12695445120334625 - score 0.9604\n",
      "2019-08-10 17:37:42,656 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:37:44,097 epoch 8 - iter 0/277 - loss 0.35506698\n",
      "2019-08-10 17:37:45,239 epoch 8 - iter 27/277 - loss 0.09630366\n",
      "2019-08-10 17:37:45,950 epoch 8 - iter 54/277 - loss 0.06210197\n",
      "2019-08-10 17:37:46,684 epoch 8 - iter 81/277 - loss 0.06441294\n",
      "2019-08-10 17:37:49,366 epoch 8 - iter 108/277 - loss 0.06194556\n",
      "2019-08-10 17:37:50,061 epoch 8 - iter 135/277 - loss 0.05849923\n",
      "2019-08-10 17:37:50,732 epoch 8 - iter 162/277 - loss 0.05787434\n",
      "2019-08-10 17:37:51,423 epoch 8 - iter 189/277 - loss 0.05596756\n",
      "2019-08-10 17:37:52,084 epoch 8 - iter 216/277 - loss 0.05749742\n",
      "2019-08-10 17:37:52,721 epoch 8 - iter 243/277 - loss 0.05610425\n",
      "2019-08-10 17:37:53,332 epoch 8 - iter 270/277 - loss 0.05399881\n",
      "2019-08-10 17:37:53,987 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:37:53,992 EPOCH 8 done: loss 0.0536 - lr 0.1000 - bad epochs 3\n",
      "2019-08-10 17:37:55,715 DEV : loss 0.055850569158792496 - score 0.982\n",
      "2019-08-10 17:37:55,718 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:37:57,171 epoch 9 - iter 0/277 - loss 0.00760292\n",
      "2019-08-10 17:37:57,832 epoch 9 - iter 27/277 - loss 0.06353220\n",
      "2019-08-10 17:37:58,515 epoch 9 - iter 54/277 - loss 0.06926178\n",
      "2019-08-10 17:37:59,214 epoch 9 - iter 81/277 - loss 0.05446111\n",
      "2019-08-10 17:37:59,884 epoch 9 - iter 108/277 - loss 0.05142176\n",
      "2019-08-10 17:38:00,548 epoch 9 - iter 135/277 - loss 0.05069463\n",
      "2019-08-10 17:38:01,261 epoch 9 - iter 162/277 - loss 0.04545231\n",
      "2019-08-10 17:38:01,917 epoch 9 - iter 189/277 - loss 0.04938590\n",
      "2019-08-10 17:38:02,631 epoch 9 - iter 216/277 - loss 0.04532432\n",
      "2019-08-10 17:38:03,285 epoch 9 - iter 243/277 - loss 0.04722315\n",
      "2019-08-10 17:38:03,915 epoch 9 - iter 270/277 - loss 0.04633191\n",
      "2019-08-10 17:38:04,572 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:38:04,574 EPOCH 9 done: loss 0.0472 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:38:06,324 DEV : loss 1.1638864278793335 - score 0.6126\n",
      "2019-08-10 17:38:06,328 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:38:07,756 epoch 10 - iter 0/277 - loss 0.93384349\n",
      "2019-08-10 17:38:08,489 epoch 10 - iter 27/277 - loss 0.07608177\n",
      "2019-08-10 17:38:09,130 epoch 10 - iter 54/277 - loss 0.05622161\n",
      "2019-08-10 17:38:11,795 epoch 10 - iter 81/277 - loss 0.04811536\n",
      "2019-08-10 17:38:12,463 epoch 10 - iter 108/277 - loss 0.04352998\n",
      "2019-08-10 17:38:13,120 epoch 10 - iter 135/277 - loss 0.04280632\n",
      "2019-08-10 17:38:13,799 epoch 10 - iter 162/277 - loss 0.04492799\n",
      "2019-08-10 17:38:14,447 epoch 10 - iter 189/277 - loss 0.04738894\n",
      "2019-08-10 17:38:15,111 epoch 10 - iter 216/277 - loss 0.05090752\n",
      "2019-08-10 17:38:15,762 epoch 10 - iter 243/277 - loss 0.05073660\n",
      "2019-08-10 17:38:16,338 epoch 10 - iter 270/277 - loss 0.04764686\n",
      "2019-08-10 17:38:16,981 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:38:16,984 EPOCH 10 done: loss 0.0467 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 17:38:18,731 DEV : loss 0.04130379110574722 - score 0.991\n",
      "2019-08-10 17:38:18,737 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:38:18,739 Testing using best model ...\n",
      "2019-08-10 17:38:20,503 0.9856\t0.9856\t0.9856\n",
      "2019-08-10 17:38:20,507 \n",
      "MICRO_AVG: acc 0.9716 - f1-score 0.9856\n",
      "MACRO_AVG: acc 0.9417 - f1-score 0.9695\n",
      "ham        tp: 475 - fp: 4 - fn: 4 - tn: 72 - precision: 0.9916 - recall: 0.9916 - accuracy: 0.9834 - f1-score: 0.9916\n",
      "spam       tp: 72 - fp: 4 - fn: 4 - tn: 475 - precision: 0.9474 - recall: 0.9474 - accuracy: 0.9000 - f1-score: 0.9474\n",
      "2019-08-10 17:38:20,510 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:38:20,513 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:38:20,516 Training run: 3\n",
      "2019-08-10 17:38:20,524 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:38:20,526 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:38:21,495 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:38:22,952 epoch 1 - iter 0/277 - loss 0.63541687\n",
      "2019-08-10 17:38:23,689 epoch 1 - iter 27/277 - loss 0.40977421\n",
      "2019-08-10 17:38:24,375 epoch 1 - iter 54/277 - loss 0.38187152\n",
      "2019-08-10 17:38:25,050 epoch 1 - iter 81/277 - loss 0.34052525\n",
      "2019-08-10 17:38:25,729 epoch 1 - iter 108/277 - loss 0.32797455\n",
      "2019-08-10 17:38:26,401 epoch 1 - iter 135/277 - loss 0.30393741\n",
      "2019-08-10 17:38:27,072 epoch 1 - iter 162/277 - loss 0.29701488\n",
      "2019-08-10 17:38:27,739 epoch 1 - iter 189/277 - loss 0.27780739\n",
      "2019-08-10 17:38:28,445 epoch 1 - iter 216/277 - loss 0.26594553\n",
      "2019-08-10 17:38:29,097 epoch 1 - iter 243/277 - loss 0.25230030\n",
      "2019-08-10 17:38:29,734 epoch 1 - iter 270/277 - loss 0.25398451\n",
      "2019-08-10 17:38:30,385 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:38:30,388 EPOCH 1 done: loss 0.2531 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:38:32,138 DEV : loss 0.17199061810970306 - score 0.9369\n",
      "2019-08-10 17:38:32,142 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:38:33,624 epoch 2 - iter 0/277 - loss 0.02318654\n",
      "2019-08-10 17:38:34,347 epoch 2 - iter 27/277 - loss 0.15458760\n",
      "2019-08-10 17:38:37,017 epoch 2 - iter 54/277 - loss 0.15513173\n",
      "2019-08-10 17:38:37,686 epoch 2 - iter 81/277 - loss 0.14565114\n",
      "2019-08-10 17:38:38,330 epoch 2 - iter 108/277 - loss 0.14381279\n",
      "2019-08-10 17:38:38,974 epoch 2 - iter 135/277 - loss 0.13273317\n",
      "2019-08-10 17:38:39,631 epoch 2 - iter 162/277 - loss 0.13438795\n",
      "2019-08-10 17:38:40,302 epoch 2 - iter 189/277 - loss 0.12658679\n",
      "2019-08-10 17:38:40,950 epoch 2 - iter 216/277 - loss 0.12759465\n",
      "2019-08-10 17:38:41,640 epoch 2 - iter 243/277 - loss 0.12897170\n",
      "2019-08-10 17:38:42,213 epoch 2 - iter 270/277 - loss 0.12405557\n",
      "2019-08-10 17:38:42,860 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:38:42,862 EPOCH 2 done: loss 0.1220 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:38:44,591 DEV : loss 0.09776700288057327 - score 0.9676\n",
      "2019-08-10 17:38:44,595 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:38:46,062 epoch 3 - iter 0/277 - loss 0.06538323\n",
      "2019-08-10 17:38:46,776 epoch 3 - iter 27/277 - loss 0.08272582\n",
      "2019-08-10 17:38:47,434 epoch 3 - iter 54/277 - loss 0.09897392\n",
      "2019-08-10 17:38:48,122 epoch 3 - iter 81/277 - loss 0.09920641\n",
      "2019-08-10 17:38:48,777 epoch 3 - iter 108/277 - loss 0.08527295\n",
      "2019-08-10 17:38:49,436 epoch 3 - iter 135/277 - loss 0.09805161\n",
      "2019-08-10 17:38:50,137 epoch 3 - iter 162/277 - loss 0.11007206\n",
      "2019-08-10 17:38:50,798 epoch 3 - iter 189/277 - loss 0.10145551\n",
      "2019-08-10 17:38:51,480 epoch 3 - iter 216/277 - loss 0.09768142\n",
      "2019-08-10 17:38:52,152 epoch 3 - iter 243/277 - loss 0.10223418\n",
      "2019-08-10 17:38:52,786 epoch 3 - iter 270/277 - loss 0.10234653\n",
      "2019-08-10 17:38:53,425 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:38:53,430 EPOCH 3 done: loss 0.1046 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:38:55,156 DEV : loss 0.09387268126010895 - score 0.9676\n",
      "2019-08-10 17:38:55,160 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:38:56,643 epoch 4 - iter 0/277 - loss 0.09557102\n",
      "2019-08-10 17:38:59,327 epoch 4 - iter 27/277 - loss 0.08695405\n",
      "2019-08-10 17:38:59,973 epoch 4 - iter 54/277 - loss 0.08403425\n",
      "2019-08-10 17:39:00,663 epoch 4 - iter 81/277 - loss 0.08841316\n",
      "2019-08-10 17:39:01,329 epoch 4 - iter 108/277 - loss 0.09097944\n",
      "2019-08-10 17:39:01,965 epoch 4 - iter 135/277 - loss 0.08578643\n",
      "2019-08-10 17:39:02,635 epoch 4 - iter 162/277 - loss 0.08706890\n",
      "2019-08-10 17:39:03,302 epoch 4 - iter 189/277 - loss 0.08381861\n",
      "2019-08-10 17:39:03,935 epoch 4 - iter 216/277 - loss 0.08512113\n",
      "2019-08-10 17:39:04,596 epoch 4 - iter 243/277 - loss 0.08577349\n",
      "2019-08-10 17:39:05,175 epoch 4 - iter 270/277 - loss 0.08922241\n",
      "2019-08-10 17:39:05,821 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:39:05,824 EPOCH 4 done: loss 0.0878 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 17:39:07,561 DEV : loss 0.06540561467409134 - score 0.982\n",
      "2019-08-10 17:39:07,565 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:39:09,011 epoch 5 - iter 0/277 - loss 0.02162272\n",
      "2019-08-10 17:39:09,674 epoch 5 - iter 27/277 - loss 0.09799992\n",
      "2019-08-10 17:39:10,351 epoch 5 - iter 54/277 - loss 0.08843589\n",
      "2019-08-10 17:39:11,030 epoch 5 - iter 81/277 - loss 0.07571553\n",
      "2019-08-10 17:39:11,695 epoch 5 - iter 108/277 - loss 0.08211533\n",
      "2019-08-10 17:39:12,350 epoch 5 - iter 135/277 - loss 0.08029959\n",
      "2019-08-10 17:39:13,060 epoch 5 - iter 162/277 - loss 0.08206967\n",
      "2019-08-10 17:39:13,755 epoch 5 - iter 189/277 - loss 0.08714934\n",
      "2019-08-10 17:39:14,398 epoch 5 - iter 216/277 - loss 0.08171649\n",
      "2019-08-10 17:39:15,061 epoch 5 - iter 243/277 - loss 0.07966110\n",
      "2019-08-10 17:39:15,666 epoch 5 - iter 270/277 - loss 0.07713224\n",
      "2019-08-10 17:39:16,304 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:39:16,307 EPOCH 5 done: loss 0.0774 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:39:20,160 DEV : loss 0.15502837300300598 - score 0.955\n",
      "2019-08-10 17:39:20,163 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:39:21,617 epoch 6 - iter 0/277 - loss 0.00177976\n",
      "2019-08-10 17:39:22,368 epoch 6 - iter 27/277 - loss 0.05326536\n",
      "2019-08-10 17:39:23,053 epoch 6 - iter 54/277 - loss 0.04251834\n",
      "2019-08-10 17:39:23,726 epoch 6 - iter 81/277 - loss 0.04679404\n",
      "2019-08-10 17:39:24,405 epoch 6 - iter 108/277 - loss 0.06537581\n",
      "2019-08-10 17:39:25,108 epoch 6 - iter 135/277 - loss 0.06036587\n",
      "2019-08-10 17:39:25,772 epoch 6 - iter 162/277 - loss 0.06845777\n",
      "2019-08-10 17:39:26,468 epoch 6 - iter 189/277 - loss 0.07087801\n",
      "2019-08-10 17:39:27,161 epoch 6 - iter 216/277 - loss 0.07128965\n",
      "2019-08-10 17:39:27,820 epoch 6 - iter 243/277 - loss 0.06825472\n",
      "2019-08-10 17:39:28,453 epoch 6 - iter 270/277 - loss 0.06891367\n",
      "2019-08-10 17:39:29,049 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:39:29,051 EPOCH 6 done: loss 0.0686 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 17:39:30,816 DEV : loss 0.07603307068347931 - score 0.9676\n",
      "2019-08-10 17:39:30,822 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:39:32,270 epoch 7 - iter 0/277 - loss 0.06851839\n",
      "2019-08-10 17:39:32,950 epoch 7 - iter 27/277 - loss 0.05623269\n",
      "2019-08-10 17:39:33,651 epoch 7 - iter 54/277 - loss 0.05709595\n",
      "2019-08-10 17:39:34,338 epoch 7 - iter 81/277 - loss 0.06040616\n",
      "2019-08-10 17:39:34,997 epoch 7 - iter 108/277 - loss 0.05781106\n",
      "2019-08-10 17:39:35,673 epoch 7 - iter 135/277 - loss 0.05925650\n",
      "2019-08-10 17:39:36,321 epoch 7 - iter 162/277 - loss 0.05549724\n",
      "2019-08-10 17:39:37,000 epoch 7 - iter 189/277 - loss 0.05741767\n",
      "2019-08-10 17:39:37,690 epoch 7 - iter 216/277 - loss 0.05726592\n",
      "2019-08-10 17:39:40,225 epoch 7 - iter 243/277 - loss 0.05782507\n",
      "2019-08-10 17:39:40,841 epoch 7 - iter 270/277 - loss 0.05506705\n",
      "2019-08-10 17:39:41,468 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:39:41,471 EPOCH 7 done: loss 0.0560 - lr 0.1000 - bad epochs 2\n",
      "2019-08-10 17:39:43,223 DEV : loss 0.05265090987086296 - score 0.9802\n",
      "2019-08-10 17:39:43,227 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:39:44,632 epoch 8 - iter 0/277 - loss 0.00191851\n",
      "2019-08-10 17:39:45,395 epoch 8 - iter 27/277 - loss 0.04017853\n",
      "2019-08-10 17:39:46,092 epoch 8 - iter 54/277 - loss 0.07660952\n",
      "2019-08-10 17:39:46,760 epoch 8 - iter 81/277 - loss 0.05986355\n",
      "2019-08-10 17:39:47,426 epoch 8 - iter 108/277 - loss 0.05058863\n",
      "2019-08-10 17:39:48,101 epoch 8 - iter 135/277 - loss 0.04908758\n",
      "2019-08-10 17:39:48,773 epoch 8 - iter 162/277 - loss 0.05253318\n",
      "2019-08-10 17:39:49,451 epoch 8 - iter 189/277 - loss 0.05777810\n",
      "2019-08-10 17:39:50,124 epoch 8 - iter 216/277 - loss 0.05649125\n",
      "2019-08-10 17:39:50,791 epoch 8 - iter 243/277 - loss 0.05677437\n",
      "2019-08-10 17:39:51,415 epoch 8 - iter 270/277 - loss 0.06091612\n",
      "2019-08-10 17:39:52,042 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:39:52,045 EPOCH 8 done: loss 0.0616 - lr 0.1000 - bad epochs 3\n",
      "2019-08-10 17:39:53,793 DEV : loss 0.07135652005672455 - score 0.9766\n",
      "Epoch     7: reducing learning rate of group 0 to 5.0000e-02.                        \n",
      " 40%|████      | 4/10 [1:37:32<2:16:12, 1362.08s/it, best loss: 0.011799999999999996]2019-08-10 17:39:53,803 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:39:55,270 epoch 9 - iter 0/277 - loss 0.06845462\n",
      "2019-08-10 17:39:55,963 epoch 9 - iter 27/277 - loss 0.03197649\n",
      "2019-08-10 17:39:56,658 epoch 9 - iter 54/277 - loss 0.02607351\n",
      "2019-08-10 17:39:57,317 epoch 9 - iter 81/277 - loss 0.03513764\n",
      "2019-08-10 17:39:57,956 epoch 9 - iter 108/277 - loss 0.03581484\n",
      "2019-08-10 17:39:58,623 epoch 9 - iter 135/277 - loss 0.03669775\n",
      "2019-08-10 17:39:59,308 epoch 9 - iter 162/277 - loss 0.03553306\n",
      "2019-08-10 17:39:59,975 epoch 9 - iter 189/277 - loss 0.03495712\n",
      "2019-08-10 17:40:00,652 epoch 9 - iter 216/277 - loss 0.03894604\n",
      "2019-08-10 17:40:03,206 epoch 9 - iter 243/277 - loss 0.03920227\n",
      "2019-08-10 17:40:03,814 epoch 9 - iter 270/277 - loss 0.04117696\n",
      "2019-08-10 17:40:04,471 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:04,476 EPOCH 9 done: loss 0.0409 - lr 0.0500 - bad epochs 0\n",
      "2019-08-10 17:40:06,186 DEV : loss 0.05003819987177849 - score 0.982\n",
      "2019-08-10 17:40:06,189 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:07,602 epoch 10 - iter 0/277 - loss 0.00478928\n",
      "2019-08-10 17:40:08,282 epoch 10 - iter 27/277 - loss 0.04309238\n",
      "2019-08-10 17:40:08,952 epoch 10 - iter 54/277 - loss 0.03685932\n",
      "2019-08-10 17:40:09,596 epoch 10 - iter 81/277 - loss 0.03484638\n",
      "2019-08-10 17:40:10,282 epoch 10 - iter 108/277 - loss 0.03232870\n",
      "2019-08-10 17:40:10,967 epoch 10 - iter 135/277 - loss 0.03535708\n",
      "2019-08-10 17:40:11,671 epoch 10 - iter 162/277 - loss 0.03136599\n",
      "2019-08-10 17:40:12,335 epoch 10 - iter 189/277 - loss 0.03409941\n",
      "2019-08-10 17:40:13,032 epoch 10 - iter 216/277 - loss 0.03438167\n",
      "2019-08-10 17:40:13,707 epoch 10 - iter 243/277 - loss 0.03556171\n",
      "2019-08-10 17:40:14,300 epoch 10 - iter 270/277 - loss 0.03542151\n",
      "2019-08-10 17:40:14,912 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:14,915 EPOCH 10 done: loss 0.0360 - lr 0.0500 - bad epochs 1\n",
      "2019-08-10 17:40:16,658 DEV : loss 0.0456671305000782 - score 0.9856\n",
      "2019-08-10 17:40:16,664 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:16,666 Testing using best model ...\n",
      "2019-08-10 17:40:18,418 0.9802\t0.9802\t0.9802\n",
      "2019-08-10 17:40:18,424 \n",
      "MICRO_AVG: acc 0.9611 - f1-score 0.9802\n",
      "MACRO_AVG: acc 0.9231 - f1-score 0.9592\n",
      "ham        tp: 471 - fp: 3 - fn: 8 - tn: 73 - precision: 0.9937 - recall: 0.9833 - accuracy: 0.9772 - f1-score: 0.9885\n",
      "spam       tp: 73 - fp: 8 - fn: 3 - tn: 471 - precision: 0.9012 - recall: 0.9605 - accuracy: 0.8690 - f1-score: 0.9299\n",
      "2019-08-10 17:40:18,427 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:18,430 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:18,432 Done evaluating parameter combination:\n",
      "2019-08-10 17:40:18,434 \tdropout: 0.3063031897430457\n",
      "2019-08-10 17:40:18,438 \tembeddings: /tmp/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-08-10 17:40:18,439 \thidden_size: 64\n",
      "2019-08-10 17:40:18,442 \tlearning_rate: 0.1\n",
      "2019-08-10 17:40:18,446 \tmini_batch_size: 16\n",
      "2019-08-10 17:40:18,450 \trnn_layers: 1\n",
      "2019-08-10 17:40:18,452 score: 0.06044444444444443\n",
      "2019-08-10 17:40:18,456 variance: 0.010394465185185182\n",
      "2019-08-10 17:40:18,458 test_score: 0.9802\n",
      "\n",
      "2019-08-10 17:40:18,460 ----------------------------------------------------------------------------------------------------\n",
      " 50%|█████     | 5/10 [1:37:56<1:28:25, 1061.09s/it, best loss: 0.011799999999999996]2019-08-10 17:40:18,470 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:18,472 Evaluation run: 6\n",
      "2019-08-10 17:40:18,474 Evaluating parameter combination:\n",
      "2019-08-10 17:40:18,478 \tdropout: 0.3231632321497964\n",
      "2019-08-10 17:40:18,482 \tembeddings: /tmp/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-08-10 17:40:18,484 \thidden_size: 64\n",
      "2019-08-10 17:40:18,486 \tlearning_rate: 0.15\n",
      "2019-08-10 17:40:18,488 \tmini_batch_size: 16\n",
      "2019-08-10 17:40:18,490 \trnn_layers: 1\n",
      "2019-08-10 17:40:18,493 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:21,148 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:21,151 Training run: 1\n",
      "2019-08-10 17:40:21,158 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:21,161 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:40:22,172 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:23,603 epoch 1 - iter 0/277 - loss 0.73114419\n",
      "2019-08-10 17:40:24,319 epoch 1 - iter 27/277 - loss 0.41742226\n",
      "2019-08-10 17:40:24,979 epoch 1 - iter 54/277 - loss 0.36195370\n",
      "2019-08-10 17:40:25,670 epoch 1 - iter 81/277 - loss 0.35031771\n",
      "2019-08-10 17:40:26,313 epoch 1 - iter 108/277 - loss 0.32910833\n",
      "2019-08-10 17:40:26,958 epoch 1 - iter 135/277 - loss 0.31073096\n",
      "2019-08-10 17:40:27,634 epoch 1 - iter 162/277 - loss 0.30375857\n",
      "2019-08-10 17:40:28,282 epoch 1 - iter 189/277 - loss 0.28011570\n",
      "2019-08-10 17:40:30,912 epoch 1 - iter 216/277 - loss 0.27077783\n",
      "2019-08-10 17:40:31,577 epoch 1 - iter 243/277 - loss 0.25936968\n",
      "2019-08-10 17:40:32,189 epoch 1 - iter 270/277 - loss 0.25193894\n",
      "2019-08-10 17:40:32,863 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:32,866 EPOCH 1 done: loss 0.2557 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:40:34,605 DEV : loss 0.2857668399810791 - score 0.8901\n",
      "2019-08-10 17:40:34,611 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:36,017 epoch 2 - iter 0/277 - loss 0.21193984\n",
      "2019-08-10 17:40:36,758 epoch 2 - iter 27/277 - loss 0.19169513\n",
      "2019-08-10 17:40:37,391 epoch 2 - iter 54/277 - loss 0.16218844\n",
      "2019-08-10 17:40:38,091 epoch 2 - iter 81/277 - loss 0.14074489\n",
      "2019-08-10 17:40:38,761 epoch 2 - iter 108/277 - loss 0.13870613\n",
      "2019-08-10 17:40:39,412 epoch 2 - iter 135/277 - loss 0.14285877\n",
      "2019-08-10 17:40:40,090 epoch 2 - iter 162/277 - loss 0.14259050\n",
      "2019-08-10 17:40:40,794 epoch 2 - iter 189/277 - loss 0.13751786\n",
      "2019-08-10 17:40:41,441 epoch 2 - iter 216/277 - loss 0.13930584\n",
      "2019-08-10 17:40:42,106 epoch 2 - iter 243/277 - loss 0.13930837\n",
      "2019-08-10 17:40:42,722 epoch 2 - iter 270/277 - loss 0.13737114\n",
      "2019-08-10 17:40:43,348 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:43,351 EPOCH 2 done: loss 0.1365 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:40:45,111 DEV : loss 0.08585193753242493 - score 0.9676\n",
      "2019-08-10 17:40:45,114 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:46,578 epoch 3 - iter 0/277 - loss 0.02675985\n",
      "2019-08-10 17:40:47,289 epoch 3 - iter 27/277 - loss 0.13111964\n",
      "2019-08-10 17:40:47,945 epoch 3 - iter 54/277 - loss 0.11920784\n",
      "2019-08-10 17:40:48,622 epoch 3 - iter 81/277 - loss 0.12903014\n",
      "2019-08-10 17:40:49,278 epoch 3 - iter 108/277 - loss 0.11759433\n",
      "2019-08-10 17:40:49,977 epoch 3 - iter 135/277 - loss 0.12268738\n",
      "2019-08-10 17:40:52,551 epoch 3 - iter 162/277 - loss 0.11180461\n",
      "2019-08-10 17:40:53,209 epoch 3 - iter 189/277 - loss 0.10493763\n",
      "2019-08-10 17:40:53,865 epoch 3 - iter 216/277 - loss 0.10308314\n",
      "2019-08-10 17:40:54,532 epoch 3 - iter 243/277 - loss 0.10145410\n",
      "2019-08-10 17:40:55,143 epoch 3 - iter 270/277 - loss 0.10214486\n",
      "2019-08-10 17:40:55,766 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:55,769 EPOCH 3 done: loss 0.1021 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:40:57,515 DEV : loss 0.09895523637533188 - score 0.9694\n",
      "2019-08-10 17:40:57,519 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:40:58,950 epoch 4 - iter 0/277 - loss 0.00968325\n",
      "2019-08-10 17:40:59,667 epoch 4 - iter 27/277 - loss 0.08645213\n",
      "2019-08-10 17:41:00,319 epoch 4 - iter 54/277 - loss 0.07883076\n",
      "2019-08-10 17:41:00,999 epoch 4 - iter 81/277 - loss 0.08603941\n",
      "2019-08-10 17:41:01,682 epoch 4 - iter 108/277 - loss 0.09603207\n",
      "2019-08-10 17:41:02,368 epoch 4 - iter 135/277 - loss 0.10219332\n",
      "2019-08-10 17:41:03,039 epoch 4 - iter 162/277 - loss 0.10138650\n",
      "2019-08-10 17:41:03,734 epoch 4 - iter 189/277 - loss 0.09829177\n",
      "2019-08-10 17:41:04,404 epoch 4 - iter 216/277 - loss 0.09446297\n",
      "2019-08-10 17:41:05,101 epoch 4 - iter 243/277 - loss 0.08863508\n",
      "2019-08-10 17:41:05,692 epoch 4 - iter 270/277 - loss 0.08816271\n",
      "2019-08-10 17:41:06,312 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:41:06,315 EPOCH 4 done: loss 0.0867 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:41:08,093 DEV : loss 0.07009565830230713 - score 0.9802\n",
      "2019-08-10 17:41:08,097 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:41:09,529 epoch 5 - iter 0/277 - loss 0.00821283\n",
      "2019-08-10 17:41:10,227 epoch 5 - iter 27/277 - loss 0.08189333\n",
      "2019-08-10 17:41:10,918 epoch 5 - iter 54/277 - loss 0.07560986\n",
      "2019-08-10 17:41:11,608 epoch 5 - iter 81/277 - loss 0.07854218\n",
      "2019-08-10 17:41:12,265 epoch 5 - iter 108/277 - loss 0.08619491\n",
      "2019-08-10 17:41:14,875 epoch 5 - iter 135/277 - loss 0.08182016\n",
      "2019-08-10 17:41:15,531 epoch 5 - iter 162/277 - loss 0.07516810\n",
      "2019-08-10 17:41:16,197 epoch 5 - iter 189/277 - loss 0.07355859\n",
      "2019-08-10 17:41:16,834 epoch 5 - iter 216/277 - loss 0.07530650\n",
      "2019-08-10 17:41:17,484 epoch 5 - iter 243/277 - loss 0.07571314\n",
      "2019-08-10 17:41:18,126 epoch 5 - iter 270/277 - loss 0.07078735\n",
      "2019-08-10 17:41:18,800 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:41:18,803 EPOCH 5 done: loss 0.0715 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:41:20,536 DEV : loss 0.058755941689014435 - score 0.982\n",
      "2019-08-10 17:41:20,539 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:41:22,008 epoch 6 - iter 0/277 - loss 0.00233027\n",
      "2019-08-10 17:41:22,731 epoch 6 - iter 27/277 - loss 0.10165562\n",
      "2019-08-10 17:41:23,428 epoch 6 - iter 54/277 - loss 0.08009411\n",
      "2019-08-10 17:41:24,103 epoch 6 - iter 81/277 - loss 0.06805390\n",
      "2019-08-10 17:41:24,770 epoch 6 - iter 108/277 - loss 0.07063211\n",
      "2019-08-10 17:41:25,432 epoch 6 - iter 135/277 - loss 0.06038896\n",
      "2019-08-10 17:41:26,104 epoch 6 - iter 162/277 - loss 0.07434176\n",
      "2019-08-10 17:41:26,777 epoch 6 - iter 189/277 - loss 0.07220718\n",
      "2019-08-10 17:41:27,445 epoch 6 - iter 216/277 - loss 0.06861844\n",
      "2019-08-10 17:41:28,116 epoch 6 - iter 243/277 - loss 0.07459556\n",
      "2019-08-10 17:41:28,728 epoch 6 - iter 270/277 - loss 0.07206507\n",
      "2019-08-10 17:41:29,337 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:41:29,340 EPOCH 6 done: loss 0.0713 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:41:31,074 DEV : loss 0.6623684167861938 - score 0.8523\n",
      "2019-08-10 17:41:31,078 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:41:32,504 epoch 7 - iter 0/277 - loss 0.36437857\n",
      "2019-08-10 17:41:33,199 epoch 7 - iter 27/277 - loss 0.10655776\n",
      "2019-08-10 17:41:33,864 epoch 7 - iter 54/277 - loss 0.11794048\n",
      "2019-08-10 17:41:34,525 epoch 7 - iter 81/277 - loss 0.09983704\n",
      "2019-08-10 17:41:35,210 epoch 7 - iter 108/277 - loss 0.08122243\n",
      "2019-08-10 17:41:37,829 epoch 7 - iter 135/277 - loss 0.07110430\n",
      "2019-08-10 17:41:38,467 epoch 7 - iter 162/277 - loss 0.07137349\n",
      "2019-08-10 17:41:39,117 epoch 7 - iter 189/277 - loss 0.06386667\n",
      "2019-08-10 17:41:39,776 epoch 7 - iter 216/277 - loss 0.06549525\n",
      "2019-08-10 17:41:40,442 epoch 7 - iter 243/277 - loss 0.06601231\n",
      "2019-08-10 17:41:41,053 epoch 7 - iter 270/277 - loss 0.06570603\n",
      "2019-08-10 17:41:41,682 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:41:41,685 EPOCH 7 done: loss 0.0647 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:41:43,406 DEV : loss 0.049313612282276154 - score 0.9802\n",
      "2019-08-10 17:41:43,410 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:41:44,829 epoch 8 - iter 0/277 - loss 0.00502155\n",
      "2019-08-10 17:41:45,552 epoch 8 - iter 27/277 - loss 0.06098501\n",
      "2019-08-10 17:41:46,227 epoch 8 - iter 54/277 - loss 0.05598631\n",
      "2019-08-10 17:41:46,895 epoch 8 - iter 81/277 - loss 0.04268260\n",
      "2019-08-10 17:41:47,583 epoch 8 - iter 108/277 - loss 0.04717530\n",
      "2019-08-10 17:41:48,272 epoch 8 - iter 135/277 - loss 0.05391225\n",
      "2019-08-10 17:41:48,947 epoch 8 - iter 162/277 - loss 0.04936039\n",
      "2019-08-10 17:41:49,604 epoch 8 - iter 189/277 - loss 0.05527348\n",
      "2019-08-10 17:41:50,293 epoch 8 - iter 216/277 - loss 0.05329661\n",
      "2019-08-10 17:41:50,965 epoch 8 - iter 243/277 - loss 0.05682603\n",
      "2019-08-10 17:41:51,576 epoch 8 - iter 270/277 - loss 0.05745733\n",
      "2019-08-10 17:41:52,201 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:41:52,204 EPOCH 8 done: loss 0.0565 - lr 0.1500 - bad epochs 2\n",
      "2019-08-10 17:41:53,938 DEV : loss 0.05502326413989067 - score 0.9802\n",
      "2019-08-10 17:41:53,943 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:41:55,413 epoch 9 - iter 0/277 - loss 0.18926324\n",
      "2019-08-10 17:41:56,107 epoch 9 - iter 27/277 - loss 0.04433343\n",
      "2019-08-10 17:41:56,765 epoch 9 - iter 54/277 - loss 0.03882501\n",
      "2019-08-10 17:41:57,430 epoch 9 - iter 81/277 - loss 0.03583281\n",
      "2019-08-10 17:42:00,047 epoch 9 - iter 108/277 - loss 0.04399687\n",
      "2019-08-10 17:42:00,712 epoch 9 - iter 135/277 - loss 0.04465370\n",
      "2019-08-10 17:42:01,386 epoch 9 - iter 162/277 - loss 0.05243569\n",
      "2019-08-10 17:42:02,049 epoch 9 - iter 189/277 - loss 0.05080161\n",
      "2019-08-10 17:42:02,711 epoch 9 - iter 216/277 - loss 0.05016571\n",
      "2019-08-10 17:42:03,369 epoch 9 - iter 243/277 - loss 0.05133095\n",
      "2019-08-10 17:42:03,962 epoch 9 - iter 270/277 - loss 0.04925539\n",
      "2019-08-10 17:42:04,619 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:42:04,621 EPOCH 9 done: loss 0.0506 - lr 0.1500 - bad epochs 3\n",
      "2019-08-10 17:42:06,367 DEV : loss 0.044449202716350555 - score 0.982\n",
      "Epoch     8: reducing learning rate of group 0 to 7.5000e-02.                        \n",
      " 50%|█████     | 5/10 [1:39:44<1:28:25, 1061.09s/it, best loss: 0.011799999999999996]2019-08-10 17:42:06,379 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:42:07,895 epoch 10 - iter 0/277 - loss 0.08140860\n",
      "2019-08-10 17:42:08,587 epoch 10 - iter 27/277 - loss 0.02732700\n",
      "2019-08-10 17:42:09,273 epoch 10 - iter 54/277 - loss 0.03181345\n",
      "2019-08-10 17:42:09,948 epoch 10 - iter 81/277 - loss 0.03169536\n",
      "2019-08-10 17:42:10,652 epoch 10 - iter 108/277 - loss 0.03681839\n",
      "2019-08-10 17:42:11,320 epoch 10 - iter 135/277 - loss 0.04011759\n",
      "2019-08-10 17:42:11,996 epoch 10 - iter 162/277 - loss 0.04039900\n",
      "2019-08-10 17:42:12,685 epoch 10 - iter 189/277 - loss 0.03697036\n",
      "2019-08-10 17:42:13,388 epoch 10 - iter 216/277 - loss 0.03662294\n",
      "2019-08-10 17:42:14,077 epoch 10 - iter 243/277 - loss 0.03574260\n",
      "2019-08-10 17:42:14,695 epoch 10 - iter 270/277 - loss 0.03454230\n",
      "2019-08-10 17:42:15,304 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:42:15,306 EPOCH 10 done: loss 0.0349 - lr 0.0750 - bad epochs 0\n",
      "2019-08-10 17:42:17,046 DEV : loss 0.08884531259536743 - score 0.9712\n",
      "2019-08-10 17:42:17,050 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:42:17,053 Testing using best model ...\n",
      "2019-08-10 17:42:18,807 0.9694\t0.9694\t0.9694\n",
      "2019-08-10 17:42:18,811 \n",
      "MICRO_AVG: acc 0.9406 - f1-score 0.9694\n",
      "MACRO_AVG: acc 0.8899 - f1-score 0.9400999999999999\n",
      "ham        tp: 463 - fp: 1 - fn: 16 - tn: 75 - precision: 0.9978 - recall: 0.9666 - accuracy: 0.9646 - f1-score: 0.9820\n",
      "spam       tp: 75 - fp: 16 - fn: 1 - tn: 463 - precision: 0.8242 - recall: 0.9868 - accuracy: 0.8152 - f1-score: 0.8982\n",
      "2019-08-10 17:42:18,817 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:42:18,820 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:42:18,822 Training run: 2\n",
      "2019-08-10 17:42:18,832 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:42:18,835 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:42:19,807 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:42:21,289 epoch 1 - iter 0/277 - loss 0.62389386\n",
      "2019-08-10 17:42:22,005 epoch 1 - iter 27/277 - loss 0.37064610\n",
      "2019-08-10 17:42:24,641 epoch 1 - iter 54/277 - loss 0.34938859\n",
      "2019-08-10 17:42:25,302 epoch 1 - iter 81/277 - loss 0.33441992\n",
      "2019-08-10 17:42:25,964 epoch 1 - iter 108/277 - loss 0.31040203\n",
      "2019-08-10 17:42:26,632 epoch 1 - iter 135/277 - loss 0.30094147\n",
      "2019-08-10 17:42:27,323 epoch 1 - iter 162/277 - loss 0.28949202\n",
      "2019-08-10 17:42:27,954 epoch 1 - iter 189/277 - loss 0.27630751\n",
      "2019-08-10 17:42:28,638 epoch 1 - iter 216/277 - loss 0.25978353\n",
      "2019-08-10 17:42:29,284 epoch 1 - iter 243/277 - loss 0.25371492\n",
      "2019-08-10 17:42:29,862 epoch 1 - iter 270/277 - loss 0.23797810\n",
      "2019-08-10 17:42:30,505 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:42:30,508 EPOCH 1 done: loss 0.2343 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:42:32,265 DEV : loss 0.12020628899335861 - score 0.9586\n",
      "2019-08-10 17:42:32,270 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:42:33,699 epoch 2 - iter 0/277 - loss 0.09246333\n",
      "2019-08-10 17:42:34,423 epoch 2 - iter 27/277 - loss 0.15781146\n",
      "2019-08-10 17:42:35,104 epoch 2 - iter 54/277 - loss 0.16036269\n",
      "2019-08-10 17:42:35,772 epoch 2 - iter 81/277 - loss 0.15845432\n",
      "2019-08-10 17:42:36,453 epoch 2 - iter 108/277 - loss 0.13671759\n",
      "2019-08-10 17:42:37,123 epoch 2 - iter 135/277 - loss 0.13461409\n",
      "2019-08-10 17:42:37,793 epoch 2 - iter 162/277 - loss 0.14501710\n",
      "2019-08-10 17:42:38,477 epoch 2 - iter 189/277 - loss 0.13942068\n",
      "2019-08-10 17:42:39,165 epoch 2 - iter 216/277 - loss 0.13589760\n",
      "2019-08-10 17:42:39,807 epoch 2 - iter 243/277 - loss 0.13217921\n",
      "2019-08-10 17:42:40,427 epoch 2 - iter 270/277 - loss 0.13181463\n",
      "2019-08-10 17:42:41,094 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:42:41,098 EPOCH 2 done: loss 0.1306 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:42:42,828 DEV : loss 0.08373232930898666 - score 0.9658\n",
      "2019-08-10 17:42:42,832 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:42:44,272 epoch 3 - iter 0/277 - loss 0.07330357\n",
      "2019-08-10 17:42:47,029 epoch 3 - iter 27/277 - loss 0.06419821\n",
      "2019-08-10 17:42:47,809 epoch 3 - iter 54/277 - loss 0.06409072\n",
      "2019-08-10 17:42:48,772 epoch 3 - iter 81/277 - loss 0.09676095\n",
      "2019-08-10 17:42:49,470 epoch 3 - iter 108/277 - loss 0.08940908\n",
      "2019-08-10 17:42:50,186 epoch 3 - iter 135/277 - loss 0.10288128\n",
      "2019-08-10 17:42:50,886 epoch 3 - iter 162/277 - loss 0.09860134\n",
      "2019-08-10 17:42:51,581 epoch 3 - iter 189/277 - loss 0.09885867\n",
      "2019-08-10 17:42:52,254 epoch 3 - iter 216/277 - loss 0.10354563\n",
      "2019-08-10 17:42:52,889 epoch 3 - iter 243/277 - loss 0.10032860\n",
      "2019-08-10 17:42:53,503 epoch 3 - iter 270/277 - loss 0.09649871\n",
      "2019-08-10 17:42:54,144 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:42:54,147 EPOCH 3 done: loss 0.0946 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:42:55,875 DEV : loss 0.07602544128894806 - score 0.9748\n",
      "2019-08-10 17:42:55,879 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:42:57,306 epoch 4 - iter 0/277 - loss 0.01165985\n",
      "2019-08-10 17:42:57,986 epoch 4 - iter 27/277 - loss 0.10700135\n",
      "2019-08-10 17:42:58,681 epoch 4 - iter 54/277 - loss 0.08033827\n",
      "2019-08-10 17:42:59,379 epoch 4 - iter 81/277 - loss 0.06943160\n",
      "2019-08-10 17:43:00,037 epoch 4 - iter 108/277 - loss 0.07228408\n",
      "2019-08-10 17:43:00,699 epoch 4 - iter 135/277 - loss 0.09088438\n",
      "2019-08-10 17:43:01,403 epoch 4 - iter 162/277 - loss 0.08782128\n",
      "2019-08-10 17:43:02,058 epoch 4 - iter 189/277 - loss 0.08294186\n",
      "2019-08-10 17:43:02,740 epoch 4 - iter 216/277 - loss 0.08643564\n",
      "2019-08-10 17:43:03,416 epoch 4 - iter 243/277 - loss 0.08305246\n",
      "2019-08-10 17:43:04,030 epoch 4 - iter 270/277 - loss 0.08036295\n",
      "2019-08-10 17:43:04,653 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:43:04,657 EPOCH 4 done: loss 0.0831 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:43:08,449 DEV : loss 0.06260324269533157 - score 0.9838\n",
      "2019-08-10 17:43:08,452 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:43:09,881 epoch 5 - iter 0/277 - loss 0.05069253\n",
      "2019-08-10 17:43:10,602 epoch 5 - iter 27/277 - loss 0.03814527\n",
      "2019-08-10 17:43:11,269 epoch 5 - iter 54/277 - loss 0.05240593\n",
      "2019-08-10 17:43:11,941 epoch 5 - iter 81/277 - loss 0.05161777\n",
      "2019-08-10 17:43:12,592 epoch 5 - iter 108/277 - loss 0.06474929\n",
      "2019-08-10 17:43:13,281 epoch 5 - iter 135/277 - loss 0.05523631\n",
      "2019-08-10 17:43:13,941 epoch 5 - iter 162/277 - loss 0.05793501\n",
      "2019-08-10 17:43:14,570 epoch 5 - iter 189/277 - loss 0.06518941\n",
      "2019-08-10 17:43:15,255 epoch 5 - iter 216/277 - loss 0.06522574\n",
      "2019-08-10 17:43:15,933 epoch 5 - iter 243/277 - loss 0.06243091\n",
      "2019-08-10 17:43:16,557 epoch 5 - iter 270/277 - loss 0.06473438\n",
      "2019-08-10 17:43:17,191 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:43:17,194 EPOCH 5 done: loss 0.0642 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:43:18,953 DEV : loss 0.10069483518600464 - score 0.9604\n",
      "2019-08-10 17:43:18,957 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:43:20,394 epoch 6 - iter 0/277 - loss 0.00061247\n",
      "2019-08-10 17:43:21,101 epoch 6 - iter 27/277 - loss 0.09496022\n",
      "2019-08-10 17:43:21,776 epoch 6 - iter 54/277 - loss 0.06592207\n",
      "2019-08-10 17:43:22,448 epoch 6 - iter 81/277 - loss 0.06923586\n",
      "2019-08-10 17:43:23,131 epoch 6 - iter 108/277 - loss 0.07213722\n",
      "2019-08-10 17:43:23,793 epoch 6 - iter 135/277 - loss 0.06485145\n",
      "2019-08-10 17:43:24,470 epoch 6 - iter 162/277 - loss 0.06916175\n",
      "2019-08-10 17:43:25,151 epoch 6 - iter 189/277 - loss 0.06228005\n",
      "2019-08-10 17:43:25,792 epoch 6 - iter 216/277 - loss 0.05969402\n",
      "2019-08-10 17:43:26,440 epoch 6 - iter 243/277 - loss 0.05808136\n",
      "2019-08-10 17:43:27,053 epoch 6 - iter 270/277 - loss 0.05985813\n",
      "2019-08-10 17:43:27,651 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:43:27,654 EPOCH 6 done: loss 0.0605 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:43:31,431 DEV : loss 0.052113864570856094 - score 0.982\n",
      "2019-08-10 17:43:31,434 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:43:32,854 epoch 7 - iter 0/277 - loss 0.00443773\n",
      "2019-08-10 17:43:33,589 epoch 7 - iter 27/277 - loss 0.12504794\n",
      "2019-08-10 17:43:34,217 epoch 7 - iter 54/277 - loss 0.09407689\n",
      "2019-08-10 17:43:34,890 epoch 7 - iter 81/277 - loss 0.07946440\n",
      "2019-08-10 17:43:35,534 epoch 7 - iter 108/277 - loss 0.08062429\n",
      "2019-08-10 17:43:36,211 epoch 7 - iter 135/277 - loss 0.07367456\n",
      "2019-08-10 17:43:36,866 epoch 7 - iter 162/277 - loss 0.06856427\n",
      "2019-08-10 17:43:37,572 epoch 7 - iter 189/277 - loss 0.06012481\n",
      "2019-08-10 17:43:38,206 epoch 7 - iter 216/277 - loss 0.06385088\n",
      "2019-08-10 17:43:38,884 epoch 7 - iter 243/277 - loss 0.06403178\n",
      "2019-08-10 17:43:39,477 epoch 7 - iter 270/277 - loss 0.05943708\n",
      "2019-08-10 17:43:40,096 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:43:40,098 EPOCH 7 done: loss 0.0592 - lr 0.1500 - bad epochs 2\n",
      "2019-08-10 17:43:41,824 DEV : loss 0.07487902045249939 - score 0.973\n",
      "2019-08-10 17:43:41,828 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:43:43,282 epoch 8 - iter 0/277 - loss 0.12855543\n",
      "2019-08-10 17:43:43,963 epoch 8 - iter 27/277 - loss 0.05304022\n",
      "2019-08-10 17:43:44,620 epoch 8 - iter 54/277 - loss 0.04120598\n",
      "2019-08-10 17:43:45,343 epoch 8 - iter 81/277 - loss 0.04927134\n",
      "2019-08-10 17:43:46,018 epoch 8 - iter 108/277 - loss 0.04484797\n",
      "2019-08-10 17:43:46,675 epoch 8 - iter 135/277 - loss 0.04266590\n",
      "2019-08-10 17:43:47,351 epoch 8 - iter 162/277 - loss 0.04341334\n",
      "2019-08-10 17:43:48,028 epoch 8 - iter 189/277 - loss 0.04620778\n",
      "2019-08-10 17:43:48,730 epoch 8 - iter 216/277 - loss 0.04412264\n",
      "2019-08-10 17:43:49,397 epoch 8 - iter 243/277 - loss 0.04278615\n",
      "2019-08-10 17:43:51,912 epoch 8 - iter 270/277 - loss 0.04265122\n",
      "2019-08-10 17:43:52,548 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:43:52,550 EPOCH 8 done: loss 0.0433 - lr 0.1500 - bad epochs 3\n",
      "2019-08-10 17:43:54,297 DEV : loss 0.04770231619477272 - score 0.982\n",
      "Epoch     7: reducing learning rate of group 0 to 7.5000e-02.                        \n",
      " 50%|█████     | 5/10 [1:41:32<1:28:25, 1061.09s/it, best loss: 0.011799999999999996]2019-08-10 17:43:54,310 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:43:55,784 epoch 9 - iter 0/277 - loss 0.01619454\n",
      "2019-08-10 17:43:56,481 epoch 9 - iter 27/277 - loss 0.04025069\n",
      "2019-08-10 17:43:57,162 epoch 9 - iter 54/277 - loss 0.03857726\n",
      "2019-08-10 17:43:57,827 epoch 9 - iter 81/277 - loss 0.03425728\n",
      "2019-08-10 17:43:58,495 epoch 9 - iter 108/277 - loss 0.03344922\n",
      "2019-08-10 17:43:59,137 epoch 9 - iter 135/277 - loss 0.03035524\n",
      "2019-08-10 17:43:59,805 epoch 9 - iter 162/277 - loss 0.02878350\n",
      "2019-08-10 17:44:00,498 epoch 9 - iter 189/277 - loss 0.02930854\n",
      "2019-08-10 17:44:01,148 epoch 9 - iter 216/277 - loss 0.02890517\n",
      "2019-08-10 17:44:01,846 epoch 9 - iter 243/277 - loss 0.03000697\n",
      "2019-08-10 17:44:02,435 epoch 9 - iter 270/277 - loss 0.03234680\n",
      "2019-08-10 17:44:03,060 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:44:03,063 EPOCH 9 done: loss 0.0319 - lr 0.0750 - bad epochs 0\n",
      "2019-08-10 17:44:04,798 DEV : loss 0.043246541172266006 - score 0.9838\n",
      "2019-08-10 17:44:04,801 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:44:06,220 epoch 10 - iter 0/277 - loss 0.23004885\n",
      "2019-08-10 17:44:06,953 epoch 10 - iter 27/277 - loss 0.04990045\n",
      "2019-08-10 17:44:07,623 epoch 10 - iter 54/277 - loss 0.03815321\n",
      "2019-08-10 17:44:08,288 epoch 10 - iter 81/277 - loss 0.03107204\n",
      "2019-08-10 17:44:08,960 epoch 10 - iter 108/277 - loss 0.03148102\n",
      "2019-08-10 17:44:09,620 epoch 10 - iter 135/277 - loss 0.02841376\n",
      "2019-08-10 17:44:10,294 epoch 10 - iter 162/277 - loss 0.02936062\n",
      "2019-08-10 17:44:10,974 epoch 10 - iter 189/277 - loss 0.02719887\n",
      "2019-08-10 17:44:11,633 epoch 10 - iter 216/277 - loss 0.02797055\n",
      "2019-08-10 17:44:12,306 epoch 10 - iter 243/277 - loss 0.03101149\n",
      "2019-08-10 17:44:14,838 epoch 10 - iter 270/277 - loss 0.03199689\n",
      "2019-08-10 17:44:15,456 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:44:15,459 EPOCH 10 done: loss 0.0328 - lr 0.0750 - bad epochs 1\n",
      "2019-08-10 17:44:17,169 DEV : loss 0.26957592368125916 - score 0.9117\n",
      "2019-08-10 17:44:17,173 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:44:17,176 Testing using best model ...\n",
      "2019-08-10 17:44:18,912 0.9081\t0.9081\t0.9081\n",
      "2019-08-10 17:44:18,916 \n",
      "MICRO_AVG: acc 0.8317 - f1-score 0.9081\n",
      "MACRO_AVG: acc 0.7445 - f1-score 0.8451\n",
      "ham        tp: 429 - fp: 1 - fn: 50 - tn: 75 - precision: 0.9977 - recall: 0.8956 - accuracy: 0.8938 - f1-score: 0.9439\n",
      "spam       tp: 75 - fp: 50 - fn: 1 - tn: 429 - precision: 0.6000 - recall: 0.9868 - accuracy: 0.5952 - f1-score: 0.7463\n",
      "2019-08-10 17:44:18,919 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:44:18,922 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:44:18,925 Training run: 3\n",
      "2019-08-10 17:44:18,934 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:44:18,937 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:44:19,930 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:44:21,374 epoch 1 - iter 0/277 - loss 0.72502458\n",
      "2019-08-10 17:44:22,083 epoch 1 - iter 27/277 - loss 0.42821499\n",
      "2019-08-10 17:44:22,746 epoch 1 - iter 54/277 - loss 0.37107288\n",
      "2019-08-10 17:44:23,442 epoch 1 - iter 81/277 - loss 0.34127626\n",
      "2019-08-10 17:44:24,130 epoch 1 - iter 108/277 - loss 0.31423147\n",
      "2019-08-10 17:44:24,759 epoch 1 - iter 135/277 - loss 0.29595743\n",
      "2019-08-10 17:44:25,442 epoch 1 - iter 162/277 - loss 0.28580365\n",
      "2019-08-10 17:44:26,106 epoch 1 - iter 189/277 - loss 0.27916436\n",
      "2019-08-10 17:44:26,782 epoch 1 - iter 216/277 - loss 0.26741446\n",
      "2019-08-10 17:44:27,475 epoch 1 - iter 243/277 - loss 0.25800336\n",
      "2019-08-10 17:44:28,086 epoch 1 - iter 270/277 - loss 0.24762963\n",
      "2019-08-10 17:44:28,693 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:44:28,696 EPOCH 1 done: loss 0.2456 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:44:30,438 DEV : loss 0.12881092727184296 - score 0.9586\n",
      "2019-08-10 17:44:30,442 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:44:31,936 epoch 2 - iter 0/277 - loss 0.03433086\n",
      "2019-08-10 17:44:32,652 epoch 2 - iter 27/277 - loss 0.17820872\n",
      "2019-08-10 17:44:33,367 epoch 2 - iter 54/277 - loss 0.18397354\n",
      "2019-08-10 17:44:34,048 epoch 2 - iter 81/277 - loss 0.15800426\n",
      "2019-08-10 17:44:34,730 epoch 2 - iter 108/277 - loss 0.16256799\n",
      "2019-08-10 17:44:35,393 epoch 2 - iter 135/277 - loss 0.16423942\n",
      "2019-08-10 17:44:36,097 epoch 2 - iter 162/277 - loss 0.15263401\n",
      "2019-08-10 17:44:36,774 epoch 2 - iter 189/277 - loss 0.14662015\n",
      "2019-08-10 17:44:37,470 epoch 2 - iter 216/277 - loss 0.14520110\n",
      "2019-08-10 17:44:40,079 epoch 2 - iter 243/277 - loss 0.14103130\n",
      "2019-08-10 17:44:40,707 epoch 2 - iter 270/277 - loss 0.14146920\n",
      "2019-08-10 17:44:41,344 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:44:41,348 EPOCH 2 done: loss 0.1415 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:44:43,097 DEV : loss 0.19748076796531677 - score 0.9279\n",
      "2019-08-10 17:44:43,100 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:44:44,518 epoch 3 - iter 0/277 - loss 0.12053123\n",
      "2019-08-10 17:44:45,253 epoch 3 - iter 27/277 - loss 0.06619630\n",
      "2019-08-10 17:44:45,956 epoch 3 - iter 54/277 - loss 0.05453200\n",
      "2019-08-10 17:44:46,613 epoch 3 - iter 81/277 - loss 0.08058402\n",
      "2019-08-10 17:44:47,284 epoch 3 - iter 108/277 - loss 0.09067184\n",
      "2019-08-10 17:44:47,959 epoch 3 - iter 135/277 - loss 0.10657950\n",
      "2019-08-10 17:44:48,658 epoch 3 - iter 162/277 - loss 0.10623934\n",
      "2019-08-10 17:44:49,328 epoch 3 - iter 189/277 - loss 0.10344578\n",
      "2019-08-10 17:44:49,998 epoch 3 - iter 216/277 - loss 0.10307829\n",
      "2019-08-10 17:44:50,671 epoch 3 - iter 243/277 - loss 0.09993591\n",
      "2019-08-10 17:44:51,280 epoch 3 - iter 270/277 - loss 0.09428519\n",
      "2019-08-10 17:44:51,940 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:44:51,945 EPOCH 3 done: loss 0.0948 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:44:53,672 DEV : loss 0.07395719736814499 - score 0.973\n",
      "2019-08-10 17:44:53,676 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:44:55,151 epoch 4 - iter 0/277 - loss 0.02015735\n",
      "2019-08-10 17:44:55,829 epoch 4 - iter 27/277 - loss 0.08993127\n",
      "2019-08-10 17:44:56,508 epoch 4 - iter 54/277 - loss 0.11252892\n",
      "2019-08-10 17:44:57,178 epoch 4 - iter 81/277 - loss 0.09865072\n",
      "2019-08-10 17:44:57,843 epoch 4 - iter 108/277 - loss 0.09278083\n",
      "2019-08-10 17:44:58,514 epoch 4 - iter 135/277 - loss 0.10128906\n",
      "2019-08-10 17:44:59,190 epoch 4 - iter 162/277 - loss 0.09327516\n",
      "2019-08-10 17:44:59,831 epoch 4 - iter 189/277 - loss 0.08806084\n",
      "2019-08-10 17:45:02,442 epoch 4 - iter 216/277 - loss 0.08797210\n",
      "2019-08-10 17:45:03,084 epoch 4 - iter 243/277 - loss 0.08103924\n",
      "2019-08-10 17:45:03,728 epoch 4 - iter 270/277 - loss 0.08414476\n",
      "2019-08-10 17:45:04,333 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:45:04,339 EPOCH 4 done: loss 0.0841 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:45:06,084 DEV : loss 0.07176642119884491 - score 0.9748\n",
      "2019-08-10 17:45:06,090 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:45:07,528 epoch 5 - iter 0/277 - loss 0.01368969\n",
      "2019-08-10 17:45:08,280 epoch 5 - iter 27/277 - loss 0.08472797\n",
      "2019-08-10 17:45:08,964 epoch 5 - iter 54/277 - loss 0.09268247\n",
      "2019-08-10 17:45:09,639 epoch 5 - iter 81/277 - loss 0.08311208\n",
      "2019-08-10 17:45:10,298 epoch 5 - iter 108/277 - loss 0.08198709\n",
      "2019-08-10 17:45:10,975 epoch 5 - iter 135/277 - loss 0.08056563\n",
      "2019-08-10 17:45:11,679 epoch 5 - iter 162/277 - loss 0.07542887\n",
      "2019-08-10 17:45:12,365 epoch 5 - iter 189/277 - loss 0.08243881\n",
      "2019-08-10 17:45:13,029 epoch 5 - iter 216/277 - loss 0.08387034\n",
      "2019-08-10 17:45:13,700 epoch 5 - iter 243/277 - loss 0.08220088\n",
      "2019-08-10 17:45:14,316 epoch 5 - iter 270/277 - loss 0.07593389\n",
      "2019-08-10 17:45:14,968 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:45:14,971 EPOCH 5 done: loss 0.0760 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:45:16,713 DEV : loss 0.0719255656003952 - score 0.9748\n",
      "2019-08-10 17:45:16,717 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:45:18,174 epoch 6 - iter 0/277 - loss 0.00918532\n",
      "2019-08-10 17:45:18,880 epoch 6 - iter 27/277 - loss 0.11205709\n",
      "2019-08-10 17:45:19,521 epoch 6 - iter 54/277 - loss 0.08776670\n",
      "2019-08-10 17:45:20,225 epoch 6 - iter 81/277 - loss 0.08402646\n",
      "2019-08-10 17:45:20,922 epoch 6 - iter 108/277 - loss 0.07692347\n",
      "2019-08-10 17:45:21,586 epoch 6 - iter 135/277 - loss 0.08084680\n",
      "2019-08-10 17:45:22,263 epoch 6 - iter 162/277 - loss 0.07415764\n",
      "2019-08-10 17:45:24,842 epoch 6 - iter 189/277 - loss 0.07541056\n",
      "2019-08-10 17:45:25,493 epoch 6 - iter 216/277 - loss 0.07351595\n",
      "2019-08-10 17:45:26,163 epoch 6 - iter 243/277 - loss 0.06997250\n",
      "2019-08-10 17:45:26,749 epoch 6 - iter 270/277 - loss 0.06504233\n",
      "2019-08-10 17:45:27,380 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:45:27,384 EPOCH 6 done: loss 0.0668 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:45:29,104 DEV : loss 0.05309118703007698 - score 0.9766\n",
      "2019-08-10 17:45:29,108 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:45:30,528 epoch 7 - iter 0/277 - loss 0.06264132\n",
      "2019-08-10 17:45:31,260 epoch 7 - iter 27/277 - loss 0.02387274\n",
      "2019-08-10 17:45:31,933 epoch 7 - iter 54/277 - loss 0.05113920\n",
      "2019-08-10 17:45:32,610 epoch 7 - iter 81/277 - loss 0.05160152\n",
      "2019-08-10 17:45:33,274 epoch 7 - iter 108/277 - loss 0.05403083\n",
      "2019-08-10 17:45:33,940 epoch 7 - iter 135/277 - loss 0.05084153\n",
      "2019-08-10 17:45:34,628 epoch 7 - iter 162/277 - loss 0.05916492\n",
      "2019-08-10 17:45:35,310 epoch 7 - iter 189/277 - loss 0.06331309\n",
      "2019-08-10 17:45:35,989 epoch 7 - iter 216/277 - loss 0.06392485\n",
      "2019-08-10 17:45:36,666 epoch 7 - iter 243/277 - loss 0.06205141\n",
      "2019-08-10 17:45:37,243 epoch 7 - iter 270/277 - loss 0.05980706\n",
      "2019-08-10 17:45:37,886 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:45:37,891 EPOCH 7 done: loss 0.0601 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:45:39,634 DEV : loss 0.06288432329893112 - score 0.9748\n",
      "2019-08-10 17:45:39,640 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:45:41,102 epoch 8 - iter 0/277 - loss 0.00121737\n",
      "2019-08-10 17:45:41,797 epoch 8 - iter 27/277 - loss 0.05594221\n",
      "2019-08-10 17:45:42,460 epoch 8 - iter 54/277 - loss 0.05430278\n",
      "2019-08-10 17:45:43,152 epoch 8 - iter 81/277 - loss 0.05328757\n",
      "2019-08-10 17:45:43,822 epoch 8 - iter 108/277 - loss 0.05670598\n",
      "2019-08-10 17:45:44,486 epoch 8 - iter 135/277 - loss 0.05129988\n",
      "2019-08-10 17:45:47,119 epoch 8 - iter 162/277 - loss 0.05388217\n",
      "2019-08-10 17:45:47,764 epoch 8 - iter 189/277 - loss 0.05435824\n",
      "2019-08-10 17:45:48,445 epoch 8 - iter 216/277 - loss 0.05279303\n",
      "2019-08-10 17:45:49,106 epoch 8 - iter 243/277 - loss 0.05753140\n",
      "2019-08-10 17:45:49,692 epoch 8 - iter 270/277 - loss 0.05649803\n",
      "2019-08-10 17:45:50,335 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:45:50,339 EPOCH 8 done: loss 0.0554 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:45:52,069 DEV : loss 0.049061764031648636 - score 0.982\n",
      "2019-08-10 17:45:52,072 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:45:53,493 epoch 9 - iter 0/277 - loss 0.00996633\n",
      "2019-08-10 17:45:54,223 epoch 9 - iter 27/277 - loss 0.14806045\n",
      "2019-08-10 17:45:54,868 epoch 9 - iter 54/277 - loss 0.09535455\n",
      "2019-08-10 17:45:55,565 epoch 9 - iter 81/277 - loss 0.07179786\n",
      "2019-08-10 17:45:56,246 epoch 9 - iter 108/277 - loss 0.06431616\n",
      "2019-08-10 17:45:56,913 epoch 9 - iter 135/277 - loss 0.06402987\n",
      "2019-08-10 17:45:57,589 epoch 9 - iter 162/277 - loss 0.06562436\n",
      "2019-08-10 17:45:58,260 epoch 9 - iter 189/277 - loss 0.06152582\n",
      "2019-08-10 17:45:58,902 epoch 9 - iter 216/277 - loss 0.05617397\n",
      "2019-08-10 17:45:59,584 epoch 9 - iter 243/277 - loss 0.05255189\n",
      "2019-08-10 17:46:00,179 epoch 9 - iter 270/277 - loss 0.05214537\n",
      "2019-08-10 17:46:00,819 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:00,822 EPOCH 9 done: loss 0.0512 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:46:02,551 DEV : loss 0.0472804456949234 - score 0.982\n",
      "2019-08-10 17:46:02,555 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:03,953 epoch 10 - iter 0/277 - loss 0.00324816\n",
      "2019-08-10 17:46:04,684 epoch 10 - iter 27/277 - loss 0.04310450\n",
      "2019-08-10 17:46:05,370 epoch 10 - iter 54/277 - loss 0.03561747\n",
      "2019-08-10 17:46:06,027 epoch 10 - iter 81/277 - loss 0.03573460\n",
      "2019-08-10 17:46:06,731 epoch 10 - iter 108/277 - loss 0.03420075\n",
      "2019-08-10 17:46:09,324 epoch 10 - iter 135/277 - loss 0.03243155\n",
      "2019-08-10 17:46:10,003 epoch 10 - iter 162/277 - loss 0.03360918\n",
      "2019-08-10 17:46:10,640 epoch 10 - iter 189/277 - loss 0.04331883\n",
      "2019-08-10 17:46:11,297 epoch 10 - iter 216/277 - loss 0.04329400\n",
      "2019-08-10 17:46:11,951 epoch 10 - iter 243/277 - loss 0.04421306\n",
      "2019-08-10 17:46:12,542 epoch 10 - iter 270/277 - loss 0.04334167\n",
      "2019-08-10 17:46:13,177 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:13,180 EPOCH 10 done: loss 0.0426 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:46:14,908 DEV : loss 0.04849633201956749 - score 0.9838\n",
      "2019-08-10 17:46:14,914 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:14,916 Testing using best model ...\n",
      "2019-08-10 17:46:16,643 0.9838\t0.9838\t0.9838\n",
      "2019-08-10 17:46:16,647 \n",
      "MICRO_AVG: acc 0.9681 - f1-score 0.9838\n",
      "MACRO_AVG: acc 0.9365 - f1-score 0.96665\n",
      "ham        tp: 472 - fp: 2 - fn: 7 - tn: 74 - precision: 0.9958 - recall: 0.9854 - accuracy: 0.9813 - f1-score: 0.9906\n",
      "spam       tp: 74 - fp: 7 - fn: 2 - tn: 472 - precision: 0.9136 - recall: 0.9737 - accuracy: 0.8916 - f1-score: 0.9427\n",
      "2019-08-10 17:46:16,649 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:16,653 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:16,655 Done evaluating parameter combination:\n",
      "2019-08-10 17:46:16,659 \tdropout: 0.3231632321497964\n",
      "2019-08-10 17:46:16,662 \tembeddings: /tmp/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-08-10 17:46:16,665 \thidden_size: 64\n",
      "2019-08-10 17:46:16,668 \tlearning_rate: 0.15\n",
      "2019-08-10 17:46:16,670 \tmini_batch_size: 16\n",
      "2019-08-10 17:46:16,674 \trnn_layers: 1\n",
      "2019-08-10 17:46:16,676 score: 0.026811111111111133\n",
      "2019-08-10 17:46:16,679 variance: 0.00038337407407407464\n",
      "2019-08-10 17:46:16,681 test_score: 0.9838\n",
      "\n",
      "2019-08-10 17:46:16,685 ----------------------------------------------------------------------------------------------------\n",
      " 60%|██████    | 6/10 [1:43:55<56:40, 850.23s/it, best loss: 0.011799999999999996]   2019-08-10 17:46:16,699 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:16,700 Evaluation run: 7\n",
      "2019-08-10 17:46:16,704 Evaluating parameter combination:\n",
      "2019-08-10 17:46:16,709 \tdropout: 0.29676245409087676\n",
      "2019-08-10 17:46:16,712 \tembeddings: /tmp/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-08-10 17:46:16,717 \thidden_size: 32\n",
      "2019-08-10 17:46:16,723 \tlearning_rate: 0.15\n",
      "2019-08-10 17:46:16,725 \tmini_batch_size: 16\n",
      "2019-08-10 17:46:16,727 \trnn_layers: 2\n",
      "2019-08-10 17:46:16,729 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:19,383 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:19,385 Training run: 1\n",
      "2019-08-10 17:46:19,394 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:19,396 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:46:20,399 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:21,812 epoch 1 - iter 0/277 - loss 0.63406819\n",
      "2019-08-10 17:46:22,580 epoch 1 - iter 27/277 - loss 0.36880612\n",
      "2019-08-10 17:46:23,329 epoch 1 - iter 54/277 - loss 0.35511173\n",
      "2019-08-10 17:46:24,059 epoch 1 - iter 81/277 - loss 0.33817847\n",
      "2019-08-10 17:46:24,784 epoch 1 - iter 108/277 - loss 0.31378490\n",
      "2019-08-10 17:46:25,503 epoch 1 - iter 135/277 - loss 0.30164708\n",
      "2019-08-10 17:46:26,253 epoch 1 - iter 162/277 - loss 0.28039223\n",
      "2019-08-10 17:46:26,976 epoch 1 - iter 189/277 - loss 0.26714182\n",
      "2019-08-10 17:46:27,698 epoch 1 - iter 216/277 - loss 0.26155739\n",
      "2019-08-10 17:46:28,399 epoch 1 - iter 243/277 - loss 0.24948572\n",
      "2019-08-10 17:46:29,027 epoch 1 - iter 270/277 - loss 0.24366651\n",
      "2019-08-10 17:46:29,661 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:29,665 EPOCH 1 done: loss 0.2418 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:46:31,430 DEV : loss 0.2037198394536972 - score 0.9315\n",
      "2019-08-10 17:46:31,434 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:32,878 epoch 2 - iter 0/277 - loss 0.01619492\n",
      "2019-08-10 17:46:33,643 epoch 2 - iter 27/277 - loss 0.11422362\n",
      "2019-08-10 17:46:34,400 epoch 2 - iter 54/277 - loss 0.13494357\n",
      "2019-08-10 17:46:37,068 epoch 2 - iter 81/277 - loss 0.11480290\n",
      "2019-08-10 17:46:37,774 epoch 2 - iter 108/277 - loss 0.12766247\n",
      "2019-08-10 17:46:38,472 epoch 2 - iter 135/277 - loss 0.12581360\n",
      "2019-08-10 17:46:39,153 epoch 2 - iter 162/277 - loss 0.12852489\n",
      "2019-08-10 17:46:39,860 epoch 2 - iter 189/277 - loss 0.12011667\n",
      "2019-08-10 17:46:40,567 epoch 2 - iter 216/277 - loss 0.11610230\n",
      "2019-08-10 17:46:41,300 epoch 2 - iter 243/277 - loss 0.11799250\n",
      "2019-08-10 17:46:41,960 epoch 2 - iter 270/277 - loss 0.12397867\n",
      "2019-08-10 17:46:42,626 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:42,629 EPOCH 2 done: loss 0.1238 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:46:44,405 DEV : loss 0.08978082239627838 - score 0.9658\n",
      "2019-08-10 17:46:44,409 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:45,849 epoch 3 - iter 0/277 - loss 0.09746679\n",
      "2019-08-10 17:46:46,629 epoch 3 - iter 27/277 - loss 0.08802546\n",
      "2019-08-10 17:46:47,358 epoch 3 - iter 54/277 - loss 0.10233364\n",
      "2019-08-10 17:46:48,087 epoch 3 - iter 81/277 - loss 0.10434961\n",
      "2019-08-10 17:46:48,782 epoch 3 - iter 108/277 - loss 0.10717623\n",
      "2019-08-10 17:46:49,522 epoch 3 - iter 135/277 - loss 0.10363726\n",
      "2019-08-10 17:46:50,224 epoch 3 - iter 162/277 - loss 0.09401951\n",
      "2019-08-10 17:46:50,929 epoch 3 - iter 189/277 - loss 0.09278883\n",
      "2019-08-10 17:46:51,633 epoch 3 - iter 216/277 - loss 0.09578350\n",
      "2019-08-10 17:46:52,380 epoch 3 - iter 243/277 - loss 0.09242981\n",
      "2019-08-10 17:46:53,050 epoch 3 - iter 270/277 - loss 0.08761399\n",
      "2019-08-10 17:46:53,694 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:53,698 EPOCH 3 done: loss 0.0860 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:46:55,462 DEV : loss 0.0872201919555664 - score 0.964\n",
      "2019-08-10 17:46:55,466 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:46:56,886 epoch 4 - iter 0/277 - loss 0.00428303\n",
      "2019-08-10 17:46:57,655 epoch 4 - iter 27/277 - loss 0.11852129\n",
      "2019-08-10 17:47:00,376 epoch 4 - iter 54/277 - loss 0.10567869\n",
      "2019-08-10 17:47:01,072 epoch 4 - iter 81/277 - loss 0.10026488\n",
      "2019-08-10 17:47:01,782 epoch 4 - iter 108/277 - loss 0.09125346\n",
      "2019-08-10 17:47:02,482 epoch 4 - iter 135/277 - loss 0.08504473\n",
      "2019-08-10 17:47:03,194 epoch 4 - iter 162/277 - loss 0.08167637\n",
      "2019-08-10 17:47:03,897 epoch 4 - iter 189/277 - loss 0.07607309\n",
      "2019-08-10 17:47:04,582 epoch 4 - iter 216/277 - loss 0.07017983\n",
      "2019-08-10 17:47:05,260 epoch 4 - iter 243/277 - loss 0.06814158\n",
      "2019-08-10 17:47:05,922 epoch 4 - iter 270/277 - loss 0.06447944\n",
      "2019-08-10 17:47:06,585 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:47:06,588 EPOCH 4 done: loss 0.0649 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:47:08,334 DEV : loss 0.07974032312631607 - score 0.9676\n",
      "2019-08-10 17:47:08,338 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:47:09,787 epoch 5 - iter 0/277 - loss 0.00842933\n",
      "2019-08-10 17:47:10,527 epoch 5 - iter 27/277 - loss 0.08227777\n",
      "2019-08-10 17:47:11,246 epoch 5 - iter 54/277 - loss 0.05926613\n",
      "2019-08-10 17:47:11,959 epoch 5 - iter 81/277 - loss 0.06435129\n",
      "2019-08-10 17:47:12,733 epoch 5 - iter 108/277 - loss 0.07069617\n",
      "2019-08-10 17:47:13,447 epoch 5 - iter 135/277 - loss 0.06602416\n",
      "2019-08-10 17:47:14,184 epoch 5 - iter 162/277 - loss 0.06224179\n",
      "2019-08-10 17:47:14,924 epoch 5 - iter 189/277 - loss 0.06343409\n",
      "2019-08-10 17:47:15,611 epoch 5 - iter 216/277 - loss 0.06344798\n",
      "2019-08-10 17:47:16,393 epoch 5 - iter 243/277 - loss 0.06016467\n",
      "2019-08-10 17:47:17,071 epoch 5 - iter 270/277 - loss 0.05840581\n",
      "2019-08-10 17:47:17,723 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:47:17,726 EPOCH 5 done: loss 0.0581 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:47:19,505 DEV : loss 0.051533110439777374 - score 0.9748\n",
      "2019-08-10 17:47:19,509 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:47:20,987 epoch 6 - iter 0/277 - loss 0.04138657\n",
      "2019-08-10 17:47:23,747 epoch 6 - iter 27/277 - loss 0.03668861\n",
      "2019-08-10 17:47:24,494 epoch 6 - iter 54/277 - loss 0.05538354\n",
      "2019-08-10 17:47:25,188 epoch 6 - iter 81/277 - loss 0.06263869\n",
      "2019-08-10 17:47:25,891 epoch 6 - iter 108/277 - loss 0.06294195\n",
      "2019-08-10 17:47:26,566 epoch 6 - iter 135/277 - loss 0.06066409\n",
      "2019-08-10 17:47:27,301 epoch 6 - iter 162/277 - loss 0.05391355\n",
      "2019-08-10 17:47:27,965 epoch 6 - iter 189/277 - loss 0.05026455\n",
      "2019-08-10 17:47:28,678 epoch 6 - iter 216/277 - loss 0.04911232\n",
      "2019-08-10 17:47:29,352 epoch 6 - iter 243/277 - loss 0.04779947\n",
      "2019-08-10 17:47:29,985 epoch 6 - iter 270/277 - loss 0.04417143\n",
      "2019-08-10 17:47:30,645 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:47:30,650 EPOCH 6 done: loss 0.0467 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:47:32,410 DEV : loss 0.1575462371110916 - score 0.955\n",
      "2019-08-10 17:47:32,414 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:47:33,835 epoch 7 - iter 0/277 - loss 0.26170903\n",
      "2019-08-10 17:47:34,600 epoch 7 - iter 27/277 - loss 0.06207762\n",
      "2019-08-10 17:47:35,318 epoch 7 - iter 54/277 - loss 0.06061723\n",
      "2019-08-10 17:47:36,037 epoch 7 - iter 81/277 - loss 0.05093878\n",
      "2019-08-10 17:47:36,779 epoch 7 - iter 108/277 - loss 0.04674216\n",
      "2019-08-10 17:47:37,503 epoch 7 - iter 135/277 - loss 0.04436473\n",
      "2019-08-10 17:47:38,201 epoch 7 - iter 162/277 - loss 0.04474463\n",
      "2019-08-10 17:47:38,943 epoch 7 - iter 189/277 - loss 0.04460359\n",
      "2019-08-10 17:47:39,663 epoch 7 - iter 216/277 - loss 0.04317272\n",
      "2019-08-10 17:47:40,361 epoch 7 - iter 243/277 - loss 0.04364567\n",
      "2019-08-10 17:47:41,041 epoch 7 - iter 270/277 - loss 0.04033078\n",
      "2019-08-10 17:47:41,664 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:47:41,667 EPOCH 7 done: loss 0.0396 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:47:45,447 DEV : loss 0.04471880570054054 - score 0.9874\n",
      "2019-08-10 17:47:45,449 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:47:46,904 epoch 8 - iter 0/277 - loss 0.00416084\n",
      "2019-08-10 17:47:47,644 epoch 8 - iter 27/277 - loss 0.01894387\n",
      "2019-08-10 17:47:48,372 epoch 8 - iter 54/277 - loss 0.03313251\n",
      "2019-08-10 17:47:49,098 epoch 8 - iter 81/277 - loss 0.03696806\n",
      "2019-08-10 17:47:49,778 epoch 8 - iter 108/277 - loss 0.03143046\n",
      "2019-08-10 17:47:50,485 epoch 8 - iter 135/277 - loss 0.03981536\n",
      "2019-08-10 17:47:51,472 epoch 8 - iter 162/277 - loss 0.03499668\n",
      "2019-08-10 17:47:52,386 epoch 8 - iter 189/277 - loss 0.03535991\n",
      "2019-08-10 17:47:53,165 epoch 8 - iter 216/277 - loss 0.03348895\n",
      "2019-08-10 17:47:53,910 epoch 8 - iter 243/277 - loss 0.03567913\n",
      "2019-08-10 17:47:54,645 epoch 8 - iter 270/277 - loss 0.03321483\n",
      "2019-08-10 17:47:55,300 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:47:55,303 EPOCH 8 done: loss 0.0325 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:47:57,064 DEV : loss 0.04072801396250725 - score 0.9874\n",
      "2019-08-10 17:47:57,070 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:47:58,542 epoch 9 - iter 0/277 - loss 0.00594279\n",
      "2019-08-10 17:47:59,285 epoch 9 - iter 27/277 - loss 0.01631938\n",
      "2019-08-10 17:48:00,024 epoch 9 - iter 54/277 - loss 0.02656669\n",
      "2019-08-10 17:48:00,743 epoch 9 - iter 81/277 - loss 0.02278236\n",
      "2019-08-10 17:48:01,473 epoch 9 - iter 108/277 - loss 0.02417987\n",
      "2019-08-10 17:48:02,205 epoch 9 - iter 135/277 - loss 0.02276668\n",
      "2019-08-10 17:48:02,917 epoch 9 - iter 162/277 - loss 0.02763219\n",
      "2019-08-10 17:48:03,644 epoch 9 - iter 189/277 - loss 0.02426894\n",
      "2019-08-10 17:48:04,332 epoch 9 - iter 216/277 - loss 0.02503065\n",
      "2019-08-10 17:48:05,065 epoch 9 - iter 243/277 - loss 0.02729544\n",
      "2019-08-10 17:48:07,624 epoch 9 - iter 270/277 - loss 0.02884554\n",
      "2019-08-10 17:48:08,267 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:48:08,270 EPOCH 9 done: loss 0.0283 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:48:10,012 DEV : loss 0.04383860528469086 - score 0.982\n",
      "2019-08-10 17:48:10,016 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:48:11,500 epoch 10 - iter 0/277 - loss 0.00148963\n",
      "2019-08-10 17:48:12,220 epoch 10 - iter 27/277 - loss 0.05071269\n",
      "2019-08-10 17:48:12,985 epoch 10 - iter 54/277 - loss 0.03817737\n",
      "2019-08-10 17:48:13,717 epoch 10 - iter 81/277 - loss 0.02948609\n",
      "2019-08-10 17:48:14,416 epoch 10 - iter 108/277 - loss 0.02457883\n",
      "2019-08-10 17:48:15,112 epoch 10 - iter 135/277 - loss 0.02235040\n",
      "2019-08-10 17:48:15,838 epoch 10 - iter 162/277 - loss 0.02471705\n",
      "2019-08-10 17:48:16,532 epoch 10 - iter 189/277 - loss 0.02348627\n",
      "2019-08-10 17:48:17,265 epoch 10 - iter 216/277 - loss 0.02346335\n",
      "2019-08-10 17:48:17,957 epoch 10 - iter 243/277 - loss 0.02508099\n",
      "2019-08-10 17:48:18,630 epoch 10 - iter 270/277 - loss 0.02529095\n",
      "2019-08-10 17:48:19,271 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:48:19,273 EPOCH 10 done: loss 0.0249 - lr 0.1500 - bad epochs 2\n",
      "2019-08-10 17:48:21,056 DEV : loss 0.03818436339497566 - score 0.9856\n",
      "2019-08-10 17:48:21,061 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:48:21,063 Testing using best model ...\n",
      "2019-08-10 17:48:22,838 0.9892\t0.9892\t0.9892\n",
      "2019-08-10 17:48:22,842 \n",
      "MICRO_AVG: acc 0.9786 - f1-score 0.9892\n",
      "MACRO_AVG: acc 0.9554 - f1-score 0.97685\n",
      "ham        tp: 477 - fp: 4 - fn: 2 - tn: 72 - precision: 0.9917 - recall: 0.9958 - accuracy: 0.9876 - f1-score: 0.9937\n",
      "spam       tp: 72 - fp: 2 - fn: 4 - tn: 477 - precision: 0.9730 - recall: 0.9474 - accuracy: 0.9231 - f1-score: 0.9600\n",
      "2019-08-10 17:48:22,845 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:48:22,849 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:48:22,852 Training run: 2\n",
      "2019-08-10 17:48:22,860 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:48:22,862 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:48:23,852 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:48:25,263 epoch 1 - iter 0/277 - loss 0.70856708\n",
      "2019-08-10 17:48:25,989 epoch 1 - iter 27/277 - loss 0.40932014\n",
      "2019-08-10 17:48:26,701 epoch 1 - iter 54/277 - loss 0.37925507\n",
      "2019-08-10 17:48:27,426 epoch 1 - iter 81/277 - loss 0.35552643\n",
      "2019-08-10 17:48:28,163 epoch 1 - iter 108/277 - loss 0.32887954\n",
      "2019-08-10 17:48:28,848 epoch 1 - iter 135/277 - loss 0.30624728\n",
      "2019-08-10 17:48:29,570 epoch 1 - iter 162/277 - loss 0.29334736\n",
      "2019-08-10 17:48:30,306 epoch 1 - iter 189/277 - loss 0.27476890\n",
      "2019-08-10 17:48:32,945 epoch 1 - iter 216/277 - loss 0.25832024\n",
      "2019-08-10 17:48:33,670 epoch 1 - iter 243/277 - loss 0.24423749\n",
      "2019-08-10 17:48:34,324 epoch 1 - iter 270/277 - loss 0.24431872\n",
      "2019-08-10 17:48:34,988 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:48:34,993 EPOCH 1 done: loss 0.2430 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:48:36,769 DEV : loss 0.2836538553237915 - score 0.8811\n",
      "2019-08-10 17:48:36,773 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:48:38,158 epoch 2 - iter 0/277 - loss 0.10582580\n",
      "2019-08-10 17:48:38,952 epoch 2 - iter 27/277 - loss 0.19133711\n",
      "2019-08-10 17:48:39,670 epoch 2 - iter 54/277 - loss 0.14446036\n",
      "2019-08-10 17:48:40,363 epoch 2 - iter 81/277 - loss 0.13134350\n",
      "2019-08-10 17:48:41,067 epoch 2 - iter 108/277 - loss 0.15048920\n",
      "2019-08-10 17:48:41,813 epoch 2 - iter 135/277 - loss 0.14670079\n",
      "2019-08-10 17:48:42,519 epoch 2 - iter 162/277 - loss 0.13864668\n",
      "2019-08-10 17:48:43,235 epoch 2 - iter 189/277 - loss 0.14281814\n",
      "2019-08-10 17:48:43,951 epoch 2 - iter 216/277 - loss 0.13632670\n",
      "2019-08-10 17:48:44,670 epoch 2 - iter 243/277 - loss 0.13524477\n",
      "2019-08-10 17:48:45,380 epoch 2 - iter 270/277 - loss 0.13296788\n",
      "2019-08-10 17:48:46,027 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:48:46,030 EPOCH 2 done: loss 0.1337 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:48:47,791 DEV : loss 0.12027755379676819 - score 0.9604\n",
      "2019-08-10 17:48:47,797 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:48:49,293 epoch 3 - iter 0/277 - loss 0.37037981\n",
      "2019-08-10 17:48:50,035 epoch 3 - iter 27/277 - loss 0.08387938\n",
      "2019-08-10 17:48:50,741 epoch 3 - iter 54/277 - loss 0.08521335\n",
      "2019-08-10 17:48:51,486 epoch 3 - iter 81/277 - loss 0.07879202\n",
      "2019-08-10 17:48:52,212 epoch 3 - iter 108/277 - loss 0.06982754\n",
      "2019-08-10 17:48:52,904 epoch 3 - iter 135/277 - loss 0.08096662\n",
      "2019-08-10 17:48:53,600 epoch 3 - iter 162/277 - loss 0.07604500\n",
      "2019-08-10 17:48:56,229 epoch 3 - iter 189/277 - loss 0.07744044\n",
      "2019-08-10 17:48:56,928 epoch 3 - iter 216/277 - loss 0.08038615\n",
      "2019-08-10 17:48:57,627 epoch 3 - iter 243/277 - loss 0.08222296\n",
      "2019-08-10 17:48:58,281 epoch 3 - iter 270/277 - loss 0.08258547\n",
      "2019-08-10 17:48:58,939 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:48:58,942 EPOCH 3 done: loss 0.0814 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:49:00,702 DEV : loss 0.07937973737716675 - score 0.9622\n",
      "2019-08-10 17:49:00,708 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:49:02,125 epoch 4 - iter 0/277 - loss 0.00932728\n",
      "2019-08-10 17:49:02,864 epoch 4 - iter 27/277 - loss 0.07897929\n",
      "2019-08-10 17:49:03,580 epoch 4 - iter 54/277 - loss 0.07683001\n",
      "2019-08-10 17:49:04,307 epoch 4 - iter 81/277 - loss 0.07623106\n",
      "2019-08-10 17:49:05,042 epoch 4 - iter 108/277 - loss 0.07637638\n",
      "2019-08-10 17:49:05,752 epoch 4 - iter 135/277 - loss 0.07684249\n",
      "2019-08-10 17:49:06,490 epoch 4 - iter 162/277 - loss 0.07851525\n",
      "2019-08-10 17:49:07,179 epoch 4 - iter 189/277 - loss 0.07613831\n",
      "2019-08-10 17:49:07,916 epoch 4 - iter 216/277 - loss 0.07327852\n",
      "2019-08-10 17:49:08,629 epoch 4 - iter 243/277 - loss 0.07030447\n",
      "2019-08-10 17:49:09,284 epoch 4 - iter 270/277 - loss 0.06924501\n",
      "2019-08-10 17:49:09,895 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:49:09,898 EPOCH 4 done: loss 0.0682 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:49:11,712 DEV : loss 0.06131543964147568 - score 0.973\n",
      "2019-08-10 17:49:11,716 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:49:13,159 epoch 5 - iter 0/277 - loss 0.00940440\n",
      "2019-08-10 17:49:13,921 epoch 5 - iter 27/277 - loss 0.09441794\n",
      "2019-08-10 17:49:14,626 epoch 5 - iter 54/277 - loss 0.06462678\n",
      "2019-08-10 17:49:15,352 epoch 5 - iter 81/277 - loss 0.07281596\n",
      "2019-08-10 17:49:16,084 epoch 5 - iter 108/277 - loss 0.07553466\n",
      "2019-08-10 17:49:18,747 epoch 5 - iter 135/277 - loss 0.08169090\n",
      "2019-08-10 17:49:19,410 epoch 5 - iter 162/277 - loss 0.07733186\n",
      "2019-08-10 17:49:20,149 epoch 5 - iter 189/277 - loss 0.07193789\n",
      "2019-08-10 17:49:20,820 epoch 5 - iter 216/277 - loss 0.06866516\n",
      "2019-08-10 17:49:21,505 epoch 5 - iter 243/277 - loss 0.06399705\n",
      "2019-08-10 17:49:22,143 epoch 5 - iter 270/277 - loss 0.06281652\n",
      "2019-08-10 17:49:22,783 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:49:22,788 EPOCH 5 done: loss 0.0627 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:49:24,555 DEV : loss 0.0650344118475914 - score 0.9766\n",
      "2019-08-10 17:49:24,558 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:49:25,969 epoch 6 - iter 0/277 - loss 0.15405761\n",
      "2019-08-10 17:49:26,726 epoch 6 - iter 27/277 - loss 0.04346229\n",
      "2019-08-10 17:49:27,445 epoch 6 - iter 54/277 - loss 0.04730187\n",
      "2019-08-10 17:49:28,144 epoch 6 - iter 81/277 - loss 0.04458544\n",
      "2019-08-10 17:49:28,880 epoch 6 - iter 108/277 - loss 0.05117522\n",
      "2019-08-10 17:49:29,598 epoch 6 - iter 135/277 - loss 0.05264919\n",
      "2019-08-10 17:49:30,289 epoch 6 - iter 162/277 - loss 0.05108154\n",
      "2019-08-10 17:49:31,027 epoch 6 - iter 189/277 - loss 0.04869110\n",
      "2019-08-10 17:49:31,766 epoch 6 - iter 216/277 - loss 0.04502893\n",
      "2019-08-10 17:49:32,481 epoch 6 - iter 243/277 - loss 0.05089091\n",
      "2019-08-10 17:49:33,115 epoch 6 - iter 270/277 - loss 0.05347215\n",
      "2019-08-10 17:49:33,725 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:49:33,732 EPOCH 6 done: loss 0.0525 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:49:35,472 DEV : loss 0.049459461122751236 - score 0.9748\n",
      "2019-08-10 17:49:35,476 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:49:36,915 epoch 7 - iter 0/277 - loss 0.00362765\n",
      "2019-08-10 17:49:37,657 epoch 7 - iter 27/277 - loss 0.01856285\n",
      "2019-08-10 17:49:38,363 epoch 7 - iter 54/277 - loss 0.03521454\n",
      "2019-08-10 17:49:39,060 epoch 7 - iter 81/277 - loss 0.02886681\n",
      "2019-08-10 17:49:41,791 epoch 7 - iter 108/277 - loss 0.03726694\n",
      "2019-08-10 17:49:42,498 epoch 7 - iter 135/277 - loss 0.03760777\n",
      "2019-08-10 17:49:43,243 epoch 7 - iter 162/277 - loss 0.03365145\n",
      "2019-08-10 17:49:43,951 epoch 7 - iter 189/277 - loss 0.03772547\n",
      "2019-08-10 17:49:44,640 epoch 7 - iter 216/277 - loss 0.03718360\n",
      "2019-08-10 17:49:45,382 epoch 7 - iter 243/277 - loss 0.03611519\n",
      "2019-08-10 17:49:46,050 epoch 7 - iter 270/277 - loss 0.03830721\n",
      "2019-08-10 17:49:46,736 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:49:46,739 EPOCH 7 done: loss 0.0379 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:49:48,537 DEV : loss 0.0450393445789814 - score 0.9802\n",
      "2019-08-10 17:49:48,541 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:49:50,005 epoch 8 - iter 0/277 - loss 0.00374103\n",
      "2019-08-10 17:49:50,777 epoch 8 - iter 27/277 - loss 0.02305844\n",
      "2019-08-10 17:49:51,510 epoch 8 - iter 54/277 - loss 0.03101843\n",
      "2019-08-10 17:49:52,218 epoch 8 - iter 81/277 - loss 0.03278948\n",
      "2019-08-10 17:49:52,919 epoch 8 - iter 108/277 - loss 0.03090290\n",
      "2019-08-10 17:49:53,667 epoch 8 - iter 135/277 - loss 0.02701484\n",
      "2019-08-10 17:49:54,374 epoch 8 - iter 162/277 - loss 0.02924088\n",
      "2019-08-10 17:49:55,081 epoch 8 - iter 189/277 - loss 0.02719809\n",
      "2019-08-10 17:49:55,799 epoch 8 - iter 216/277 - loss 0.03048157\n",
      "2019-08-10 17:49:56,548 epoch 8 - iter 243/277 - loss 0.03353123\n",
      "2019-08-10 17:49:57,190 epoch 8 - iter 270/277 - loss 0.03541954\n",
      "2019-08-10 17:49:57,835 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:49:57,840 EPOCH 8 done: loss 0.0352 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:49:59,599 DEV : loss 0.08328671753406525 - score 0.9676\n",
      "2019-08-10 17:49:59,603 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:50:01,047 epoch 9 - iter 0/277 - loss 0.00736827\n",
      "2019-08-10 17:50:01,766 epoch 9 - iter 27/277 - loss 0.02644580\n",
      "2019-08-10 17:50:02,497 epoch 9 - iter 54/277 - loss 0.02565217\n",
      "2019-08-10 17:50:03,191 epoch 9 - iter 81/277 - loss 0.02157846\n",
      "2019-08-10 17:50:05,886 epoch 9 - iter 108/277 - loss 0.01741566\n",
      "2019-08-10 17:50:06,581 epoch 9 - iter 135/277 - loss 0.02270268\n",
      "2019-08-10 17:50:07,252 epoch 9 - iter 162/277 - loss 0.02353429\n",
      "2019-08-10 17:50:07,967 epoch 9 - iter 189/277 - loss 0.02409371\n",
      "2019-08-10 17:50:08,681 epoch 9 - iter 216/277 - loss 0.02467821\n",
      "2019-08-10 17:50:09,362 epoch 9 - iter 243/277 - loss 0.02443848\n",
      "2019-08-10 17:50:10,030 epoch 9 - iter 270/277 - loss 0.02806909\n",
      "2019-08-10 17:50:10,707 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:50:10,710 EPOCH 9 done: loss 0.0276 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:50:12,488 DEV : loss 0.03898067772388458 - score 0.982\n",
      "2019-08-10 17:50:12,495 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:50:13,934 epoch 10 - iter 0/277 - loss 0.00737989\n",
      "2019-08-10 17:50:14,693 epoch 10 - iter 27/277 - loss 0.02724462\n",
      "2019-08-10 17:50:15,410 epoch 10 - iter 54/277 - loss 0.01857352\n",
      "2019-08-10 17:50:16,127 epoch 10 - iter 81/277 - loss 0.01554658\n",
      "2019-08-10 17:50:16,842 epoch 10 - iter 108/277 - loss 0.01863663\n",
      "2019-08-10 17:50:17,569 epoch 10 - iter 135/277 - loss 0.02003942\n",
      "2019-08-10 17:50:18,304 epoch 10 - iter 162/277 - loss 0.02348881\n",
      "2019-08-10 17:50:19,021 epoch 10 - iter 189/277 - loss 0.02339263\n",
      "2019-08-10 17:50:19,721 epoch 10 - iter 216/277 - loss 0.02284577\n",
      "2019-08-10 17:50:20,453 epoch 10 - iter 243/277 - loss 0.02533808\n",
      "2019-08-10 17:50:21,106 epoch 10 - iter 270/277 - loss 0.02370109\n",
      "2019-08-10 17:50:21,730 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:50:21,734 EPOCH 10 done: loss 0.0239 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:50:23,489 DEV : loss 0.053907547146081924 - score 0.9838\n",
      "2019-08-10 17:50:23,493 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:50:23,496 Testing using best model ...\n",
      "2019-08-10 17:50:25,262 0.982\t0.982\t0.982\n",
      "2019-08-10 17:50:25,266 \n",
      "MICRO_AVG: acc 0.9646 - f1-score 0.982\n",
      "MACRO_AVG: acc 0.9301 - f1-score 0.9631000000000001\n",
      "ham        tp: 471 - fp: 2 - fn: 8 - tn: 74 - precision: 0.9958 - recall: 0.9833 - accuracy: 0.9792 - f1-score: 0.9895\n",
      "spam       tp: 74 - fp: 8 - fn: 2 - tn: 471 - precision: 0.9024 - recall: 0.9737 - accuracy: 0.8810 - f1-score: 0.9367\n",
      "2019-08-10 17:50:25,269 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:50:25,272 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:50:25,274 Training run: 3\n",
      "2019-08-10 17:50:25,283 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:50:25,285 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:50:26,292 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:50:27,750 epoch 1 - iter 0/277 - loss 0.75166273\n",
      "2019-08-10 17:50:28,496 epoch 1 - iter 27/277 - loss 0.34214538\n",
      "2019-08-10 17:50:31,187 epoch 1 - iter 54/277 - loss 0.34257667\n",
      "2019-08-10 17:50:31,894 epoch 1 - iter 81/277 - loss 0.31667072\n",
      "2019-08-10 17:50:32,611 epoch 1 - iter 108/277 - loss 0.29515442\n",
      "2019-08-10 17:50:33,347 epoch 1 - iter 135/277 - loss 0.29375452\n",
      "2019-08-10 17:50:34,040 epoch 1 - iter 162/277 - loss 0.27265993\n",
      "2019-08-10 17:50:34,759 epoch 1 - iter 189/277 - loss 0.26702491\n",
      "2019-08-10 17:50:35,494 epoch 1 - iter 216/277 - loss 0.25549947\n",
      "2019-08-10 17:50:36,178 epoch 1 - iter 243/277 - loss 0.24519501\n",
      "2019-08-10 17:50:36,847 epoch 1 - iter 270/277 - loss 0.24495172\n",
      "2019-08-10 17:50:37,481 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:50:37,485 EPOCH 1 done: loss 0.2416 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:50:39,243 DEV : loss 0.14875981211662292 - score 0.9495\n",
      "2019-08-10 17:50:39,249 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:50:40,703 epoch 2 - iter 0/277 - loss 0.05088273\n",
      "2019-08-10 17:50:41,440 epoch 2 - iter 27/277 - loss 0.10300671\n",
      "2019-08-10 17:50:42,191 epoch 2 - iter 54/277 - loss 0.10309717\n",
      "2019-08-10 17:50:42,894 epoch 2 - iter 81/277 - loss 0.11503060\n",
      "2019-08-10 17:50:43,629 epoch 2 - iter 108/277 - loss 0.12158004\n",
      "2019-08-10 17:50:44,348 epoch 2 - iter 135/277 - loss 0.12531300\n",
      "2019-08-10 17:50:45,082 epoch 2 - iter 162/277 - loss 0.12754280\n",
      "2019-08-10 17:50:45,805 epoch 2 - iter 189/277 - loss 0.11847031\n",
      "2019-08-10 17:50:46,535 epoch 2 - iter 216/277 - loss 0.11810941\n",
      "2019-08-10 17:50:47,264 epoch 2 - iter 243/277 - loss 0.11545892\n",
      "2019-08-10 17:50:47,942 epoch 2 - iter 270/277 - loss 0.11428781\n",
      "2019-08-10 17:50:48,552 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:50:48,555 EPOCH 2 done: loss 0.1137 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:50:52,353 DEV : loss 0.15879598259925842 - score 0.9514\n",
      "2019-08-10 17:50:52,356 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:50:53,794 epoch 3 - iter 0/277 - loss 0.54493630\n",
      "2019-08-10 17:50:54,552 epoch 3 - iter 27/277 - loss 0.08207216\n",
      "2019-08-10 17:50:55,264 epoch 3 - iter 54/277 - loss 0.07081490\n",
      "2019-08-10 17:50:55,949 epoch 3 - iter 81/277 - loss 0.06423927\n",
      "2019-08-10 17:50:56,674 epoch 3 - iter 108/277 - loss 0.07755210\n",
      "2019-08-10 17:50:57,413 epoch 3 - iter 135/277 - loss 0.09203687\n",
      "2019-08-10 17:50:58,113 epoch 3 - iter 162/277 - loss 0.08834268\n",
      "2019-08-10 17:50:58,844 epoch 3 - iter 189/277 - loss 0.08510316\n",
      "2019-08-10 17:50:59,545 epoch 3 - iter 216/277 - loss 0.08489155\n",
      "2019-08-10 17:51:00,270 epoch 3 - iter 243/277 - loss 0.08796310\n",
      "2019-08-10 17:51:00,911 epoch 3 - iter 270/277 - loss 0.08384425\n",
      "2019-08-10 17:51:01,553 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:51:01,555 EPOCH 3 done: loss 0.0873 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:51:03,301 DEV : loss 0.062293339520692825 - score 0.9748\n",
      "2019-08-10 17:51:03,305 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:51:04,794 epoch 4 - iter 0/277 - loss 0.03474027\n",
      "2019-08-10 17:51:05,537 epoch 4 - iter 27/277 - loss 0.05590683\n",
      "2019-08-10 17:51:06,275 epoch 4 - iter 54/277 - loss 0.07119704\n",
      "2019-08-10 17:51:06,982 epoch 4 - iter 81/277 - loss 0.07110832\n",
      "2019-08-10 17:51:07,706 epoch 4 - iter 108/277 - loss 0.06932737\n",
      "2019-08-10 17:51:08,398 epoch 4 - iter 135/277 - loss 0.06771630\n",
      "2019-08-10 17:51:09,115 epoch 4 - iter 162/277 - loss 0.06831182\n",
      "2019-08-10 17:51:09,842 epoch 4 - iter 189/277 - loss 0.06864854\n",
      "2019-08-10 17:51:10,573 epoch 4 - iter 216/277 - loss 0.06472106\n",
      "2019-08-10 17:51:11,286 epoch 4 - iter 243/277 - loss 0.06393549\n",
      "2019-08-10 17:51:13,817 epoch 4 - iter 270/277 - loss 0.06210493\n",
      "2019-08-10 17:51:14,485 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:51:14,490 EPOCH 4 done: loss 0.0615 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:51:16,209 DEV : loss 0.06395348161458969 - score 0.9694\n",
      "2019-08-10 17:51:16,212 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:51:17,623 epoch 5 - iter 0/277 - loss 0.01665056\n",
      "2019-08-10 17:51:18,390 epoch 5 - iter 27/277 - loss 0.04840360\n",
      "2019-08-10 17:51:19,101 epoch 5 - iter 54/277 - loss 0.04214415\n",
      "2019-08-10 17:51:19,812 epoch 5 - iter 81/277 - loss 0.03835626\n",
      "2019-08-10 17:51:20,544 epoch 5 - iter 108/277 - loss 0.04958482\n",
      "2019-08-10 17:51:21,277 epoch 5 - iter 135/277 - loss 0.04618391\n",
      "2019-08-10 17:51:21,983 epoch 5 - iter 162/277 - loss 0.04434185\n",
      "2019-08-10 17:51:22,711 epoch 5 - iter 189/277 - loss 0.04446889\n",
      "2019-08-10 17:51:23,421 epoch 5 - iter 216/277 - loss 0.05249450\n",
      "2019-08-10 17:51:24,149 epoch 5 - iter 243/277 - loss 0.05059534\n",
      "2019-08-10 17:51:24,775 epoch 5 - iter 270/277 - loss 0.05313968\n",
      "2019-08-10 17:51:25,397 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:51:25,400 EPOCH 5 done: loss 0.0525 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:51:27,159 DEV : loss 0.04313276335597038 - score 0.9856\n",
      "2019-08-10 17:51:27,163 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:51:28,619 epoch 6 - iter 0/277 - loss 0.00477627\n",
      "2019-08-10 17:51:29,358 epoch 6 - iter 27/277 - loss 0.02365755\n",
      "2019-08-10 17:51:30,071 epoch 6 - iter 54/277 - loss 0.04195518\n",
      "2019-08-10 17:51:30,800 epoch 6 - iter 81/277 - loss 0.03852975\n",
      "2019-08-10 17:51:31,555 epoch 6 - iter 108/277 - loss 0.03358884\n",
      "2019-08-10 17:51:32,251 epoch 6 - iter 135/277 - loss 0.04638303\n",
      "2019-08-10 17:51:32,963 epoch 6 - iter 162/277 - loss 0.04890630\n",
      "2019-08-10 17:51:33,655 epoch 6 - iter 189/277 - loss 0.04882949\n",
      "2019-08-10 17:51:34,378 epoch 6 - iter 216/277 - loss 0.05419444\n",
      "2019-08-10 17:51:36,994 epoch 6 - iter 243/277 - loss 0.04996912\n",
      "2019-08-10 17:51:37,631 epoch 6 - iter 270/277 - loss 0.04674521\n",
      "2019-08-10 17:51:38,263 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:51:38,266 EPOCH 6 done: loss 0.0470 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:51:40,027 DEV : loss 0.05970454216003418 - score 0.9838\n",
      "2019-08-10 17:51:40,031 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:51:41,480 epoch 7 - iter 0/277 - loss 0.00608156\n",
      "2019-08-10 17:51:42,259 epoch 7 - iter 27/277 - loss 0.00778913\n",
      "2019-08-10 17:51:42,982 epoch 7 - iter 54/277 - loss 0.01377618\n",
      "2019-08-10 17:51:43,711 epoch 7 - iter 81/277 - loss 0.01652935\n",
      "2019-08-10 17:51:44,392 epoch 7 - iter 108/277 - loss 0.02094007\n",
      "2019-08-10 17:51:45,156 epoch 7 - iter 135/277 - loss 0.02989259\n",
      "2019-08-10 17:51:45,879 epoch 7 - iter 162/277 - loss 0.03038783\n",
      "2019-08-10 17:51:46,571 epoch 7 - iter 189/277 - loss 0.03644829\n",
      "2019-08-10 17:51:47,269 epoch 7 - iter 216/277 - loss 0.03442722\n",
      "2019-08-10 17:51:48,008 epoch 7 - iter 243/277 - loss 0.03372721\n",
      "2019-08-10 17:51:48,641 epoch 7 - iter 270/277 - loss 0.03342517\n",
      "2019-08-10 17:51:49,250 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:51:49,253 EPOCH 7 done: loss 0.0345 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:51:51,016 DEV : loss 0.13970036804676056 - score 0.9459\n",
      "2019-08-10 17:51:51,021 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:51:52,503 epoch 8 - iter 0/277 - loss 0.00884021\n",
      "2019-08-10 17:51:53,282 epoch 8 - iter 27/277 - loss 0.05267436\n",
      "2019-08-10 17:51:54,017 epoch 8 - iter 54/277 - loss 0.03944085\n",
      "2019-08-10 17:51:54,712 epoch 8 - iter 81/277 - loss 0.03177988\n",
      "2019-08-10 17:51:55,428 epoch 8 - iter 108/277 - loss 0.02973078\n",
      "2019-08-10 17:51:56,149 epoch 8 - iter 135/277 - loss 0.03103237\n",
      "2019-08-10 17:51:56,881 epoch 8 - iter 162/277 - loss 0.03231223\n",
      "2019-08-10 17:51:57,581 epoch 8 - iter 189/277 - loss 0.02983752\n",
      "2019-08-10 17:52:00,170 epoch 8 - iter 216/277 - loss 0.03170169\n",
      "2019-08-10 17:52:00,877 epoch 8 - iter 243/277 - loss 0.03391982\n",
      "2019-08-10 17:52:01,532 epoch 8 - iter 270/277 - loss 0.03605663\n",
      "2019-08-10 17:52:02,184 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:02,188 EPOCH 8 done: loss 0.0356 - lr 0.1500 - bad epochs 2\n",
      "2019-08-10 17:52:03,963 DEV : loss 0.04014330357313156 - score 0.982\n",
      "2019-08-10 17:52:03,967 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:05,416 epoch 9 - iter 0/277 - loss 0.00389796\n",
      "2019-08-10 17:52:06,152 epoch 9 - iter 27/277 - loss 0.02586580\n",
      "2019-08-10 17:52:06,899 epoch 9 - iter 54/277 - loss 0.03841833\n",
      "2019-08-10 17:52:07,611 epoch 9 - iter 81/277 - loss 0.02927100\n",
      "2019-08-10 17:52:08,325 epoch 9 - iter 108/277 - loss 0.02458951\n",
      "2019-08-10 17:52:09,035 epoch 9 - iter 135/277 - loss 0.02295505\n",
      "2019-08-10 17:52:09,744 epoch 9 - iter 162/277 - loss 0.02263496\n",
      "2019-08-10 17:52:10,443 epoch 9 - iter 189/277 - loss 0.02787910\n",
      "2019-08-10 17:52:11,128 epoch 9 - iter 216/277 - loss 0.03033594\n",
      "2019-08-10 17:52:11,875 epoch 9 - iter 243/277 - loss 0.02966569\n",
      "2019-08-10 17:52:12,520 epoch 9 - iter 270/277 - loss 0.03147964\n",
      "2019-08-10 17:52:13,153 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:13,156 EPOCH 9 done: loss 0.0316 - lr 0.1500 - bad epochs 3\n",
      "2019-08-10 17:52:14,930 DEV : loss 0.03267890214920044 - score 0.9874\n",
      "2019-08-10 17:52:14,934 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:16,391 epoch 10 - iter 0/277 - loss 0.00084271\n",
      "2019-08-10 17:52:17,146 epoch 10 - iter 27/277 - loss 0.02326187\n",
      "2019-08-10 17:52:17,870 epoch 10 - iter 54/277 - loss 0.01784029\n",
      "2019-08-10 17:52:18,613 epoch 10 - iter 81/277 - loss 0.01720823\n",
      "2019-08-10 17:52:19,337 epoch 10 - iter 108/277 - loss 0.02928456\n",
      "2019-08-10 17:52:20,069 epoch 10 - iter 135/277 - loss 0.02709553\n",
      "2019-08-10 17:52:20,787 epoch 10 - iter 162/277 - loss 0.02480250\n",
      "2019-08-10 17:52:21,531 epoch 10 - iter 189/277 - loss 0.02953406\n",
      "2019-08-10 17:52:24,201 epoch 10 - iter 216/277 - loss 0.03009100\n",
      "2019-08-10 17:52:24,893 epoch 10 - iter 243/277 - loss 0.03209626\n",
      "2019-08-10 17:52:25,562 epoch 10 - iter 270/277 - loss 0.03142285\n",
      "2019-08-10 17:52:26,210 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:26,213 EPOCH 10 done: loss 0.0309 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:52:27,980 DEV : loss 0.03645706921815872 - score 0.9856\n",
      "2019-08-10 17:52:27,985 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:27,987 Testing using best model ...\n",
      "2019-08-10 17:52:29,720 0.9892\t0.9892\t0.9892\n",
      "2019-08-10 17:52:29,724 \n",
      "MICRO_AVG: acc 0.9786 - f1-score 0.9892\n",
      "MACRO_AVG: acc 0.9559 - f1-score 0.9771000000000001\n",
      "ham        tp: 476 - fp: 3 - fn: 3 - tn: 73 - precision: 0.9937 - recall: 0.9937 - accuracy: 0.9876 - f1-score: 0.9937\n",
      "spam       tp: 73 - fp: 3 - fn: 3 - tn: 476 - precision: 0.9605 - recall: 0.9605 - accuracy: 0.9241 - f1-score: 0.9605\n",
      "2019-08-10 17:52:29,727 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:29,730 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:29,733 Done evaluating parameter combination:\n",
      "2019-08-10 17:52:29,736 \tdropout: 0.29676245409087676\n",
      "2019-08-10 17:52:29,740 \tembeddings: /tmp/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-08-10 17:52:29,743 \thidden_size: 32\n",
      "2019-08-10 17:52:29,746 \tlearning_rate: 0.15\n",
      "2019-08-10 17:52:29,749 \tmini_batch_size: 16\n",
      "2019-08-10 17:52:29,753 \trnn_layers: 2\n",
      "2019-08-10 17:52:29,755 score: 0.017399999999999985\n",
      "2019-08-10 17:52:29,757 variance: 2.0880000000000047e-05\n",
      "2019-08-10 17:52:29,760 test_score: 0.9892\n",
      "\n",
      "2019-08-10 17:52:29,764 ----------------------------------------------------------------------------------------------------\n",
      " 70%|███████   | 7/10 [1:50:08<35:21, 707.09s/it, best loss: 0.011799999999999996]2019-08-10 17:52:29,773 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:29,774 Evaluation run: 8\n",
      "2019-08-10 17:52:29,777 Evaluating parameter combination:\n",
      "2019-08-10 17:52:29,780 \tdropout: 0.36772469368140304\n",
      "2019-08-10 17:52:29,782 \tembeddings: /tmp/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-08-10 17:52:29,784 \thidden_size: 256\n",
      "2019-08-10 17:52:29,786 \tlearning_rate: 0.15\n",
      "2019-08-10 17:52:29,788 \tmini_batch_size: 32\n",
      "2019-08-10 17:52:29,790 \trnn_layers: 2\n",
      "2019-08-10 17:52:29,793 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:32,460 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:32,462 Training run: 1\n",
      "2019-08-10 17:52:32,478 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:32,480 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:52:33,500 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:35,056 epoch 1 - iter 0/139 - loss 0.71259928\n",
      "2019-08-10 17:52:35,701 epoch 1 - iter 13/139 - loss 0.43895672\n",
      "2019-08-10 17:52:36,317 epoch 1 - iter 26/139 - loss 0.41515146\n",
      "2019-08-10 17:52:36,996 epoch 1 - iter 39/139 - loss 0.40270947\n",
      "2019-08-10 17:52:37,608 epoch 1 - iter 52/139 - loss 0.38027258\n",
      "2019-08-10 17:52:38,235 epoch 1 - iter 65/139 - loss 0.36145631\n",
      "2019-08-10 17:52:38,861 epoch 1 - iter 78/139 - loss 0.33885719\n",
      "2019-08-10 17:52:39,463 epoch 1 - iter 91/139 - loss 0.32639983\n",
      "2019-08-10 17:52:40,060 epoch 1 - iter 104/139 - loss 0.31497119\n",
      "2019-08-10 17:52:40,678 epoch 1 - iter 117/139 - loss 0.29976104\n",
      "2019-08-10 17:52:41,228 epoch 1 - iter 130/139 - loss 0.28850276\n",
      "2019-08-10 17:52:42,000 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:42,003 EPOCH 1 done: loss 0.2826 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:52:43,756 DEV : loss 0.9016358256340027 - score 0.8486\n",
      "2019-08-10 17:52:43,760 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:45,355 epoch 2 - iter 0/139 - loss 1.18954980\n",
      "2019-08-10 17:52:46,036 epoch 2 - iter 13/139 - loss 0.21928194\n",
      "2019-08-10 17:52:46,685 epoch 2 - iter 26/139 - loss 0.18145242\n",
      "2019-08-10 17:52:47,309 epoch 2 - iter 39/139 - loss 0.17538409\n",
      "2019-08-10 17:52:49,851 epoch 2 - iter 52/139 - loss 0.17080049\n",
      "2019-08-10 17:52:50,457 epoch 2 - iter 65/139 - loss 0.15836600\n",
      "2019-08-10 17:52:51,038 epoch 2 - iter 78/139 - loss 0.16330131\n",
      "2019-08-10 17:52:51,623 epoch 2 - iter 91/139 - loss 0.15048823\n",
      "2019-08-10 17:52:52,239 epoch 2 - iter 104/139 - loss 0.15144589\n",
      "2019-08-10 17:52:52,829 epoch 2 - iter 117/139 - loss 0.14871390\n",
      "2019-08-10 17:52:53,367 epoch 2 - iter 130/139 - loss 0.14736949\n",
      "2019-08-10 17:52:54,197 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:54,201 EPOCH 2 done: loss 0.1465 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:52:56,218 DEV : loss 0.326736718416214 - score 0.8559\n",
      "2019-08-10 17:52:56,223 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:52:57,830 epoch 3 - iter 0/139 - loss 0.21389163\n",
      "2019-08-10 17:52:58,518 epoch 3 - iter 13/139 - loss 0.16782927\n",
      "2019-08-10 17:52:59,108 epoch 3 - iter 26/139 - loss 0.13173834\n",
      "2019-08-10 17:52:59,738 epoch 3 - iter 39/139 - loss 0.13123729\n",
      "2019-08-10 17:53:00,378 epoch 3 - iter 52/139 - loss 0.12965921\n",
      "2019-08-10 17:53:01,000 epoch 3 - iter 65/139 - loss 0.12381068\n",
      "2019-08-10 17:53:01,590 epoch 3 - iter 78/139 - loss 0.12349626\n",
      "2019-08-10 17:53:02,191 epoch 3 - iter 91/139 - loss 0.11883067\n",
      "2019-08-10 17:53:02,851 epoch 3 - iter 104/139 - loss 0.13205818\n",
      "2019-08-10 17:53:03,519 epoch 3 - iter 117/139 - loss 0.12547287\n",
      "2019-08-10 17:53:04,035 epoch 3 - iter 130/139 - loss 0.11909869\n",
      "2019-08-10 17:53:04,814 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:53:04,818 EPOCH 3 done: loss 0.1248 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:53:08,591 DEV : loss 0.19255931675434113 - score 0.9243\n",
      "2019-08-10 17:53:08,594 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:53:10,165 epoch 4 - iter 0/139 - loss 0.12087056\n",
      "2019-08-10 17:53:10,833 epoch 4 - iter 13/139 - loss 0.06454501\n",
      "2019-08-10 17:53:11,433 epoch 4 - iter 26/139 - loss 0.13841911\n",
      "2019-08-10 17:53:12,079 epoch 4 - iter 39/139 - loss 0.12542213\n",
      "2019-08-10 17:53:12,656 epoch 4 - iter 52/139 - loss 0.10942871\n",
      "2019-08-10 17:53:13,299 epoch 4 - iter 65/139 - loss 0.10155181\n",
      "2019-08-10 17:53:13,937 epoch 4 - iter 78/139 - loss 0.10459693\n",
      "2019-08-10 17:53:14,563 epoch 4 - iter 91/139 - loss 0.11112076\n",
      "2019-08-10 17:53:15,228 epoch 4 - iter 104/139 - loss 0.10775012\n",
      "2019-08-10 17:53:15,845 epoch 4 - iter 117/139 - loss 0.10007586\n",
      "2019-08-10 17:53:16,390 epoch 4 - iter 130/139 - loss 0.10694532\n",
      "2019-08-10 17:53:17,176 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:53:17,181 EPOCH 4 done: loss 0.1029 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:53:18,928 DEV : loss 0.10652337223291397 - score 0.9586\n",
      "2019-08-10 17:53:18,934 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:53:20,486 epoch 5 - iter 0/139 - loss 0.05670185\n",
      "2019-08-10 17:53:21,132 epoch 5 - iter 13/139 - loss 0.12084340\n",
      "2019-08-10 17:53:21,756 epoch 5 - iter 26/139 - loss 0.08481266\n",
      "2019-08-10 17:53:22,355 epoch 5 - iter 39/139 - loss 0.07829051\n",
      "2019-08-10 17:53:22,974 epoch 5 - iter 52/139 - loss 0.06721554\n",
      "2019-08-10 17:53:23,639 epoch 5 - iter 65/139 - loss 0.08757074\n",
      "2019-08-10 17:53:24,277 epoch 5 - iter 78/139 - loss 0.08017558\n",
      "2019-08-10 17:53:24,873 epoch 5 - iter 91/139 - loss 0.08012838\n",
      "2019-08-10 17:53:27,346 epoch 5 - iter 104/139 - loss 0.08242963\n",
      "2019-08-10 17:53:27,921 epoch 5 - iter 117/139 - loss 0.08289409\n",
      "2019-08-10 17:53:28,454 epoch 5 - iter 130/139 - loss 0.08178436\n",
      "2019-08-10 17:53:29,236 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:53:29,238 EPOCH 5 done: loss 0.0833 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:53:30,943 DEV : loss 0.07301235944032669 - score 0.9712\n",
      "2019-08-10 17:53:30,947 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:53:32,488 epoch 6 - iter 0/139 - loss 0.02422393\n",
      "2019-08-10 17:53:33,134 epoch 6 - iter 13/139 - loss 0.02944097\n",
      "2019-08-10 17:53:33,775 epoch 6 - iter 26/139 - loss 0.04578400\n",
      "2019-08-10 17:53:34,412 epoch 6 - iter 39/139 - loss 0.07066950\n",
      "2019-08-10 17:53:35,010 epoch 6 - iter 52/139 - loss 0.07999501\n",
      "2019-08-10 17:53:35,631 epoch 6 - iter 65/139 - loss 0.07488627\n",
      "2019-08-10 17:53:36,231 epoch 6 - iter 78/139 - loss 0.08189943\n",
      "2019-08-10 17:53:36,842 epoch 6 - iter 91/139 - loss 0.07658507\n",
      "2019-08-10 17:53:37,459 epoch 6 - iter 104/139 - loss 0.07554485\n",
      "2019-08-10 17:53:38,092 epoch 6 - iter 117/139 - loss 0.07617860\n",
      "2019-08-10 17:53:38,619 epoch 6 - iter 130/139 - loss 0.07478327\n",
      "2019-08-10 17:53:39,389 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:53:39,392 EPOCH 6 done: loss 0.0741 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:53:41,136 DEV : loss 0.08090437948703766 - score 0.9676\n",
      "2019-08-10 17:53:41,140 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:53:42,692 epoch 7 - iter 0/139 - loss 0.22447041\n",
      "2019-08-10 17:53:43,364 epoch 7 - iter 13/139 - loss 0.08552808\n",
      "2019-08-10 17:53:43,959 epoch 7 - iter 26/139 - loss 0.06403079\n",
      "2019-08-10 17:53:44,565 epoch 7 - iter 39/139 - loss 0.08324784\n",
      "2019-08-10 17:53:47,188 epoch 7 - iter 52/139 - loss 0.08337880\n",
      "2019-08-10 17:53:47,776 epoch 7 - iter 65/139 - loss 0.08550595\n",
      "2019-08-10 17:53:48,384 epoch 7 - iter 78/139 - loss 0.08514596\n",
      "2019-08-10 17:53:49,004 epoch 7 - iter 91/139 - loss 0.08158193\n",
      "2019-08-10 17:53:49,581 epoch 7 - iter 104/139 - loss 0.07741926\n",
      "2019-08-10 17:53:50,203 epoch 7 - iter 117/139 - loss 0.07747538\n",
      "2019-08-10 17:53:50,724 epoch 7 - iter 130/139 - loss 0.07499814\n",
      "2019-08-10 17:53:51,548 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:53:51,551 EPOCH 7 done: loss 0.0748 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:53:53,284 DEV : loss 0.067019522190094 - score 0.9712\n",
      "2019-08-10 17:53:53,288 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:53:54,818 epoch 8 - iter 0/139 - loss 0.06832378\n",
      "2019-08-10 17:53:55,499 epoch 8 - iter 13/139 - loss 0.05310414\n",
      "2019-08-10 17:53:56,118 epoch 8 - iter 26/139 - loss 0.08385223\n",
      "2019-08-10 17:53:56,743 epoch 8 - iter 39/139 - loss 0.07841903\n",
      "2019-08-10 17:53:57,342 epoch 8 - iter 52/139 - loss 0.06627958\n",
      "2019-08-10 17:53:57,968 epoch 8 - iter 65/139 - loss 0.06655687\n",
      "2019-08-10 17:53:58,564 epoch 8 - iter 78/139 - loss 0.06348909\n",
      "2019-08-10 17:53:59,178 epoch 8 - iter 91/139 - loss 0.09095166\n",
      "2019-08-10 17:53:59,815 epoch 8 - iter 104/139 - loss 0.08710367\n",
      "2019-08-10 17:54:00,396 epoch 8 - iter 117/139 - loss 0.08500663\n",
      "2019-08-10 17:54:00,955 epoch 8 - iter 130/139 - loss 0.08175645\n",
      "2019-08-10 17:54:01,780 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:54:01,783 EPOCH 8 done: loss 0.0791 - lr 0.1500 - bad epochs 2\n",
      "2019-08-10 17:54:03,530 DEV : loss 0.08265890181064606 - score 0.9604\n",
      "2019-08-10 17:54:03,536 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:54:05,091 epoch 9 - iter 0/139 - loss 0.07023592\n",
      "2019-08-10 17:54:07,660 epoch 9 - iter 13/139 - loss 0.07430047\n",
      "2019-08-10 17:54:08,231 epoch 9 - iter 26/139 - loss 0.06508989\n",
      "2019-08-10 17:54:08,854 epoch 9 - iter 39/139 - loss 0.05845821\n",
      "2019-08-10 17:54:09,449 epoch 9 - iter 52/139 - loss 0.05511447\n",
      "2019-08-10 17:54:10,049 epoch 9 - iter 65/139 - loss 0.05625006\n",
      "2019-08-10 17:54:10,691 epoch 9 - iter 78/139 - loss 0.05018856\n",
      "2019-08-10 17:54:11,288 epoch 9 - iter 91/139 - loss 0.04627434\n",
      "2019-08-10 17:54:11,915 epoch 9 - iter 104/139 - loss 0.05909590\n",
      "2019-08-10 17:54:12,500 epoch 9 - iter 117/139 - loss 0.06302251\n",
      "2019-08-10 17:54:13,042 epoch 9 - iter 130/139 - loss 0.06793325\n",
      "2019-08-10 17:54:13,815 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:54:13,820 EPOCH 9 done: loss 0.0686 - lr 0.1500 - bad epochs 3\n",
      "2019-08-10 17:54:15,574 DEV : loss 0.06450408697128296 - score 0.9748\n",
      "2019-08-10 17:54:15,578 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:54:17,170 epoch 10 - iter 0/139 - loss 0.08385019\n",
      "2019-08-10 17:54:17,786 epoch 10 - iter 13/139 - loss 0.06196371\n",
      "2019-08-10 17:54:18,434 epoch 10 - iter 26/139 - loss 0.05190723\n",
      "2019-08-10 17:54:19,022 epoch 10 - iter 39/139 - loss 0.05000005\n",
      "2019-08-10 17:54:19,670 epoch 10 - iter 52/139 - loss 0.04641183\n",
      "2019-08-10 17:54:20,337 epoch 10 - iter 65/139 - loss 0.04980750\n",
      "2019-08-10 17:54:20,979 epoch 10 - iter 78/139 - loss 0.04913369\n",
      "2019-08-10 17:54:21,566 epoch 10 - iter 91/139 - loss 0.06081084\n",
      "2019-08-10 17:54:22,209 epoch 10 - iter 104/139 - loss 0.06047692\n",
      "2019-08-10 17:54:24,722 epoch 10 - iter 117/139 - loss 0.05896264\n",
      "2019-08-10 17:54:25,259 epoch 10 - iter 130/139 - loss 0.05806521\n",
      "2019-08-10 17:54:26,034 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:54:26,037 EPOCH 10 done: loss 0.0580 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:54:27,772 DEV : loss 0.05694114416837692 - score 0.9802\n",
      "2019-08-10 17:54:27,777 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:54:27,779 Testing using best model ...\n",
      "2019-08-10 17:54:29,542 0.9784\t0.9784\t0.9784\n",
      "2019-08-10 17:54:29,546 \n",
      "MICRO_AVG: acc 0.9577 - f1-score 0.9784\n",
      "MACRO_AVG: acc 0.9169 - f1-score 0.9557\n",
      "ham        tp: 470 - fp: 3 - fn: 9 - tn: 73 - precision: 0.9937 - recall: 0.9812 - accuracy: 0.9751 - f1-score: 0.9874\n",
      "spam       tp: 73 - fp: 9 - fn: 3 - tn: 470 - precision: 0.8902 - recall: 0.9605 - accuracy: 0.8588 - f1-score: 0.9240\n",
      "2019-08-10 17:54:29,548 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:54:29,551 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:54:29,554 Training run: 2\n",
      "2019-08-10 17:54:29,571 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:54:29,575 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:54:30,576 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:54:32,113 epoch 1 - iter 0/139 - loss 0.69207031\n",
      "2019-08-10 17:54:32,774 epoch 1 - iter 13/139 - loss 0.42088350\n",
      "2019-08-10 17:54:33,407 epoch 1 - iter 26/139 - loss 0.38053903\n",
      "2019-08-10 17:54:34,064 epoch 1 - iter 39/139 - loss 0.37168518\n",
      "2019-08-10 17:54:34,706 epoch 1 - iter 52/139 - loss 0.36353864\n",
      "2019-08-10 17:54:35,307 epoch 1 - iter 65/139 - loss 0.34613703\n",
      "2019-08-10 17:54:35,960 epoch 1 - iter 78/139 - loss 0.33722870\n",
      "2019-08-10 17:54:36,594 epoch 1 - iter 91/139 - loss 0.31741660\n",
      "2019-08-10 17:54:37,171 epoch 1 - iter 104/139 - loss 0.30945927\n",
      "2019-08-10 17:54:37,830 epoch 1 - iter 117/139 - loss 0.30652385\n",
      "2019-08-10 17:54:38,369 epoch 1 - iter 130/139 - loss 0.29316860\n",
      "2019-08-10 17:54:39,152 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:54:39,155 EPOCH 1 done: loss 0.2866 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:54:40,906 DEV : loss 0.17032694816589355 - score 0.9405\n",
      "2019-08-10 17:54:40,910 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:54:42,477 epoch 2 - iter 0/139 - loss 0.04336568\n",
      "2019-08-10 17:54:43,138 epoch 2 - iter 13/139 - loss 0.14036920\n",
      "2019-08-10 17:54:43,776 epoch 2 - iter 26/139 - loss 0.20048482\n",
      "2019-08-10 17:54:44,381 epoch 2 - iter 39/139 - loss 0.18406251\n",
      "2019-08-10 17:54:46,875 epoch 2 - iter 52/139 - loss 0.16517407\n",
      "2019-08-10 17:54:47,509 epoch 2 - iter 65/139 - loss 0.17340613\n",
      "2019-08-10 17:54:48,099 epoch 2 - iter 78/139 - loss 0.16473864\n",
      "2019-08-10 17:54:48,694 epoch 2 - iter 91/139 - loss 0.16987458\n",
      "2019-08-10 17:54:49,313 epoch 2 - iter 104/139 - loss 0.17002643\n",
      "2019-08-10 17:54:49,924 epoch 2 - iter 117/139 - loss 0.16507578\n",
      "2019-08-10 17:54:50,462 epoch 2 - iter 130/139 - loss 0.15897102\n",
      "2019-08-10 17:54:51,252 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:54:51,256 EPOCH 2 done: loss 0.1534 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:54:53,052 DEV : loss 0.11289054900407791 - score 0.9604\n",
      "2019-08-10 17:54:53,056 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:54:54,624 epoch 3 - iter 0/139 - loss 0.03372091\n",
      "2019-08-10 17:54:55,301 epoch 3 - iter 13/139 - loss 0.16281703\n",
      "2019-08-10 17:54:55,942 epoch 3 - iter 26/139 - loss 0.14218038\n",
      "2019-08-10 17:54:56,591 epoch 3 - iter 39/139 - loss 0.12756145\n",
      "2019-08-10 17:54:57,229 epoch 3 - iter 52/139 - loss 0.13346813\n",
      "2019-08-10 17:54:57,862 epoch 3 - iter 65/139 - loss 0.11719374\n",
      "2019-08-10 17:54:58,503 epoch 3 - iter 78/139 - loss 0.10718646\n",
      "2019-08-10 17:54:59,093 epoch 3 - iter 91/139 - loss 0.12226813\n",
      "2019-08-10 17:54:59,738 epoch 3 - iter 104/139 - loss 0.12182269\n",
      "2019-08-10 17:55:00,389 epoch 3 - iter 117/139 - loss 0.12025097\n",
      "2019-08-10 17:55:00,930 epoch 3 - iter 130/139 - loss 0.11201471\n",
      "2019-08-10 17:55:01,761 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:55:01,764 EPOCH 3 done: loss 0.1126 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:55:05,532 DEV : loss 0.8437961339950562 - score 0.8505\n",
      "2019-08-10 17:55:05,538 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:55:07,146 epoch 4 - iter 0/139 - loss 0.83591521\n",
      "2019-08-10 17:55:07,777 epoch 4 - iter 13/139 - loss 0.10843778\n",
      "2019-08-10 17:55:08,386 epoch 4 - iter 26/139 - loss 0.08629774\n",
      "2019-08-10 17:55:09,023 epoch 4 - iter 39/139 - loss 0.08575149\n",
      "2019-08-10 17:55:09,627 epoch 4 - iter 52/139 - loss 0.11768182\n",
      "2019-08-10 17:55:10,248 epoch 4 - iter 65/139 - loss 0.10814470\n",
      "2019-08-10 17:55:10,899 epoch 4 - iter 78/139 - loss 0.09961638\n",
      "2019-08-10 17:55:11,522 epoch 4 - iter 91/139 - loss 0.10888447\n",
      "2019-08-10 17:55:12,137 epoch 4 - iter 104/139 - loss 0.10699767\n",
      "2019-08-10 17:55:12,761 epoch 4 - iter 117/139 - loss 0.10181917\n",
      "2019-08-10 17:55:13,274 epoch 4 - iter 130/139 - loss 0.10346510\n",
      "2019-08-10 17:55:14,096 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:55:14,099 EPOCH 4 done: loss 0.1005 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:55:15,825 DEV : loss 0.08522944152355194 - score 0.9712\n",
      "2019-08-10 17:55:15,829 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:55:17,381 epoch 5 - iter 0/139 - loss 0.02252856\n",
      "2019-08-10 17:55:18,055 epoch 5 - iter 13/139 - loss 0.08814094\n",
      "2019-08-10 17:55:18,692 epoch 5 - iter 26/139 - loss 0.08637934\n",
      "2019-08-10 17:55:19,314 epoch 5 - iter 39/139 - loss 0.07733135\n",
      "2019-08-10 17:55:19,928 epoch 5 - iter 52/139 - loss 0.09935568\n",
      "2019-08-10 17:55:20,585 epoch 5 - iter 65/139 - loss 0.09588236\n",
      "2019-08-10 17:55:21,213 epoch 5 - iter 78/139 - loss 0.08665021\n",
      "2019-08-10 17:55:23,673 epoch 5 - iter 91/139 - loss 0.08644065\n",
      "2019-08-10 17:55:24,289 epoch 5 - iter 104/139 - loss 0.08689060\n",
      "2019-08-10 17:55:24,854 epoch 5 - iter 117/139 - loss 0.08494575\n",
      "2019-08-10 17:55:25,386 epoch 5 - iter 130/139 - loss 0.09146401\n",
      "2019-08-10 17:55:26,164 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:55:26,168 EPOCH 5 done: loss 0.0927 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:55:27,908 DEV : loss 0.08261934667825699 - score 0.9712\n",
      "2019-08-10 17:55:27,912 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:55:29,505 epoch 6 - iter 0/139 - loss 0.03128261\n",
      "2019-08-10 17:55:30,167 epoch 6 - iter 13/139 - loss 0.08909474\n",
      "2019-08-10 17:55:30,783 epoch 6 - iter 26/139 - loss 0.07427332\n",
      "2019-08-10 17:55:31,421 epoch 6 - iter 39/139 - loss 0.08269687\n",
      "2019-08-10 17:55:32,009 epoch 6 - iter 52/139 - loss 0.07053987\n",
      "2019-08-10 17:55:32,613 epoch 6 - iter 65/139 - loss 0.07349411\n",
      "2019-08-10 17:55:33,224 epoch 6 - iter 78/139 - loss 0.06963269\n",
      "2019-08-10 17:55:33,844 epoch 6 - iter 91/139 - loss 0.06673344\n",
      "2019-08-10 17:55:34,475 epoch 6 - iter 104/139 - loss 0.06910501\n",
      "2019-08-10 17:55:35,116 epoch 6 - iter 117/139 - loss 0.07559829\n",
      "2019-08-10 17:55:35,648 epoch 6 - iter 130/139 - loss 0.07896435\n",
      "2019-08-10 17:55:36,394 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:55:36,397 EPOCH 6 done: loss 0.0850 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:55:38,109 DEV : loss 0.08353791385889053 - score 0.973\n",
      "2019-08-10 17:55:38,113 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:55:39,675 epoch 7 - iter 0/139 - loss 0.05993431\n",
      "2019-08-10 17:55:40,321 epoch 7 - iter 13/139 - loss 0.11193196\n",
      "2019-08-10 17:55:40,957 epoch 7 - iter 26/139 - loss 0.08004688\n",
      "2019-08-10 17:55:43,467 epoch 7 - iter 39/139 - loss 0.06230846\n",
      "2019-08-10 17:55:44,095 epoch 7 - iter 52/139 - loss 0.07747779\n",
      "2019-08-10 17:55:44,683 epoch 7 - iter 65/139 - loss 0.07424765\n",
      "2019-08-10 17:55:45,369 epoch 7 - iter 78/139 - loss 0.07570191\n",
      "2019-08-10 17:55:45,955 epoch 7 - iter 91/139 - loss 0.07006792\n",
      "2019-08-10 17:55:46,581 epoch 7 - iter 104/139 - loss 0.07539494\n",
      "2019-08-10 17:55:47,186 epoch 7 - iter 117/139 - loss 0.07075429\n",
      "2019-08-10 17:55:47,691 epoch 7 - iter 130/139 - loss 0.07641544\n",
      "2019-08-10 17:55:48,476 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:55:48,479 EPOCH 7 done: loss 0.0753 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:55:50,228 DEV : loss 0.0704868882894516 - score 0.9748\n",
      "2019-08-10 17:55:50,232 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:55:51,788 epoch 8 - iter 0/139 - loss 0.05223129\n",
      "2019-08-10 17:55:52,435 epoch 8 - iter 13/139 - loss 0.04337983\n",
      "2019-08-10 17:55:53,050 epoch 8 - iter 26/139 - loss 0.06691574\n",
      "2019-08-10 17:55:53,683 epoch 8 - iter 39/139 - loss 0.05827863\n",
      "2019-08-10 17:55:54,313 epoch 8 - iter 52/139 - loss 0.06315687\n",
      "2019-08-10 17:55:54,962 epoch 8 - iter 65/139 - loss 0.06932053\n",
      "2019-08-10 17:55:55,577 epoch 8 - iter 78/139 - loss 0.06684286\n",
      "2019-08-10 17:55:56,199 epoch 8 - iter 91/139 - loss 0.06497572\n",
      "2019-08-10 17:55:56,826 epoch 8 - iter 104/139 - loss 0.06399761\n",
      "2019-08-10 17:55:57,480 epoch 8 - iter 117/139 - loss 0.06571684\n",
      "2019-08-10 17:55:58,002 epoch 8 - iter 130/139 - loss 0.06329675\n",
      "2019-08-10 17:55:58,771 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:55:58,776 EPOCH 8 done: loss 0.0628 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:56:02,539 DEV : loss 0.06042443588376045 - score 0.9766\n",
      "2019-08-10 17:56:02,542 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:56:04,099 epoch 9 - iter 0/139 - loss 0.02328248\n",
      "2019-08-10 17:56:04,753 epoch 9 - iter 13/139 - loss 0.14677096\n",
      "2019-08-10 17:56:05,380 epoch 9 - iter 26/139 - loss 0.11230938\n",
      "2019-08-10 17:56:05,969 epoch 9 - iter 39/139 - loss 0.09639448\n",
      "2019-08-10 17:56:06,623 epoch 9 - iter 52/139 - loss 0.08191325\n",
      "2019-08-10 17:56:07,230 epoch 9 - iter 65/139 - loss 0.07957822\n",
      "2019-08-10 17:56:07,831 epoch 9 - iter 78/139 - loss 0.07672487\n",
      "2019-08-10 17:56:08,457 epoch 9 - iter 91/139 - loss 0.07583469\n",
      "2019-08-10 17:56:09,079 epoch 9 - iter 104/139 - loss 0.07031904\n",
      "2019-08-10 17:56:09,723 epoch 9 - iter 117/139 - loss 0.06817345\n",
      "2019-08-10 17:56:10,263 epoch 9 - iter 130/139 - loss 0.07633354\n",
      "2019-08-10 17:56:11,052 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:56:11,055 EPOCH 9 done: loss 0.0737 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:56:12,813 DEV : loss 0.056994352489709854 - score 0.9766\n",
      "2019-08-10 17:56:12,818 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:56:14,373 epoch 10 - iter 0/139 - loss 0.07502671\n",
      "2019-08-10 17:56:15,035 epoch 10 - iter 13/139 - loss 0.07532100\n",
      "2019-08-10 17:56:15,660 epoch 10 - iter 26/139 - loss 0.06253206\n",
      "2019-08-10 17:56:16,279 epoch 10 - iter 39/139 - loss 0.06354266\n",
      "2019-08-10 17:56:16,900 epoch 10 - iter 52/139 - loss 0.06754328\n",
      "2019-08-10 17:56:17,526 epoch 10 - iter 65/139 - loss 0.06740949\n",
      "2019-08-10 17:56:18,141 epoch 10 - iter 78/139 - loss 0.06737227\n",
      "2019-08-10 17:56:20,671 epoch 10 - iter 91/139 - loss 0.06433159\n",
      "2019-08-10 17:56:21,262 epoch 10 - iter 104/139 - loss 0.06422038\n",
      "2019-08-10 17:56:21,892 epoch 10 - iter 117/139 - loss 0.06187038\n",
      "2019-08-10 17:56:22,414 epoch 10 - iter 130/139 - loss 0.05981991\n",
      "2019-08-10 17:56:23,211 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:56:23,215 EPOCH 10 done: loss 0.0577 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:56:24,915 DEV : loss 0.11358018964529037 - score 0.9622\n",
      "2019-08-10 17:56:24,920 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:56:24,923 Testing using best model ...\n",
      "2019-08-10 17:56:26,664 0.9712\t0.9712\t0.9712\n",
      "2019-08-10 17:56:26,668 \n",
      "MICRO_AVG: acc 0.944 - f1-score 0.9712\n",
      "MACRO_AVG: acc 0.8786 - f1-score 0.933\n",
      "ham        tp: 479 - fp: 16 - fn: 0 - tn: 60 - precision: 0.9677 - recall: 1.0000 - accuracy: 0.9677 - f1-score: 0.9836\n",
      "spam       tp: 60 - fp: 0 - fn: 16 - tn: 479 - precision: 1.0000 - recall: 0.7895 - accuracy: 0.7895 - f1-score: 0.8824\n",
      "2019-08-10 17:56:26,673 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:56:26,676 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:56:26,678 Training run: 3\n",
      "2019-08-10 17:56:26,693 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:56:26,696 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:56:27,684 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:56:29,226 epoch 1 - iter 0/139 - loss 0.75178009\n",
      "2019-08-10 17:56:29,899 epoch 1 - iter 13/139 - loss 0.43130049\n",
      "2019-08-10 17:56:30,553 epoch 1 - iter 26/139 - loss 0.41768955\n",
      "2019-08-10 17:56:31,192 epoch 1 - iter 39/139 - loss 0.40038335\n",
      "2019-08-10 17:56:31,800 epoch 1 - iter 52/139 - loss 0.37009988\n",
      "2019-08-10 17:56:32,433 epoch 1 - iter 65/139 - loss 0.33741509\n",
      "2019-08-10 17:56:32,998 epoch 1 - iter 78/139 - loss 0.32205948\n",
      "2019-08-10 17:56:33,656 epoch 1 - iter 91/139 - loss 0.30735145\n",
      "2019-08-10 17:56:34,229 epoch 1 - iter 104/139 - loss 0.31249724\n",
      "2019-08-10 17:56:34,822 epoch 1 - iter 117/139 - loss 0.30302466\n",
      "2019-08-10 17:56:35,345 epoch 1 - iter 130/139 - loss 0.28967050\n",
      "2019-08-10 17:56:36,138 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:56:36,141 EPOCH 1 done: loss 0.2861 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:56:37,876 DEV : loss 0.7249016761779785 - score 0.8486\n",
      "2019-08-10 17:56:37,880 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:56:39,433 epoch 2 - iter 0/139 - loss 0.78947443\n",
      "2019-08-10 17:56:40,098 epoch 2 - iter 13/139 - loss 0.16053366\n",
      "2019-08-10 17:56:42,668 epoch 2 - iter 26/139 - loss 0.18508133\n",
      "2019-08-10 17:56:43,286 epoch 2 - iter 39/139 - loss 0.19122199\n",
      "2019-08-10 17:56:43,896 epoch 2 - iter 52/139 - loss 0.17314088\n",
      "2019-08-10 17:56:44,462 epoch 2 - iter 65/139 - loss 0.17486505\n",
      "2019-08-10 17:56:45,110 epoch 2 - iter 78/139 - loss 0.16236733\n",
      "2019-08-10 17:56:45,715 epoch 2 - iter 91/139 - loss 0.17762307\n",
      "2019-08-10 17:56:46,283 epoch 2 - iter 104/139 - loss 0.17437113\n",
      "2019-08-10 17:56:46,853 epoch 2 - iter 117/139 - loss 0.17146233\n",
      "2019-08-10 17:56:47,383 epoch 2 - iter 130/139 - loss 0.16335974\n",
      "2019-08-10 17:56:48,174 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:56:48,177 EPOCH 2 done: loss 0.1655 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:56:49,898 DEV : loss 0.1383666843175888 - score 0.9532\n",
      "2019-08-10 17:56:49,902 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:56:51,430 epoch 3 - iter 0/139 - loss 0.10500358\n",
      "2019-08-10 17:56:52,073 epoch 3 - iter 13/139 - loss 0.13965131\n",
      "2019-08-10 17:56:52,684 epoch 3 - iter 26/139 - loss 0.11628821\n",
      "2019-08-10 17:56:53,313 epoch 3 - iter 39/139 - loss 0.10253094\n",
      "2019-08-10 17:56:53,939 epoch 3 - iter 52/139 - loss 0.11252005\n",
      "2019-08-10 17:56:54,574 epoch 3 - iter 65/139 - loss 0.10984634\n",
      "2019-08-10 17:56:55,155 epoch 3 - iter 78/139 - loss 0.11145890\n",
      "2019-08-10 17:56:55,805 epoch 3 - iter 91/139 - loss 0.11051120\n",
      "2019-08-10 17:56:56,418 epoch 3 - iter 104/139 - loss 0.11197884\n",
      "2019-08-10 17:56:57,068 epoch 3 - iter 117/139 - loss 0.11386370\n",
      "2019-08-10 17:56:59,487 epoch 3 - iter 130/139 - loss 0.11165522\n",
      "2019-08-10 17:57:00,301 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:57:00,304 EPOCH 3 done: loss 0.1122 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:57:02,038 DEV : loss 0.09853692352771759 - score 0.9586\n",
      "2019-08-10 17:57:02,042 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:57:03,616 epoch 4 - iter 0/139 - loss 0.14772740\n",
      "2019-08-10 17:57:04,262 epoch 4 - iter 13/139 - loss 0.10113405\n",
      "2019-08-10 17:57:04,904 epoch 4 - iter 26/139 - loss 0.10527959\n",
      "2019-08-10 17:57:05,530 epoch 4 - iter 39/139 - loss 0.09972610\n",
      "2019-08-10 17:57:06,161 epoch 4 - iter 52/139 - loss 0.10023607\n",
      "2019-08-10 17:57:06,796 epoch 4 - iter 65/139 - loss 0.09248029\n",
      "2019-08-10 17:57:07,407 epoch 4 - iter 78/139 - loss 0.08749297\n",
      "2019-08-10 17:57:08,005 epoch 4 - iter 91/139 - loss 0.08843971\n",
      "2019-08-10 17:57:08,631 epoch 4 - iter 104/139 - loss 0.08694383\n",
      "2019-08-10 17:57:09,238 epoch 4 - iter 117/139 - loss 0.09070357\n",
      "2019-08-10 17:57:09,784 epoch 4 - iter 130/139 - loss 0.08802201\n",
      "2019-08-10 17:57:10,536 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:57:10,540 EPOCH 4 done: loss 0.0914 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:57:12,299 DEV : loss 0.9973047971725464 - score 0.6126\n",
      "2019-08-10 17:57:12,303 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:57:13,936 epoch 5 - iter 0/139 - loss 1.04750752\n",
      "2019-08-10 17:57:14,575 epoch 5 - iter 13/139 - loss 0.21092624\n",
      "2019-08-10 17:57:15,225 epoch 5 - iter 26/139 - loss 0.15409891\n",
      "2019-08-10 17:57:15,857 epoch 5 - iter 39/139 - loss 0.13127718\n",
      "2019-08-10 17:57:16,503 epoch 5 - iter 52/139 - loss 0.11950656\n",
      "2019-08-10 17:57:17,103 epoch 5 - iter 65/139 - loss 0.10834814\n",
      "2019-08-10 17:57:19,612 epoch 5 - iter 78/139 - loss 0.10452516\n",
      "2019-08-10 17:57:20,228 epoch 5 - iter 91/139 - loss 0.09351552\n",
      "2019-08-10 17:57:20,810 epoch 5 - iter 104/139 - loss 0.09684549\n",
      "2019-08-10 17:57:21,383 epoch 5 - iter 117/139 - loss 0.09015822\n",
      "2019-08-10 17:57:21,915 epoch 5 - iter 130/139 - loss 0.09159375\n",
      "2019-08-10 17:57:22,710 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:57:22,713 EPOCH 5 done: loss 0.0916 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:57:24,501 DEV : loss 0.07645046710968018 - score 0.973\n",
      "2019-08-10 17:57:24,507 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:57:26,084 epoch 6 - iter 0/139 - loss 0.00850276\n",
      "2019-08-10 17:57:26,775 epoch 6 - iter 13/139 - loss 0.07345982\n",
      "2019-08-10 17:57:27,394 epoch 6 - iter 26/139 - loss 0.07884708\n",
      "2019-08-10 17:57:28,037 epoch 6 - iter 39/139 - loss 0.06375985\n",
      "2019-08-10 17:57:28,653 epoch 6 - iter 52/139 - loss 0.05997401\n",
      "2019-08-10 17:57:29,272 epoch 6 - iter 65/139 - loss 0.06616362\n",
      "2019-08-10 17:57:29,884 epoch 6 - iter 78/139 - loss 0.06465651\n",
      "2019-08-10 17:57:30,523 epoch 6 - iter 91/139 - loss 0.07660151\n",
      "2019-08-10 17:57:31,117 epoch 6 - iter 104/139 - loss 0.07683589\n",
      "2019-08-10 17:57:31,745 epoch 6 - iter 117/139 - loss 0.07568147\n",
      "2019-08-10 17:57:32,274 epoch 6 - iter 130/139 - loss 0.07965770\n",
      "2019-08-10 17:57:33,042 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:57:33,047 EPOCH 6 done: loss 0.0825 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:57:34,825 DEV : loss 0.06990379095077515 - score 0.9676\n",
      "2019-08-10 17:57:34,829 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:57:36,392 epoch 7 - iter 0/139 - loss 0.07503969\n",
      "2019-08-10 17:57:37,046 epoch 7 - iter 13/139 - loss 0.07009068\n",
      "2019-08-10 17:57:39,625 epoch 7 - iter 26/139 - loss 0.06041331\n",
      "2019-08-10 17:57:40,202 epoch 7 - iter 39/139 - loss 0.06511178\n",
      "2019-08-10 17:57:40,811 epoch 7 - iter 52/139 - loss 0.05738105\n",
      "2019-08-10 17:57:41,426 epoch 7 - iter 65/139 - loss 0.09735179\n",
      "2019-08-10 17:57:42,016 epoch 7 - iter 78/139 - loss 0.08944760\n",
      "2019-08-10 17:57:42,621 epoch 7 - iter 91/139 - loss 0.09858482\n",
      "2019-08-10 17:57:43,227 epoch 7 - iter 104/139 - loss 0.10088277\n",
      "2019-08-10 17:57:43,862 epoch 7 - iter 117/139 - loss 0.09593508\n",
      "2019-08-10 17:57:44,356 epoch 7 - iter 130/139 - loss 0.09258969\n",
      "2019-08-10 17:57:45,217 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:57:45,220 EPOCH 7 done: loss 0.0891 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 17:57:46,976 DEV : loss 0.07311669737100601 - score 0.9694\n",
      "2019-08-10 17:57:46,980 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:57:48,536 epoch 8 - iter 0/139 - loss 0.00562672\n",
      "2019-08-10 17:57:49,217 epoch 8 - iter 13/139 - loss 0.05534295\n",
      "2019-08-10 17:57:49,806 epoch 8 - iter 26/139 - loss 0.04725052\n",
      "2019-08-10 17:57:50,455 epoch 8 - iter 39/139 - loss 0.06600331\n",
      "2019-08-10 17:57:51,086 epoch 8 - iter 52/139 - loss 0.06559326\n",
      "2019-08-10 17:57:51,694 epoch 8 - iter 65/139 - loss 0.07254873\n",
      "2019-08-10 17:57:52,306 epoch 8 - iter 78/139 - loss 0.06805585\n",
      "2019-08-10 17:57:52,936 epoch 8 - iter 91/139 - loss 0.06935038\n",
      "2019-08-10 17:57:53,565 epoch 8 - iter 104/139 - loss 0.06509774\n",
      "2019-08-10 17:57:54,159 epoch 8 - iter 117/139 - loss 0.06088096\n",
      "2019-08-10 17:57:56,590 epoch 8 - iter 130/139 - loss 0.06305535\n",
      "2019-08-10 17:57:57,375 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:57:57,380 EPOCH 8 done: loss 0.0754 - lr 0.1500 - bad epochs 2\n",
      "2019-08-10 17:57:59,477 DEV : loss 0.0709383562207222 - score 0.9658\n",
      "2019-08-10 17:57:59,481 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:01,104 epoch 9 - iter 0/139 - loss 0.04690311\n",
      "2019-08-10 17:58:01,788 epoch 9 - iter 13/139 - loss 0.06019555\n",
      "2019-08-10 17:58:02,400 epoch 9 - iter 26/139 - loss 0.06520278\n",
      "2019-08-10 17:58:03,058 epoch 9 - iter 39/139 - loss 0.05561738\n",
      "2019-08-10 17:58:03,658 epoch 9 - iter 52/139 - loss 0.06725984\n",
      "2019-08-10 17:58:04,270 epoch 9 - iter 65/139 - loss 0.06574572\n",
      "2019-08-10 17:58:04,894 epoch 9 - iter 78/139 - loss 0.06265877\n",
      "2019-08-10 17:58:05,525 epoch 9 - iter 91/139 - loss 0.06033308\n",
      "2019-08-10 17:58:06,158 epoch 9 - iter 104/139 - loss 0.06969693\n",
      "2019-08-10 17:58:06,750 epoch 9 - iter 117/139 - loss 0.06686463\n",
      "2019-08-10 17:58:07,269 epoch 9 - iter 130/139 - loss 0.06520191\n",
      "2019-08-10 17:58:08,044 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:08,047 EPOCH 9 done: loss 0.0661 - lr 0.1500 - bad epochs 3\n",
      "2019-08-10 17:58:09,819 DEV : loss 0.056447453796863556 - score 0.9784\n",
      "2019-08-10 17:58:09,824 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:11,428 epoch 10 - iter 0/139 - loss 0.03745387\n",
      "2019-08-10 17:58:12,098 epoch 10 - iter 13/139 - loss 0.06336616\n",
      "2019-08-10 17:58:12,707 epoch 10 - iter 26/139 - loss 0.05940618\n",
      "2019-08-10 17:58:13,320 epoch 10 - iter 39/139 - loss 0.04682295\n",
      "2019-08-10 17:58:13,944 epoch 10 - iter 52/139 - loss 0.04528943\n",
      "2019-08-10 17:58:14,553 epoch 10 - iter 65/139 - loss 0.03862708\n",
      "2019-08-10 17:58:17,052 epoch 10 - iter 78/139 - loss 0.06236759\n",
      "2019-08-10 17:58:17,640 epoch 10 - iter 91/139 - loss 0.05741270\n",
      "2019-08-10 17:58:18,215 epoch 10 - iter 104/139 - loss 0.05788938\n",
      "2019-08-10 17:58:18,849 epoch 10 - iter 117/139 - loss 0.05780520\n",
      "2019-08-10 17:58:19,403 epoch 10 - iter 130/139 - loss 0.06222477\n",
      "2019-08-10 17:58:20,209 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:20,212 EPOCH 10 done: loss 0.0614 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 17:58:21,938 DEV : loss 0.06511204689741135 - score 0.9766\n",
      "2019-08-10 17:58:21,944 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:21,947 Testing using best model ...\n",
      "2019-08-10 17:58:23,703 0.9802\t0.9802\t0.9802\n",
      "2019-08-10 17:58:23,707 \n",
      "MICRO_AVG: acc 0.9611 - f1-score 0.9802\n",
      "MACRO_AVG: acc 0.9183 - f1-score 0.95635\n",
      "ham        tp: 477 - fp: 9 - fn: 2 - tn: 67 - precision: 0.9815 - recall: 0.9958 - accuracy: 0.9775 - f1-score: 0.9886\n",
      "spam       tp: 67 - fp: 2 - fn: 9 - tn: 477 - precision: 0.9710 - recall: 0.8816 - accuracy: 0.8590 - f1-score: 0.9241\n",
      "2019-08-10 17:58:23,710 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:23,714 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:23,716 Done evaluating parameter combination:\n",
      "2019-08-10 17:58:23,720 \tdropout: 0.36772469368140304\n",
      "2019-08-10 17:58:23,723 \tembeddings: /tmp/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-08-10 17:58:23,725 \thidden_size: 256\n",
      "2019-08-10 17:58:23,728 \tlearning_rate: 0.15\n",
      "2019-08-10 17:58:23,732 \tmini_batch_size: 32\n",
      "2019-08-10 17:58:23,735 \trnn_layers: 2\n",
      "2019-08-10 17:58:23,741 score: 0.027599999999999982\n",
      "2019-08-10 17:58:23,744 variance: 4.8959999999999856e-05\n",
      "2019-08-10 17:58:23,747 test_score: 0.9802\n",
      "\n",
      "2019-08-10 17:58:23,750 ----------------------------------------------------------------------------------------------------\n",
      " 80%|████████  | 8/10 [1:56:02<20:02, 601.16s/it, best loss: 0.011799999999999996]2019-08-10 17:58:23,765 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:23,768 Evaluation run: 9\n",
      "2019-08-10 17:58:23,770 Evaluating parameter combination:\n",
      "2019-08-10 17:58:23,773 \tdropout: 0.13652012820627824\n",
      "2019-08-10 17:58:23,775 \tembeddings: /tmp/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-08-10 17:58:23,777 \thidden_size: 256\n",
      "2019-08-10 17:58:23,779 \tlearning_rate: 0.1\n",
      "2019-08-10 17:58:23,782 \tmini_batch_size: 32\n",
      "2019-08-10 17:58:23,785 \trnn_layers: 1\n",
      "2019-08-10 17:58:23,786 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:26,433 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:26,435 Training run: 1\n",
      "2019-08-10 17:58:26,447 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:26,450 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 17:58:27,429 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:28,954 epoch 1 - iter 0/139 - loss 0.70269257\n",
      "2019-08-10 17:58:29,596 epoch 1 - iter 13/139 - loss 0.39373586\n",
      "2019-08-10 17:58:30,188 epoch 1 - iter 26/139 - loss 0.36773740\n",
      "2019-08-10 17:58:30,784 epoch 1 - iter 39/139 - loss 0.34953727\n",
      "2019-08-10 17:58:31,407 epoch 1 - iter 52/139 - loss 0.34711190\n",
      "2019-08-10 17:58:31,988 epoch 1 - iter 65/139 - loss 0.33732540\n",
      "2019-08-10 17:58:32,597 epoch 1 - iter 78/139 - loss 0.33432739\n",
      "2019-08-10 17:58:33,196 epoch 1 - iter 91/139 - loss 0.32658405\n",
      "2019-08-10 17:58:33,824 epoch 1 - iter 104/139 - loss 0.32172564\n",
      "2019-08-10 17:58:34,386 epoch 1 - iter 117/139 - loss 0.31241557\n",
      "2019-08-10 17:58:34,964 epoch 1 - iter 130/139 - loss 0.30404178\n",
      "2019-08-10 17:58:35,745 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:35,748 EPOCH 1 done: loss 0.3004 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:58:37,480 DEV : loss 0.23251168429851532 - score 0.9027\n",
      "2019-08-10 17:58:37,484 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:39,073 epoch 2 - iter 0/139 - loss 0.09974858\n",
      "2019-08-10 17:58:41,684 epoch 2 - iter 13/139 - loss 0.24357378\n",
      "2019-08-10 17:58:42,276 epoch 2 - iter 26/139 - loss 0.20078661\n",
      "2019-08-10 17:58:42,842 epoch 2 - iter 39/139 - loss 0.19180937\n",
      "2019-08-10 17:58:43,435 epoch 2 - iter 52/139 - loss 0.19220258\n",
      "2019-08-10 17:58:44,027 epoch 2 - iter 65/139 - loss 0.19121330\n",
      "2019-08-10 17:58:44,608 epoch 2 - iter 78/139 - loss 0.18244610\n",
      "2019-08-10 17:58:45,223 epoch 2 - iter 91/139 - loss 0.18682210\n",
      "2019-08-10 17:58:45,750 epoch 2 - iter 104/139 - loss 0.18089907\n",
      "2019-08-10 17:58:46,350 epoch 2 - iter 117/139 - loss 0.17007111\n",
      "2019-08-10 17:58:46,835 epoch 2 - iter 130/139 - loss 0.16369209\n",
      "2019-08-10 17:58:47,605 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:47,610 EPOCH 2 done: loss 0.1612 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:58:49,348 DEV : loss 0.13158567249774933 - score 0.9495\n",
      "2019-08-10 17:58:49,352 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:50,911 epoch 3 - iter 0/139 - loss 0.36075065\n",
      "2019-08-10 17:58:51,589 epoch 3 - iter 13/139 - loss 0.21371614\n",
      "2019-08-10 17:58:52,161 epoch 3 - iter 26/139 - loss 0.19591426\n",
      "2019-08-10 17:58:52,789 epoch 3 - iter 39/139 - loss 0.16857860\n",
      "2019-08-10 17:58:53,383 epoch 3 - iter 52/139 - loss 0.18270619\n",
      "2019-08-10 17:58:53,977 epoch 3 - iter 65/139 - loss 0.16755915\n",
      "2019-08-10 17:58:54,549 epoch 3 - iter 78/139 - loss 0.16377754\n",
      "2019-08-10 17:58:55,160 epoch 3 - iter 91/139 - loss 0.15531123\n",
      "2019-08-10 17:58:57,619 epoch 3 - iter 104/139 - loss 0.14573918\n",
      "2019-08-10 17:58:58,178 epoch 3 - iter 117/139 - loss 0.14864847\n",
      "2019-08-10 17:58:58,655 epoch 3 - iter 130/139 - loss 0.14203393\n",
      "2019-08-10 17:58:59,453 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:58:59,455 EPOCH 3 done: loss 0.1418 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:59:01,178 DEV : loss 0.09287431091070175 - score 0.9676\n",
      "2019-08-10 17:59:01,182 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:59:02,729 epoch 4 - iter 0/139 - loss 0.04612179\n",
      "2019-08-10 17:59:03,345 epoch 4 - iter 13/139 - loss 0.08291859\n",
      "2019-08-10 17:59:03,965 epoch 4 - iter 26/139 - loss 0.09255736\n",
      "2019-08-10 17:59:04,576 epoch 4 - iter 39/139 - loss 0.10044641\n",
      "2019-08-10 17:59:05,132 epoch 4 - iter 52/139 - loss 0.11886973\n",
      "2019-08-10 17:59:05,754 epoch 4 - iter 65/139 - loss 0.11008845\n",
      "2019-08-10 17:59:06,324 epoch 4 - iter 78/139 - loss 0.10593419\n",
      "2019-08-10 17:59:06,951 epoch 4 - iter 91/139 - loss 0.10729192\n",
      "2019-08-10 17:59:07,563 epoch 4 - iter 104/139 - loss 0.10674287\n",
      "2019-08-10 17:59:08,144 epoch 4 - iter 117/139 - loss 0.09960906\n",
      "2019-08-10 17:59:08,634 epoch 4 - iter 130/139 - loss 0.09840663\n",
      "2019-08-10 17:59:09,405 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:59:09,408 EPOCH 4 done: loss 0.1122 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:59:11,118 DEV : loss 0.13128836452960968 - score 0.9568\n",
      "2019-08-10 17:59:11,122 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:59:12,683 epoch 5 - iter 0/139 - loss 0.16933307\n",
      "2019-08-10 17:59:13,328 epoch 5 - iter 13/139 - loss 0.10148691\n",
      "2019-08-10 17:59:13,935 epoch 5 - iter 26/139 - loss 0.10276014\n",
      "2019-08-10 17:59:14,526 epoch 5 - iter 39/139 - loss 0.10054916\n",
      "2019-08-10 17:59:17,097 epoch 5 - iter 52/139 - loss 0.09128683\n",
      "2019-08-10 17:59:17,659 epoch 5 - iter 65/139 - loss 0.08995763\n",
      "2019-08-10 17:59:18,242 epoch 5 - iter 78/139 - loss 0.08344055\n",
      "2019-08-10 17:59:18,802 epoch 5 - iter 91/139 - loss 0.08304474\n",
      "2019-08-10 17:59:19,394 epoch 5 - iter 104/139 - loss 0.08592617\n",
      "2019-08-10 17:59:19,932 epoch 5 - iter 117/139 - loss 0.08366236\n",
      "2019-08-10 17:59:20,432 epoch 5 - iter 130/139 - loss 0.07984283\n",
      "2019-08-10 17:59:21,204 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:59:21,208 EPOCH 5 done: loss 0.0780 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 17:59:22,933 DEV : loss 0.06885639578104019 - score 0.9748\n",
      "2019-08-10 17:59:22,937 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:59:24,498 epoch 6 - iter 0/139 - loss 0.07118564\n",
      "2019-08-10 17:59:25,124 epoch 6 - iter 13/139 - loss 0.05415019\n",
      "2019-08-10 17:59:25,746 epoch 6 - iter 26/139 - loss 0.05588357\n",
      "2019-08-10 17:59:26,352 epoch 6 - iter 39/139 - loss 0.06036313\n",
      "2019-08-10 17:59:26,921 epoch 6 - iter 52/139 - loss 0.05812697\n",
      "2019-08-10 17:59:27,500 epoch 6 - iter 65/139 - loss 0.08216410\n",
      "2019-08-10 17:59:28,084 epoch 6 - iter 78/139 - loss 0.09088718\n",
      "2019-08-10 17:59:28,668 epoch 6 - iter 91/139 - loss 0.09011847\n",
      "2019-08-10 17:59:29,265 epoch 6 - iter 104/139 - loss 0.08339146\n",
      "2019-08-10 17:59:29,868 epoch 6 - iter 117/139 - loss 0.07955746\n",
      "2019-08-10 17:59:30,360 epoch 6 - iter 130/139 - loss 0.08068323\n",
      "2019-08-10 17:59:31,157 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:59:31,160 EPOCH 6 done: loss 0.0805 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 17:59:32,882 DEV : loss 0.08699730038642883 - score 0.9604\n",
      "2019-08-10 17:59:32,888 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:59:36,423 epoch 7 - iter 0/139 - loss 0.01908633\n",
      "2019-08-10 17:59:37,032 epoch 7 - iter 13/139 - loss 0.03411896\n",
      "2019-08-10 17:59:37,598 epoch 7 - iter 26/139 - loss 0.06055096\n",
      "2019-08-10 17:59:38,195 epoch 7 - iter 39/139 - loss 0.07310268\n",
      "2019-08-10 17:59:38,767 epoch 7 - iter 52/139 - loss 0.08878660\n",
      "2019-08-10 17:59:41,439 epoch 7 - iter 65/139 - loss 0.08267691\n",
      "2019-08-10 17:59:43,822 epoch 7 - iter 78/139 - loss 0.07265006\n",
      "2019-08-10 17:59:48,795 epoch 7 - iter 91/139 - loss 0.06465165\n",
      "2019-08-10 17:59:51,128 epoch 7 - iter 104/139 - loss 0.07435660\n",
      "2019-08-10 17:59:51,696 epoch 7 - iter 117/139 - loss 0.07223368\n",
      "2019-08-10 17:59:52,202 epoch 7 - iter 130/139 - loss 0.07374385\n",
      "2019-08-10 17:59:53,169 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:59:53,174 EPOCH 7 done: loss 0.0731 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 17:59:54,905 DEV : loss 0.07293564826250076 - score 0.9748\n",
      "2019-08-10 17:59:54,911 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 17:59:56,505 epoch 8 - iter 0/139 - loss 0.01720992\n",
      "2019-08-10 17:59:57,140 epoch 8 - iter 13/139 - loss 0.06074320\n",
      "2019-08-10 17:59:57,750 epoch 8 - iter 26/139 - loss 0.06270515\n",
      "2019-08-10 17:59:58,363 epoch 8 - iter 39/139 - loss 0.06011791\n",
      "2019-08-10 17:59:58,976 epoch 8 - iter 52/139 - loss 0.05815242\n",
      "2019-08-10 17:59:59,589 epoch 8 - iter 65/139 - loss 0.06142311\n",
      "2019-08-10 18:00:00,172 epoch 8 - iter 78/139 - loss 0.05854857\n",
      "2019-08-10 18:00:02,668 epoch 8 - iter 91/139 - loss 0.05944042\n",
      "2019-08-10 18:00:03,216 epoch 8 - iter 104/139 - loss 0.05673095\n",
      "2019-08-10 18:00:03,829 epoch 8 - iter 117/139 - loss 0.06242376\n",
      "2019-08-10 18:00:04,335 epoch 8 - iter 130/139 - loss 0.06837885\n",
      "2019-08-10 18:00:05,133 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:00:05,136 EPOCH 8 done: loss 0.0703 - lr 0.1000 - bad epochs 2\n",
      "2019-08-10 18:00:06,911 DEV : loss 0.06634525954723358 - score 0.9766\n",
      "2019-08-10 18:00:06,916 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:00:08,473 epoch 9 - iter 0/139 - loss 0.04863830\n",
      "2019-08-10 18:00:09,100 epoch 9 - iter 13/139 - loss 0.09525180\n",
      "2019-08-10 18:00:09,726 epoch 9 - iter 26/139 - loss 0.07432007\n",
      "2019-08-10 18:00:10,322 epoch 9 - iter 39/139 - loss 0.07198429\n",
      "2019-08-10 18:00:10,957 epoch 9 - iter 52/139 - loss 0.08625669\n",
      "2019-08-10 18:00:11,565 epoch 9 - iter 65/139 - loss 0.08216352\n",
      "2019-08-10 18:00:12,200 epoch 9 - iter 78/139 - loss 0.07701629\n",
      "2019-08-10 18:00:12,753 epoch 9 - iter 91/139 - loss 0.07031136\n",
      "2019-08-10 18:00:13,375 epoch 9 - iter 104/139 - loss 0.06570678\n",
      "2019-08-10 18:00:13,952 epoch 9 - iter 117/139 - loss 0.06391633\n",
      "2019-08-10 18:00:14,466 epoch 9 - iter 130/139 - loss 0.06273393\n",
      "2019-08-10 18:00:15,210 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:00:15,212 EPOCH 9 done: loss 0.0617 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 18:00:16,940 DEV : loss 0.0959179475903511 - score 0.9604\n",
      "2019-08-10 18:00:16,945 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:00:18,550 epoch 10 - iter 0/139 - loss 0.00232147\n",
      "2019-08-10 18:00:19,165 epoch 10 - iter 13/139 - loss 0.06656103\n",
      "2019-08-10 18:00:19,821 epoch 10 - iter 26/139 - loss 0.06208925\n",
      "2019-08-10 18:00:20,389 epoch 10 - iter 39/139 - loss 0.05438842\n",
      "2019-08-10 18:00:22,936 epoch 10 - iter 52/139 - loss 0.05662753\n",
      "2019-08-10 18:00:23,529 epoch 10 - iter 65/139 - loss 0.05337735\n",
      "2019-08-10 18:00:24,101 epoch 10 - iter 78/139 - loss 0.05096484\n",
      "2019-08-10 18:00:24,668 epoch 10 - iter 91/139 - loss 0.05127557\n",
      "2019-08-10 18:00:25,221 epoch 10 - iter 104/139 - loss 0.05032072\n",
      "2019-08-10 18:00:25,801 epoch 10 - iter 117/139 - loss 0.05659307\n",
      "2019-08-10 18:00:26,280 epoch 10 - iter 130/139 - loss 0.05627664\n",
      "2019-08-10 18:00:27,077 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:00:27,080 EPOCH 10 done: loss 0.0553 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 18:00:28,770 DEV : loss 0.2455652505159378 - score 0.9261\n",
      "2019-08-10 18:00:28,774 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:00:28,776 Testing using best model ...\n",
      "2019-08-10 18:00:30,484 0.9333\t0.9333\t0.9333\n",
      "2019-08-10 18:00:30,491 \n",
      "MICRO_AVG: acc 0.875 - f1-score 0.9333\n",
      "MACRO_AVG: acc 0.7208 - f1-score 0.82055\n",
      "ham        tp: 479 - fp: 37 - fn: 0 - tn: 39 - precision: 0.9283 - recall: 1.0000 - accuracy: 0.9283 - f1-score: 0.9628\n",
      "spam       tp: 39 - fp: 0 - fn: 37 - tn: 479 - precision: 1.0000 - recall: 0.5132 - accuracy: 0.5132 - f1-score: 0.6783\n",
      "2019-08-10 18:00:30,494 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:00:30,497 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:00:30,499 Training run: 2\n",
      "2019-08-10 18:00:30,511 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:00:30,513 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 18:00:31,481 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:00:33,057 epoch 1 - iter 0/139 - loss 0.81126708\n",
      "2019-08-10 18:00:33,734 epoch 1 - iter 13/139 - loss 0.48803066\n",
      "2019-08-10 18:00:34,292 epoch 1 - iter 26/139 - loss 0.42234841\n",
      "2019-08-10 18:00:34,919 epoch 1 - iter 39/139 - loss 0.39563203\n",
      "2019-08-10 18:00:35,493 epoch 1 - iter 52/139 - loss 0.39396412\n",
      "2019-08-10 18:00:36,072 epoch 1 - iter 65/139 - loss 0.37831922\n",
      "2019-08-10 18:00:36,668 epoch 1 - iter 78/139 - loss 0.36081323\n",
      "2019-08-10 18:00:37,257 epoch 1 - iter 91/139 - loss 0.35510300\n",
      "2019-08-10 18:00:37,836 epoch 1 - iter 104/139 - loss 0.34242912\n",
      "2019-08-10 18:00:38,429 epoch 1 - iter 117/139 - loss 0.33347418\n",
      "2019-08-10 18:00:40,796 epoch 1 - iter 130/139 - loss 0.32222602\n",
      "2019-08-10 18:00:41,596 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:00:41,599 EPOCH 1 done: loss 0.3195 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 18:00:43,343 DEV : loss 0.25512540340423584 - score 0.9063\n",
      "2019-08-10 18:00:43,349 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:00:44,919 epoch 2 - iter 0/139 - loss 0.11032052\n",
      "2019-08-10 18:00:45,588 epoch 2 - iter 13/139 - loss 0.21877462\n",
      "2019-08-10 18:00:46,187 epoch 2 - iter 26/139 - loss 0.21028756\n",
      "2019-08-10 18:00:46,801 epoch 2 - iter 39/139 - loss 0.20918954\n",
      "2019-08-10 18:00:47,383 epoch 2 - iter 52/139 - loss 0.22036488\n",
      "2019-08-10 18:00:47,952 epoch 2 - iter 65/139 - loss 0.21360884\n",
      "2019-08-10 18:00:48,567 epoch 2 - iter 78/139 - loss 0.20233015\n",
      "2019-08-10 18:00:49,127 epoch 2 - iter 91/139 - loss 0.19634332\n",
      "2019-08-10 18:00:49,736 epoch 2 - iter 104/139 - loss 0.18615489\n",
      "2019-08-10 18:00:50,340 epoch 2 - iter 117/139 - loss 0.19842453\n",
      "2019-08-10 18:00:50,834 epoch 2 - iter 130/139 - loss 0.19620420\n",
      "2019-08-10 18:00:51,612 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:00:51,616 EPOCH 2 done: loss 0.1917 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 18:00:53,341 DEV : loss 0.1273733228445053 - score 0.955\n",
      "2019-08-10 18:00:53,345 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:00:54,883 epoch 3 - iter 0/139 - loss 0.17801881\n",
      "2019-08-10 18:00:55,554 epoch 3 - iter 13/139 - loss 0.17708678\n",
      "2019-08-10 18:00:56,130 epoch 3 - iter 26/139 - loss 0.15336727\n",
      "2019-08-10 18:00:56,737 epoch 3 - iter 39/139 - loss 0.14385217\n",
      "2019-08-10 18:00:57,340 epoch 3 - iter 52/139 - loss 0.12747560\n",
      "2019-08-10 18:00:57,909 epoch 3 - iter 65/139 - loss 0.13993042\n",
      "2019-08-10 18:01:00,405 epoch 3 - iter 78/139 - loss 0.14637001\n",
      "2019-08-10 18:01:01,008 epoch 3 - iter 91/139 - loss 0.14127763\n",
      "2019-08-10 18:01:01,568 epoch 3 - iter 104/139 - loss 0.13273961\n",
      "2019-08-10 18:01:02,139 epoch 3 - iter 117/139 - loss 0.12782087\n",
      "2019-08-10 18:01:02,626 epoch 3 - iter 130/139 - loss 0.12840045\n",
      "2019-08-10 18:01:03,405 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:01:03,408 EPOCH 3 done: loss 0.1309 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 18:01:05,166 DEV : loss 0.09148061275482178 - score 0.964\n",
      "2019-08-10 18:01:05,170 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:01:06,724 epoch 4 - iter 0/139 - loss 0.01886969\n",
      "2019-08-10 18:01:07,381 epoch 4 - iter 13/139 - loss 0.08112424\n",
      "2019-08-10 18:01:07,996 epoch 4 - iter 26/139 - loss 0.11047190\n",
      "2019-08-10 18:01:08,592 epoch 4 - iter 39/139 - loss 0.09876138\n",
      "2019-08-10 18:01:09,198 epoch 4 - iter 52/139 - loss 0.10153079\n",
      "2019-08-10 18:01:09,793 epoch 4 - iter 65/139 - loss 0.11021717\n",
      "2019-08-10 18:01:10,402 epoch 4 - iter 78/139 - loss 0.11157770\n",
      "2019-08-10 18:01:10,988 epoch 4 - iter 91/139 - loss 0.11016340\n",
      "2019-08-10 18:01:11,597 epoch 4 - iter 104/139 - loss 0.12107388\n",
      "2019-08-10 18:01:12,204 epoch 4 - iter 117/139 - loss 0.11776201\n",
      "2019-08-10 18:01:12,697 epoch 4 - iter 130/139 - loss 0.12127757\n",
      "2019-08-10 18:01:13,469 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:01:13,472 EPOCH 4 done: loss 0.1183 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 18:01:15,205 DEV : loss 0.29871422052383423 - score 0.9009\n",
      "2019-08-10 18:01:15,209 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:01:16,764 epoch 5 - iter 0/139 - loss 0.05773453\n",
      "2019-08-10 18:01:17,392 epoch 5 - iter 13/139 - loss 0.10995348\n",
      "2019-08-10 18:01:19,971 epoch 5 - iter 26/139 - loss 0.13322606\n",
      "2019-08-10 18:01:20,568 epoch 5 - iter 39/139 - loss 0.10778480\n",
      "2019-08-10 18:01:21,118 epoch 5 - iter 52/139 - loss 0.11958259\n",
      "2019-08-10 18:01:21,712 epoch 5 - iter 65/139 - loss 0.11335235\n",
      "2019-08-10 18:01:22,284 epoch 5 - iter 78/139 - loss 0.10581522\n",
      "2019-08-10 18:01:22,843 epoch 5 - iter 91/139 - loss 0.10304284\n",
      "2019-08-10 18:01:23,452 epoch 5 - iter 104/139 - loss 0.09832111\n",
      "2019-08-10 18:01:24,033 epoch 5 - iter 117/139 - loss 0.09560962\n",
      "2019-08-10 18:01:24,533 epoch 5 - iter 130/139 - loss 0.09390417\n",
      "2019-08-10 18:01:25,288 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:01:25,291 EPOCH 5 done: loss 0.0982 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 18:01:27,038 DEV : loss 1.8720508813858032 - score 0.3604\n",
      "2019-08-10 18:01:27,042 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:01:28,583 epoch 6 - iter 0/139 - loss 1.62496090\n",
      "2019-08-10 18:01:29,200 epoch 6 - iter 13/139 - loss 0.18657589\n",
      "2019-08-10 18:01:29,787 epoch 6 - iter 26/139 - loss 0.11310830\n",
      "2019-08-10 18:01:30,371 epoch 6 - iter 39/139 - loss 0.11422524\n",
      "2019-08-10 18:01:31,013 epoch 6 - iter 52/139 - loss 0.10514745\n",
      "2019-08-10 18:01:31,589 epoch 6 - iter 65/139 - loss 0.09998694\n",
      "2019-08-10 18:01:32,181 epoch 6 - iter 78/139 - loss 0.10018897\n",
      "2019-08-10 18:01:32,785 epoch 6 - iter 91/139 - loss 0.09127129\n",
      "2019-08-10 18:01:33,338 epoch 6 - iter 104/139 - loss 0.08770487\n",
      "2019-08-10 18:01:33,992 epoch 6 - iter 117/139 - loss 0.08550156\n",
      "2019-08-10 18:01:36,354 epoch 6 - iter 130/139 - loss 0.08636825\n",
      "2019-08-10 18:01:37,127 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:01:37,132 EPOCH 6 done: loss 0.0861 - lr 0.1000 - bad epochs 2\n",
      "2019-08-10 18:01:38,855 DEV : loss 0.0673309713602066 - score 0.9748\n",
      "2019-08-10 18:01:38,859 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:01:40,445 epoch 7 - iter 0/139 - loss 0.01263825\n",
      "2019-08-10 18:01:41,065 epoch 7 - iter 13/139 - loss 0.07354517\n",
      "2019-08-10 18:01:41,663 epoch 7 - iter 26/139 - loss 0.09162964\n",
      "2019-08-10 18:01:42,246 epoch 7 - iter 39/139 - loss 0.08733668\n",
      "2019-08-10 18:01:42,835 epoch 7 - iter 52/139 - loss 0.08203803\n",
      "2019-08-10 18:01:43,440 epoch 7 - iter 65/139 - loss 0.07333252\n",
      "2019-08-10 18:01:44,018 epoch 7 - iter 78/139 - loss 0.08143377\n",
      "2019-08-10 18:01:44,614 epoch 7 - iter 91/139 - loss 0.08615236\n",
      "2019-08-10 18:01:45,252 epoch 7 - iter 104/139 - loss 0.08480192\n",
      "2019-08-10 18:01:45,848 epoch 7 - iter 117/139 - loss 0.07983280\n",
      "2019-08-10 18:01:46,355 epoch 7 - iter 130/139 - loss 0.07514567\n",
      "2019-08-10 18:01:47,084 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:01:47,088 EPOCH 7 done: loss 0.0782 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 18:01:48,844 DEV : loss 2.167398452758789 - score 0.4\n",
      "2019-08-10 18:01:48,848 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:01:50,433 epoch 8 - iter 0/139 - loss 2.19469571\n",
      "2019-08-10 18:01:51,053 epoch 8 - iter 13/139 - loss 0.23397349\n",
      "2019-08-10 18:01:51,676 epoch 8 - iter 26/139 - loss 0.14512380\n",
      "2019-08-10 18:01:52,261 epoch 8 - iter 39/139 - loss 0.11666195\n",
      "2019-08-10 18:01:52,880 epoch 8 - iter 52/139 - loss 0.09449397\n",
      "2019-08-10 18:01:53,434 epoch 8 - iter 65/139 - loss 0.08763120\n",
      "2019-08-10 18:01:54,044 epoch 8 - iter 78/139 - loss 0.08607017\n",
      "2019-08-10 18:01:56,569 epoch 8 - iter 91/139 - loss 0.08053830\n",
      "2019-08-10 18:01:57,146 epoch 8 - iter 104/139 - loss 0.07753443\n",
      "2019-08-10 18:01:57,680 epoch 8 - iter 117/139 - loss 0.07699786\n",
      "2019-08-10 18:01:58,191 epoch 8 - iter 130/139 - loss 0.07866585\n",
      "2019-08-10 18:01:59,007 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:01:59,012 EPOCH 8 done: loss 0.0775 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 18:02:00,720 DEV : loss 0.05841014161705971 - score 0.9802\n",
      "2019-08-10 18:02:00,725 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:02:02,279 epoch 9 - iter 0/139 - loss 0.03413257\n",
      "2019-08-10 18:02:02,927 epoch 9 - iter 13/139 - loss 0.05421708\n",
      "2019-08-10 18:02:03,518 epoch 9 - iter 26/139 - loss 0.05151054\n",
      "2019-08-10 18:02:04,120 epoch 9 - iter 39/139 - loss 0.05339570\n",
      "2019-08-10 18:02:04,699 epoch 9 - iter 52/139 - loss 0.05498571\n",
      "2019-08-10 18:02:05,307 epoch 9 - iter 65/139 - loss 0.05523385\n",
      "2019-08-10 18:02:05,912 epoch 9 - iter 78/139 - loss 0.05293568\n",
      "2019-08-10 18:02:06,490 epoch 9 - iter 91/139 - loss 0.05732851\n",
      "2019-08-10 18:02:07,063 epoch 9 - iter 104/139 - loss 0.05504983\n",
      "2019-08-10 18:02:07,650 epoch 9 - iter 117/139 - loss 0.05395526\n",
      "2019-08-10 18:02:08,181 epoch 9 - iter 130/139 - loss 0.05866431\n",
      "2019-08-10 18:02:08,928 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:02:08,933 EPOCH 9 done: loss 0.0571 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 18:02:10,651 DEV : loss 0.05504068732261658 - score 0.982\n",
      "2019-08-10 18:02:10,655 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:02:12,216 epoch 10 - iter 0/139 - loss 0.01923561\n",
      "2019-08-10 18:02:12,838 epoch 10 - iter 13/139 - loss 0.12022118\n",
      "2019-08-10 18:02:13,461 epoch 10 - iter 26/139 - loss 0.08238285\n",
      "2019-08-10 18:02:15,997 epoch 10 - iter 39/139 - loss 0.08762240\n",
      "2019-08-10 18:02:16,587 epoch 10 - iter 52/139 - loss 0.07065989\n",
      "2019-08-10 18:02:17,161 epoch 10 - iter 65/139 - loss 0.06533130\n",
      "2019-08-10 18:02:17,720 epoch 10 - iter 78/139 - loss 0.07312238\n",
      "2019-08-10 18:02:18,307 epoch 10 - iter 91/139 - loss 0.06901083\n",
      "2019-08-10 18:02:18,881 epoch 10 - iter 104/139 - loss 0.06667942\n",
      "2019-08-10 18:02:19,460 epoch 10 - iter 117/139 - loss 0.06286601\n",
      "2019-08-10 18:02:19,956 epoch 10 - iter 130/139 - loss 0.06228343\n",
      "2019-08-10 18:02:20,726 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:02:20,729 EPOCH 10 done: loss 0.0599 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 18:02:22,475 DEV : loss 0.06143014878034592 - score 0.9766\n",
      "2019-08-10 18:02:22,479 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:02:22,482 Testing using best model ...\n",
      "2019-08-10 18:02:24,228 0.9766\t0.9766\t0.9766\n",
      "2019-08-10 18:02:24,232 \n",
      "MICRO_AVG: acc 0.9542 - f1-score 0.9766\n",
      "MACRO_AVG: acc 0.9101 - f1-score 0.9518\n",
      "ham        tp: 470 - fp: 4 - fn: 9 - tn: 72 - precision: 0.9916 - recall: 0.9812 - accuracy: 0.9731 - f1-score: 0.9864\n",
      "spam       tp: 72 - fp: 9 - fn: 4 - tn: 470 - precision: 0.8889 - recall: 0.9474 - accuracy: 0.8471 - f1-score: 0.9172\n",
      "2019-08-10 18:02:24,235 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:02:24,238 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:02:24,240 Training run: 3\n",
      "2019-08-10 18:02:24,253 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:02:24,256 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 18:02:25,254 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:02:26,835 epoch 1 - iter 0/139 - loss 0.65576065\n",
      "2019-08-10 18:02:27,461 epoch 1 - iter 13/139 - loss 0.41671272\n",
      "2019-08-10 18:02:28,077 epoch 1 - iter 26/139 - loss 0.41108721\n",
      "2019-08-10 18:02:28,723 epoch 1 - iter 39/139 - loss 0.38071535\n",
      "2019-08-10 18:02:29,331 epoch 1 - iter 52/139 - loss 0.37362964\n",
      "2019-08-10 18:02:29,954 epoch 1 - iter 65/139 - loss 0.34933681\n",
      "2019-08-10 18:02:30,555 epoch 1 - iter 78/139 - loss 0.33878959\n",
      "2019-08-10 18:02:31,172 epoch 1 - iter 91/139 - loss 0.32974781\n",
      "2019-08-10 18:02:31,795 epoch 1 - iter 104/139 - loss 0.32183417\n",
      "2019-08-10 18:02:34,257 epoch 1 - iter 117/139 - loss 0.30889126\n",
      "2019-08-10 18:02:34,713 epoch 1 - iter 130/139 - loss 0.30658762\n",
      "2019-08-10 18:02:35,503 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:02:35,506 EPOCH 1 done: loss 0.3019 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 18:02:37,248 DEV : loss 0.25666552782058716 - score 0.8901\n",
      "2019-08-10 18:02:37,252 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:02:38,840 epoch 2 - iter 0/139 - loss 0.29391366\n",
      "2019-08-10 18:02:39,483 epoch 2 - iter 13/139 - loss 0.18542810\n",
      "2019-08-10 18:02:40,118 epoch 2 - iter 26/139 - loss 0.17987532\n",
      "2019-08-10 18:02:40,690 epoch 2 - iter 39/139 - loss 0.17670086\n",
      "2019-08-10 18:02:41,291 epoch 2 - iter 52/139 - loss 0.16878063\n",
      "2019-08-10 18:02:41,875 epoch 2 - iter 65/139 - loss 0.16317668\n",
      "2019-08-10 18:02:42,453 epoch 2 - iter 78/139 - loss 0.18003346\n",
      "2019-08-10 18:02:43,028 epoch 2 - iter 91/139 - loss 0.17118359\n",
      "2019-08-10 18:02:43,614 epoch 2 - iter 104/139 - loss 0.16763644\n",
      "2019-08-10 18:02:44,226 epoch 2 - iter 117/139 - loss 0.17164400\n",
      "2019-08-10 18:02:44,727 epoch 2 - iter 130/139 - loss 0.16589042\n",
      "2019-08-10 18:02:45,524 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:02:45,528 EPOCH 2 done: loss 0.1697 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 18:02:47,246 DEV : loss 0.17971710860729218 - score 0.9351\n",
      "2019-08-10 18:02:47,250 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:02:48,784 epoch 3 - iter 0/139 - loss 0.32301876\n",
      "2019-08-10 18:02:49,445 epoch 3 - iter 13/139 - loss 0.15101323\n",
      "2019-08-10 18:02:50,032 epoch 3 - iter 26/139 - loss 0.14531042\n",
      "2019-08-10 18:02:50,592 epoch 3 - iter 39/139 - loss 0.11819570\n",
      "2019-08-10 18:02:51,192 epoch 3 - iter 52/139 - loss 0.12782551\n",
      "2019-08-10 18:02:53,680 epoch 3 - iter 65/139 - loss 0.11509863\n",
      "2019-08-10 18:02:54,254 epoch 3 - iter 78/139 - loss 0.11087875\n",
      "2019-08-10 18:02:54,870 epoch 3 - iter 91/139 - loss 0.11216274\n",
      "2019-08-10 18:02:55,459 epoch 3 - iter 104/139 - loss 0.11242264\n",
      "2019-08-10 18:02:56,062 epoch 3 - iter 117/139 - loss 0.11125566\n",
      "2019-08-10 18:02:56,540 epoch 3 - iter 130/139 - loss 0.12049284\n",
      "2019-08-10 18:02:57,320 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:02:57,324 EPOCH 3 done: loss 0.1177 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 18:02:59,050 DEV : loss 0.08905858546495438 - score 0.9622\n",
      "2019-08-10 18:02:59,054 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:03:00,647 epoch 4 - iter 0/139 - loss 0.21083112\n",
      "2019-08-10 18:03:01,552 epoch 4 - iter 13/139 - loss 0.08784172\n",
      "2019-08-10 18:03:02,321 epoch 4 - iter 26/139 - loss 0.12143634\n",
      "2019-08-10 18:03:02,984 epoch 4 - iter 39/139 - loss 0.10741353\n",
      "2019-08-10 18:03:03,588 epoch 4 - iter 52/139 - loss 0.11645867\n",
      "2019-08-10 18:03:04,209 epoch 4 - iter 65/139 - loss 0.10147565\n",
      "2019-08-10 18:03:04,838 epoch 4 - iter 78/139 - loss 0.09339951\n",
      "2019-08-10 18:03:05,412 epoch 4 - iter 91/139 - loss 0.10027708\n",
      "2019-08-10 18:03:06,026 epoch 4 - iter 104/139 - loss 0.10014548\n",
      "2019-08-10 18:03:06,601 epoch 4 - iter 117/139 - loss 0.10477691\n",
      "2019-08-10 18:03:07,102 epoch 4 - iter 130/139 - loss 0.10267947\n",
      "2019-08-10 18:03:07,862 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:03:07,870 EPOCH 4 done: loss 0.1025 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 18:03:09,612 DEV : loss 0.09284522384405136 - score 0.964\n",
      "2019-08-10 18:03:09,616 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:03:11,204 epoch 5 - iter 0/139 - loss 0.01275147\n",
      "2019-08-10 18:03:13,861 epoch 5 - iter 13/139 - loss 0.07896707\n",
      "2019-08-10 18:03:14,400 epoch 5 - iter 26/139 - loss 0.09975421\n",
      "2019-08-10 18:03:14,966 epoch 5 - iter 39/139 - loss 0.07854032\n",
      "2019-08-10 18:03:15,533 epoch 5 - iter 52/139 - loss 0.09002040\n",
      "2019-08-10 18:03:16,103 epoch 5 - iter 65/139 - loss 0.08906455\n",
      "2019-08-10 18:03:16,717 epoch 5 - iter 78/139 - loss 0.09170916\n",
      "2019-08-10 18:03:17,271 epoch 5 - iter 91/139 - loss 0.08740745\n",
      "2019-08-10 18:03:17,850 epoch 5 - iter 104/139 - loss 0.08505393\n",
      "2019-08-10 18:03:18,440 epoch 5 - iter 117/139 - loss 0.08476955\n",
      "2019-08-10 18:03:18,929 epoch 5 - iter 130/139 - loss 0.08854836\n",
      "2019-08-10 18:03:19,742 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:03:19,745 EPOCH 5 done: loss 0.0866 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 18:03:21,478 DEV : loss 0.07068251818418503 - score 0.9766\n",
      "2019-08-10 18:03:21,484 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:03:23,050 epoch 6 - iter 0/139 - loss 0.02306666\n",
      "2019-08-10 18:03:23,682 epoch 6 - iter 13/139 - loss 0.05980099\n",
      "2019-08-10 18:03:24,248 epoch 6 - iter 26/139 - loss 0.05769691\n",
      "2019-08-10 18:03:24,869 epoch 6 - iter 39/139 - loss 0.06672914\n",
      "2019-08-10 18:03:25,474 epoch 6 - iter 52/139 - loss 0.06668049\n",
      "2019-08-10 18:03:26,096 epoch 6 - iter 65/139 - loss 0.08224112\n",
      "2019-08-10 18:03:26,692 epoch 6 - iter 78/139 - loss 0.07830179\n",
      "2019-08-10 18:03:27,278 epoch 6 - iter 91/139 - loss 0.07913313\n",
      "2019-08-10 18:03:27,838 epoch 6 - iter 104/139 - loss 0.07622280\n",
      "2019-08-10 18:03:30,314 epoch 6 - iter 117/139 - loss 0.07273451\n",
      "2019-08-10 18:03:30,812 epoch 6 - iter 130/139 - loss 0.08021489\n",
      "2019-08-10 18:03:31,577 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:03:31,580 EPOCH 6 done: loss 0.0791 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 18:03:33,303 DEV : loss 0.07031241059303284 - score 0.9676\n",
      "2019-08-10 18:03:33,307 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:03:34,854 epoch 7 - iter 0/139 - loss 0.02812485\n",
      "2019-08-10 18:03:35,476 epoch 7 - iter 13/139 - loss 0.05557389\n",
      "2019-08-10 18:03:36,093 epoch 7 - iter 26/139 - loss 0.04528707\n",
      "2019-08-10 18:03:36,698 epoch 7 - iter 39/139 - loss 0.06275187\n",
      "2019-08-10 18:03:37,277 epoch 7 - iter 52/139 - loss 0.06078419\n",
      "2019-08-10 18:03:37,897 epoch 7 - iter 65/139 - loss 0.06258027\n",
      "2019-08-10 18:03:38,479 epoch 7 - iter 78/139 - loss 0.06243747\n",
      "2019-08-10 18:03:39,062 epoch 7 - iter 91/139 - loss 0.06398821\n",
      "2019-08-10 18:03:39,644 epoch 7 - iter 104/139 - loss 0.06384843\n",
      "2019-08-10 18:03:40,244 epoch 7 - iter 117/139 - loss 0.06353036\n",
      "2019-08-10 18:03:40,729 epoch 7 - iter 130/139 - loss 0.06218671\n",
      "2019-08-10 18:03:41,509 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:03:41,512 EPOCH 7 done: loss 0.0630 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 18:03:43,228 DEV : loss 0.06638286262750626 - score 0.9766\n",
      "2019-08-10 18:03:43,232 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:03:44,762 epoch 8 - iter 0/139 - loss 0.01946430\n",
      "2019-08-10 18:03:45,435 epoch 8 - iter 13/139 - loss 0.07320250\n",
      "2019-08-10 18:03:46,053 epoch 8 - iter 26/139 - loss 0.06892315\n",
      "2019-08-10 18:03:46,682 epoch 8 - iter 39/139 - loss 0.07811747\n",
      "2019-08-10 18:03:47,277 epoch 8 - iter 52/139 - loss 0.07325076\n",
      "2019-08-10 18:03:49,766 epoch 8 - iter 65/139 - loss 0.07103468\n",
      "2019-08-10 18:03:50,325 epoch 8 - iter 78/139 - loss 0.07256211\n",
      "2019-08-10 18:03:50,907 epoch 8 - iter 91/139 - loss 0.07084286\n",
      "2019-08-10 18:03:51,514 epoch 8 - iter 104/139 - loss 0.07008609\n",
      "2019-08-10 18:03:52,084 epoch 8 - iter 117/139 - loss 0.06687379\n",
      "2019-08-10 18:03:52,594 epoch 8 - iter 130/139 - loss 0.06637466\n",
      "2019-08-10 18:03:53,384 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:03:53,387 EPOCH 8 done: loss 0.0634 - lr 0.1000 - bad epochs 2\n",
      "2019-08-10 18:03:55,133 DEV : loss 0.06359544396400452 - score 0.9784\n",
      "2019-08-10 18:03:55,137 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:03:56,765 epoch 9 - iter 0/139 - loss 0.05910534\n",
      "2019-08-10 18:03:57,412 epoch 9 - iter 13/139 - loss 0.04854556\n",
      "2019-08-10 18:03:58,004 epoch 9 - iter 26/139 - loss 0.05280723\n",
      "2019-08-10 18:03:58,601 epoch 9 - iter 39/139 - loss 0.05717067\n",
      "2019-08-10 18:03:59,213 epoch 9 - iter 52/139 - loss 0.06616388\n",
      "2019-08-10 18:03:59,812 epoch 9 - iter 65/139 - loss 0.06457747\n",
      "2019-08-10 18:04:00,412 epoch 9 - iter 78/139 - loss 0.05833368\n",
      "2019-08-10 18:04:01,045 epoch 9 - iter 91/139 - loss 0.06461915\n",
      "2019-08-10 18:04:01,597 epoch 9 - iter 104/139 - loss 0.06176182\n",
      "2019-08-10 18:04:02,201 epoch 9 - iter 117/139 - loss 0.06082012\n",
      "2019-08-10 18:04:02,690 epoch 9 - iter 130/139 - loss 0.05704807\n",
      "2019-08-10 18:04:03,449 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:04:03,452 EPOCH 9 done: loss 0.0562 - lr 0.1000 - bad epochs 0\n",
      "2019-08-10 18:04:05,178 DEV : loss 0.06554314494132996 - score 0.9784\n",
      "2019-08-10 18:04:05,183 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:04:06,748 epoch 10 - iter 0/139 - loss 0.02528857\n",
      "2019-08-10 18:04:09,336 epoch 10 - iter 13/139 - loss 0.02137493\n",
      "2019-08-10 18:04:09,930 epoch 10 - iter 26/139 - loss 0.02358514\n",
      "2019-08-10 18:04:10,493 epoch 10 - iter 39/139 - loss 0.03768430\n",
      "2019-08-10 18:04:11,093 epoch 10 - iter 52/139 - loss 0.03951835\n",
      "2019-08-10 18:04:11,638 epoch 10 - iter 65/139 - loss 0.04672702\n",
      "2019-08-10 18:04:12,244 epoch 10 - iter 78/139 - loss 0.05800645\n",
      "2019-08-10 18:04:12,801 epoch 10 - iter 91/139 - loss 0.05533668\n",
      "2019-08-10 18:04:13,411 epoch 10 - iter 104/139 - loss 0.05999587\n",
      "2019-08-10 18:04:13,970 epoch 10 - iter 117/139 - loss 0.05855170\n",
      "2019-08-10 18:04:14,462 epoch 10 - iter 130/139 - loss 0.05834155\n",
      "2019-08-10 18:04:15,245 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:04:15,248 EPOCH 10 done: loss 0.0579 - lr 0.1000 - bad epochs 1\n",
      "2019-08-10 18:04:16,992 DEV : loss 0.060060977935791016 - score 0.9784\n",
      "2019-08-10 18:04:16,996 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:04:16,998 Testing using best model ...\n",
      "2019-08-10 18:04:18,753 0.973\t0.973\t0.973\n",
      "2019-08-10 18:04:18,760 \n",
      "MICRO_AVG: acc 0.9474 - f1-score 0.973\n",
      "MACRO_AVG: acc 0.8973 - f1-score 0.94435\n",
      "ham        tp: 469 - fp: 5 - fn: 10 - tn: 71 - precision: 0.9895 - recall: 0.9791 - accuracy: 0.9690 - f1-score: 0.9843\n",
      "spam       tp: 71 - fp: 10 - fn: 5 - tn: 469 - precision: 0.8765 - recall: 0.9342 - accuracy: 0.8256 - f1-score: 0.9044\n",
      "2019-08-10 18:04:18,762 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:04:18,766 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:04:18,768 Done evaluating parameter combination:\n",
      "2019-08-10 18:04:18,770 \tdropout: 0.13652012820627824\n",
      "2019-08-10 18:04:18,773 \tembeddings: /tmp/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-08-10 18:04:18,775 \thidden_size: 256\n",
      "2019-08-10 18:04:18,780 \tlearning_rate: 0.1\n",
      "2019-08-10 18:04:18,782 \tmini_batch_size: 32\n",
      "2019-08-10 18:04:18,785 \trnn_layers: 1\n",
      "2019-08-10 18:04:18,788 score: 0.02921111111111109\n",
      "2019-08-10 18:04:18,791 variance: 0.00014942740740740733\n",
      "2019-08-10 18:04:18,795 test_score: 0.973\n",
      "\n",
      "2019-08-10 18:04:18,797 ----------------------------------------------------------------------------------------------------\n",
      " 90%|█████████ | 9/10 [2:01:57<08:47, 527.32s/it, best loss: 0.011799999999999996]2019-08-10 18:04:18,807 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:04:18,811 Evaluation run: 10\n",
      "2019-08-10 18:04:18,814 Evaluating parameter combination:\n",
      "2019-08-10 18:04:18,817 \tdropout: 0.29794656826671373\n",
      "2019-08-10 18:04:18,820 \tembeddings: /tmp/.flair/embeddings/news-forward-0.4.1.pt,/tmp/.flair/embeddings/news-backward-0.4.1.pt\n",
      "2019-08-10 18:04:18,823 \thidden_size: 64\n",
      "2019-08-10 18:04:18,826 \tlearning_rate: 0.15\n",
      "2019-08-10 18:04:18,829 \tmini_batch_size: 32\n",
      "2019-08-10 18:04:18,831 \trnn_layers: 1\n",
      "2019-08-10 18:04:18,834 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:04:21,516 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:04:21,518 Training run: 1\n",
      "2019-08-10 18:04:21,798 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:04:21,801 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 18:04:22,799 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:04:24,450 epoch 1 - iter 0/139 - loss 0.69343299\n",
      "2019-08-10 18:04:27,217 epoch 1 - iter 13/139 - loss 0.31061782\n",
      "2019-08-10 18:04:30,025 epoch 1 - iter 26/139 - loss 0.20394989\n",
      "2019-08-10 18:04:32,793 epoch 1 - iter 39/139 - loss 0.17080806\n",
      "2019-08-10 18:04:35,590 epoch 1 - iter 52/139 - loss 0.14174682\n",
      "2019-08-10 18:04:38,392 epoch 1 - iter 65/139 - loss 0.12647422\n",
      "2019-08-10 18:04:42,983 epoch 1 - iter 78/139 - loss 0.11241826\n",
      "2019-08-10 18:04:45,688 epoch 1 - iter 91/139 - loss 0.10593961\n",
      "2019-08-10 18:04:48,419 epoch 1 - iter 104/139 - loss 0.09948868\n",
      "2019-08-10 18:04:51,062 epoch 1 - iter 117/139 - loss 0.09559405\n",
      "2019-08-10 18:04:53,600 epoch 1 - iter 130/139 - loss 0.09015994\n",
      "2019-08-10 18:04:55,749 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:04:55,752 EPOCH 1 done: loss 0.0922 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:05:00,466 DEV : loss 0.2997938096523285 - score 0.9117\n",
      "2019-08-10 18:05:00,470 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:05:02,232 epoch 2 - iter 0/139 - loss 0.16373932\n",
      "2019-08-10 18:05:05,146 epoch 2 - iter 13/139 - loss 0.05329285\n",
      "2019-08-10 18:05:07,941 epoch 2 - iter 26/139 - loss 0.04554641\n",
      "2019-08-10 18:05:10,705 epoch 2 - iter 39/139 - loss 0.05531348\n",
      "2019-08-10 18:05:13,601 epoch 2 - iter 52/139 - loss 0.04628861\n",
      "2019-08-10 18:05:16,304 epoch 2 - iter 65/139 - loss 0.04712722\n",
      "2019-08-10 18:05:19,142 epoch 2 - iter 78/139 - loss 0.05310369\n",
      "2019-08-10 18:05:21,874 epoch 2 - iter 91/139 - loss 0.05280963\n",
      "2019-08-10 18:05:24,672 epoch 2 - iter 104/139 - loss 0.05159922\n",
      "2019-08-10 18:05:27,347 epoch 2 - iter 117/139 - loss 0.05071689\n",
      "2019-08-10 18:05:32,245 epoch 2 - iter 130/139 - loss 0.04905311\n",
      "2019-08-10 18:05:34,476 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:05:34,481 EPOCH 2 done: loss 0.0467 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:05:39,069 DEV : loss 0.06453758478164673 - score 0.9766\n",
      "2019-08-10 18:05:39,073 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:05:40,810 epoch 3 - iter 0/139 - loss 0.03108839\n",
      "2019-08-10 18:05:43,736 epoch 3 - iter 13/139 - loss 0.03524755\n",
      "2019-08-10 18:05:46,637 epoch 3 - iter 26/139 - loss 0.03485232\n",
      "2019-08-10 18:05:49,331 epoch 3 - iter 39/139 - loss 0.03206096\n",
      "2019-08-10 18:05:52,107 epoch 3 - iter 52/139 - loss 0.03214925\n",
      "2019-08-10 18:05:54,864 epoch 3 - iter 65/139 - loss 0.03459741\n",
      "2019-08-10 18:05:57,554 epoch 3 - iter 78/139 - loss 0.03947539\n",
      "2019-08-10 18:06:00,305 epoch 3 - iter 91/139 - loss 0.03807857\n",
      "2019-08-10 18:06:03,090 epoch 3 - iter 104/139 - loss 0.03622916\n",
      "2019-08-10 18:06:05,912 epoch 3 - iter 117/139 - loss 0.03446668\n",
      "2019-08-10 18:06:08,547 epoch 3 - iter 130/139 - loss 0.03316469\n",
      "2019-08-10 18:06:10,796 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:06:10,799 EPOCH 3 done: loss 0.0359 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:06:15,488 DEV : loss 0.31055957078933716 - score 0.8847\n",
      "2019-08-10 18:06:15,492 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:06:17,139 epoch 4 - iter 0/139 - loss 0.20992382\n",
      "2019-08-10 18:06:19,967 epoch 4 - iter 13/139 - loss 0.05678059\n",
      "2019-08-10 18:06:25,427 epoch 4 - iter 26/139 - loss 0.03948060\n",
      "2019-08-10 18:06:28,024 epoch 4 - iter 39/139 - loss 0.03144019\n",
      "2019-08-10 18:06:30,807 epoch 4 - iter 52/139 - loss 0.03055363\n",
      "2019-08-10 18:06:33,354 epoch 4 - iter 65/139 - loss 0.02970685\n",
      "2019-08-10 18:06:36,061 epoch 4 - iter 78/139 - loss 0.02975774\n",
      "2019-08-10 18:06:38,722 epoch 4 - iter 91/139 - loss 0.02967826\n",
      "2019-08-10 18:06:41,460 epoch 4 - iter 104/139 - loss 0.03115515\n",
      "2019-08-10 18:06:44,134 epoch 4 - iter 117/139 - loss 0.03227827\n",
      "2019-08-10 18:06:46,824 epoch 4 - iter 130/139 - loss 0.03095235\n",
      "2019-08-10 18:06:49,084 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:06:49,087 EPOCH 4 done: loss 0.0306 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 18:06:53,740 DEV : loss 0.058697838336229324 - score 0.9802\n",
      "2019-08-10 18:06:53,745 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:06:55,514 epoch 5 - iter 0/139 - loss 0.05458697\n",
      "2019-08-10 18:06:58,334 epoch 5 - iter 13/139 - loss 0.03656150\n",
      "2019-08-10 18:07:01,054 epoch 5 - iter 26/139 - loss 0.03382005\n",
      "2019-08-10 18:07:03,866 epoch 5 - iter 39/139 - loss 0.02959430\n",
      "2019-08-10 18:07:06,631 epoch 5 - iter 52/139 - loss 0.02498616\n",
      "2019-08-10 18:07:09,362 epoch 5 - iter 65/139 - loss 0.02691182\n",
      "2019-08-10 18:07:14,720 epoch 5 - iter 78/139 - loss 0.02503532\n",
      "2019-08-10 18:07:17,264 epoch 5 - iter 91/139 - loss 0.02235407\n",
      "2019-08-10 18:07:19,889 epoch 5 - iter 104/139 - loss 0.02349416\n",
      "2019-08-10 18:07:22,663 epoch 5 - iter 117/139 - loss 0.02324268\n",
      "2019-08-10 18:07:25,304 epoch 5 - iter 130/139 - loss 0.02435388\n",
      "2019-08-10 18:07:27,470 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:07:27,473 EPOCH 5 done: loss 0.0235 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:07:32,165 DEV : loss 0.039616696536540985 - score 0.9856\n",
      "2019-08-10 18:07:32,169 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:07:34,037 epoch 6 - iter 0/139 - loss 0.01561392\n",
      "2019-08-10 18:07:36,937 epoch 6 - iter 13/139 - loss 0.00842720\n",
      "2019-08-10 18:07:39,810 epoch 6 - iter 26/139 - loss 0.02571065\n",
      "2019-08-10 18:07:42,560 epoch 6 - iter 39/139 - loss 0.02110181\n",
      "2019-08-10 18:07:45,495 epoch 6 - iter 52/139 - loss 0.01963525\n",
      "2019-08-10 18:07:48,360 epoch 6 - iter 65/139 - loss 0.01835390\n",
      "2019-08-10 18:07:51,156 epoch 6 - iter 78/139 - loss 0.01916409\n",
      "2019-08-10 18:07:53,706 epoch 6 - iter 91/139 - loss 0.01789948\n",
      "2019-08-10 18:07:56,546 epoch 6 - iter 104/139 - loss 0.01837087\n",
      "2019-08-10 18:07:59,267 epoch 6 - iter 117/139 - loss 0.01766819\n",
      "2019-08-10 18:08:01,978 epoch 6 - iter 130/139 - loss 0.01622402\n",
      "2019-08-10 18:08:04,143 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:08:04,148 EPOCH 6 done: loss 0.0161 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:08:19,653 DEV : loss 0.0857168585062027 - score 0.9784\n",
      "2019-08-10 18:08:19,658 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:08:21,433 epoch 7 - iter 0/139 - loss 0.00322089\n",
      "2019-08-10 18:08:24,238 epoch 7 - iter 13/139 - loss 0.01154928\n",
      "2019-08-10 18:08:26,858 epoch 7 - iter 26/139 - loss 0.01101349\n",
      "2019-08-10 18:08:29,650 epoch 7 - iter 39/139 - loss 0.01765225\n",
      "2019-08-10 18:08:32,423 epoch 7 - iter 52/139 - loss 0.01419222\n",
      "2019-08-10 18:08:35,165 epoch 7 - iter 65/139 - loss 0.01569171\n",
      "2019-08-10 18:08:38,146 epoch 7 - iter 78/139 - loss 0.01516103\n",
      "2019-08-10 18:08:40,932 epoch 7 - iter 91/139 - loss 0.01438800\n",
      "2019-08-10 18:08:43,737 epoch 7 - iter 104/139 - loss 0.01532478\n",
      "2019-08-10 18:08:46,567 epoch 7 - iter 117/139 - loss 0.01408927\n",
      "2019-08-10 18:08:49,241 epoch 7 - iter 130/139 - loss 0.01586886\n",
      "2019-08-10 18:08:51,406 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:08:51,409 EPOCH 7 done: loss 0.0153 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 18:08:56,094 DEV : loss 0.056658852845430374 - score 0.982\n",
      "2019-08-10 18:08:56,098 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:08:57,784 epoch 8 - iter 0/139 - loss 0.01000212\n",
      "2019-08-10 18:09:00,676 epoch 8 - iter 13/139 - loss 0.00680092\n",
      "2019-08-10 18:09:03,406 epoch 8 - iter 26/139 - loss 0.00514620\n",
      "2019-08-10 18:09:08,735 epoch 8 - iter 39/139 - loss 0.00788440\n",
      "2019-08-10 18:09:11,498 epoch 8 - iter 52/139 - loss 0.00727312\n",
      "2019-08-10 18:09:14,172 epoch 8 - iter 65/139 - loss 0.00911049\n",
      "2019-08-10 18:09:17,036 epoch 8 - iter 78/139 - loss 0.00893393\n",
      "2019-08-10 18:09:19,836 epoch 8 - iter 91/139 - loss 0.01055826\n",
      "2019-08-10 18:09:22,417 epoch 8 - iter 104/139 - loss 0.01046911\n",
      "2019-08-10 18:09:24,971 epoch 8 - iter 117/139 - loss 0.01025772\n",
      "2019-08-10 18:09:27,502 epoch 8 - iter 130/139 - loss 0.01020855\n",
      "2019-08-10 18:09:29,680 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:09:29,683 EPOCH 8 done: loss 0.0099 - lr 0.1500 - bad epochs 2\n",
      "2019-08-10 18:09:34,381 DEV : loss 0.040788184851408005 - score 0.9874\n",
      "2019-08-10 18:09:34,385 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:09:36,146 epoch 9 - iter 0/139 - loss 0.00180660\n",
      "2019-08-10 18:09:38,898 epoch 9 - iter 13/139 - loss 0.00515205\n",
      "2019-08-10 18:09:41,840 epoch 9 - iter 26/139 - loss 0.01996162\n",
      "2019-08-10 18:09:44,641 epoch 9 - iter 39/139 - loss 0.01566317\n",
      "2019-08-10 18:09:47,410 epoch 9 - iter 52/139 - loss 0.01318835\n",
      "2019-08-10 18:09:50,220 epoch 9 - iter 65/139 - loss 0.01099642\n",
      "2019-08-10 18:09:52,982 epoch 9 - iter 78/139 - loss 0.00950668\n",
      "2019-08-10 18:09:55,706 epoch 9 - iter 91/139 - loss 0.00939909\n",
      "2019-08-10 18:10:00,806 epoch 9 - iter 104/139 - loss 0.00912673\n",
      "2019-08-10 18:10:03,463 epoch 9 - iter 117/139 - loss 0.00839773\n",
      "2019-08-10 18:10:06,128 epoch 9 - iter 130/139 - loss 0.00837157\n",
      "2019-08-10 18:10:08,397 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:10:08,402 EPOCH 9 done: loss 0.0082 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:10:13,006 DEV : loss 0.04741920903325081 - score 0.9874\n",
      "2019-08-10 18:10:13,010 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:10:14,770 epoch 10 - iter 0/139 - loss 0.00047491\n",
      "2019-08-10 18:10:17,561 epoch 10 - iter 13/139 - loss 0.00566115\n",
      "2019-08-10 18:10:20,312 epoch 10 - iter 26/139 - loss 0.00357839\n",
      "2019-08-10 18:10:23,040 epoch 10 - iter 39/139 - loss 0.00713041\n",
      "2019-08-10 18:10:26,004 epoch 10 - iter 52/139 - loss 0.00637253\n",
      "2019-08-10 18:10:28,771 epoch 10 - iter 65/139 - loss 0.00657631\n",
      "2019-08-10 18:10:31,582 epoch 10 - iter 78/139 - loss 0.00593737\n",
      "2019-08-10 18:10:34,444 epoch 10 - iter 91/139 - loss 0.00526652\n",
      "2019-08-10 18:10:37,227 epoch 10 - iter 104/139 - loss 0.00512998\n",
      "2019-08-10 18:10:40,065 epoch 10 - iter 117/139 - loss 0.00498914\n",
      "2019-08-10 18:10:42,838 epoch 10 - iter 130/139 - loss 0.00523281\n",
      "2019-08-10 18:10:45,076 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:10:45,079 EPOCH 10 done: loss 0.0052 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 18:10:52,623 DEV : loss 0.0382956899702549 - score 0.9874\n",
      "2019-08-10 18:10:52,626 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:10:52,629 Testing using best model ...\n",
      "2019-08-10 18:10:57,363 0.9892\t0.9892\t0.9892\n",
      "2019-08-10 18:10:57,367 \n",
      "MICRO_AVG: acc 0.9786 - f1-score 0.9892\n",
      "MACRO_AVG: acc 0.9559 - f1-score 0.9771000000000001\n",
      "ham        tp: 476 - fp: 3 - fn: 3 - tn: 73 - precision: 0.9937 - recall: 0.9937 - accuracy: 0.9876 - f1-score: 0.9937\n",
      "spam       tp: 73 - fp: 3 - fn: 3 - tn: 476 - precision: 0.9605 - recall: 0.9605 - accuracy: 0.9241 - f1-score: 0.9605\n",
      "2019-08-10 18:10:57,369 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:10:57,373 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:10:57,376 Training run: 2\n",
      "2019-08-10 18:10:57,691 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:10:57,694 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 18:10:58,718 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:11:00,464 epoch 1 - iter 0/139 - loss 0.61432832\n",
      "2019-08-10 18:11:03,307 epoch 1 - iter 13/139 - loss 0.27388571\n",
      "2019-08-10 18:11:06,002 epoch 1 - iter 26/139 - loss 0.17767214\n",
      "2019-08-10 18:11:08,812 epoch 1 - iter 39/139 - loss 0.14987133\n",
      "2019-08-10 18:11:11,589 epoch 1 - iter 52/139 - loss 0.12608337\n",
      "2019-08-10 18:11:14,458 epoch 1 - iter 65/139 - loss 0.11366523\n",
      "2019-08-10 18:11:17,154 epoch 1 - iter 78/139 - loss 0.10327858\n",
      "2019-08-10 18:11:19,962 epoch 1 - iter 91/139 - loss 0.10578577\n",
      "2019-08-10 18:11:22,735 epoch 1 - iter 104/139 - loss 0.10002204\n",
      "2019-08-10 18:11:25,475 epoch 1 - iter 117/139 - loss 0.09369993\n",
      "2019-08-10 18:11:28,375 epoch 1 - iter 130/139 - loss 0.09224216\n",
      "2019-08-10 18:11:30,488 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:11:30,491 EPOCH 1 done: loss 0.0882 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:11:35,203 DEV : loss 0.06279744952917099 - score 0.9748\n",
      "2019-08-10 18:11:35,207 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:11:37,034 epoch 2 - iter 0/139 - loss 0.01091815\n",
      "2019-08-10 18:11:39,962 epoch 2 - iter 13/139 - loss 0.05662388\n",
      "2019-08-10 18:11:45,480 epoch 2 - iter 26/139 - loss 0.05725535\n",
      "2019-08-10 18:11:48,178 epoch 2 - iter 39/139 - loss 0.04972864\n",
      "2019-08-10 18:11:50,848 epoch 2 - iter 52/139 - loss 0.04382285\n",
      "2019-08-10 18:11:53,584 epoch 2 - iter 65/139 - loss 0.04560388\n",
      "2019-08-10 18:11:56,204 epoch 2 - iter 78/139 - loss 0.04844693\n",
      "2019-08-10 18:11:58,960 epoch 2 - iter 91/139 - loss 0.04564844\n",
      "2019-08-10 18:12:01,604 epoch 2 - iter 104/139 - loss 0.04470291\n",
      "2019-08-10 18:12:04,380 epoch 2 - iter 117/139 - loss 0.04775332\n",
      "2019-08-10 18:12:06,985 epoch 2 - iter 130/139 - loss 0.04692719\n",
      "2019-08-10 18:12:09,192 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:12:09,197 EPOCH 2 done: loss 0.0451 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:12:13,838 DEV : loss 0.06725005805492401 - score 0.9802\n",
      "2019-08-10 18:12:13,847 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:12:15,681 epoch 3 - iter 0/139 - loss 0.00288891\n",
      "2019-08-10 18:12:18,593 epoch 3 - iter 13/139 - loss 0.03669803\n",
      "2019-08-10 18:12:21,360 epoch 3 - iter 26/139 - loss 0.02664243\n",
      "2019-08-10 18:12:24,241 epoch 3 - iter 39/139 - loss 0.03110204\n",
      "2019-08-10 18:12:27,029 epoch 3 - iter 52/139 - loss 0.02951710\n",
      "2019-08-10 18:12:29,758 epoch 3 - iter 65/139 - loss 0.02728151\n",
      "2019-08-10 18:12:32,525 epoch 3 - iter 78/139 - loss 0.02765491\n",
      "2019-08-10 18:12:37,792 epoch 3 - iter 91/139 - loss 0.03213019\n",
      "2019-08-10 18:12:40,364 epoch 3 - iter 104/139 - loss 0.03054126\n",
      "2019-08-10 18:12:43,106 epoch 3 - iter 117/139 - loss 0.02954641\n",
      "2019-08-10 18:12:45,699 epoch 3 - iter 130/139 - loss 0.03078337\n",
      "2019-08-10 18:12:47,913 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:12:47,916 EPOCH 3 done: loss 0.0322 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:12:52,573 DEV : loss 0.049199748784303665 - score 0.9838\n",
      "2019-08-10 18:12:52,577 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:12:54,352 epoch 4 - iter 0/139 - loss 0.00420224\n",
      "2019-08-10 18:12:57,142 epoch 4 - iter 13/139 - loss 0.03232347\n",
      "2019-08-10 18:13:00,017 epoch 4 - iter 26/139 - loss 0.02917664\n",
      "2019-08-10 18:13:02,766 epoch 4 - iter 39/139 - loss 0.02511013\n",
      "2019-08-10 18:13:05,548 epoch 4 - iter 52/139 - loss 0.02619906\n",
      "2019-08-10 18:13:08,664 epoch 4 - iter 65/139 - loss 0.02648717\n",
      "2019-08-10 18:13:11,610 epoch 4 - iter 78/139 - loss 0.03165902\n",
      "2019-08-10 18:13:14,299 epoch 4 - iter 91/139 - loss 0.02917113\n",
      "2019-08-10 18:13:17,078 epoch 4 - iter 104/139 - loss 0.02857071\n",
      "2019-08-10 18:13:19,910 epoch 4 - iter 117/139 - loss 0.02848520\n",
      "2019-08-10 18:13:22,644 epoch 4 - iter 130/139 - loss 0.02676049\n",
      "2019-08-10 18:13:27,043 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:13:27,046 EPOCH 4 done: loss 0.0272 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:13:31,687 DEV : loss 0.06278833001852036 - score 0.982\n",
      "2019-08-10 18:13:31,691 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:13:33,478 epoch 5 - iter 0/139 - loss 0.02671504\n",
      "2019-08-10 18:13:36,320 epoch 5 - iter 13/139 - loss 0.01424707\n",
      "2019-08-10 18:13:39,066 epoch 5 - iter 26/139 - loss 0.02547861\n",
      "2019-08-10 18:13:41,776 epoch 5 - iter 39/139 - loss 0.01987593\n",
      "2019-08-10 18:13:44,695 epoch 5 - iter 52/139 - loss 0.02577124\n",
      "2019-08-10 18:13:47,563 epoch 5 - iter 65/139 - loss 0.02681885\n",
      "2019-08-10 18:13:50,340 epoch 5 - iter 78/139 - loss 0.02322636\n",
      "2019-08-10 18:13:53,106 epoch 5 - iter 91/139 - loss 0.02062021\n",
      "2019-08-10 18:13:55,962 epoch 5 - iter 104/139 - loss 0.01912745\n",
      "2019-08-10 18:13:58,600 epoch 5 - iter 117/139 - loss 0.02128936\n",
      "2019-08-10 18:14:01,318 epoch 5 - iter 130/139 - loss 0.02339976\n",
      "2019-08-10 18:14:03,507 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:14:03,512 EPOCH 5 done: loss 0.0233 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 18:14:08,195 DEV : loss 0.0804758369922638 - score 0.9766\n",
      "2019-08-10 18:14:08,199 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:14:09,959 epoch 6 - iter 0/139 - loss 0.00614759\n",
      "2019-08-10 18:14:12,793 epoch 6 - iter 13/139 - loss 0.01457849\n",
      "2019-08-10 18:14:15,486 epoch 6 - iter 26/139 - loss 0.01230586\n",
      "2019-08-10 18:14:21,060 epoch 6 - iter 39/139 - loss 0.01850610\n",
      "2019-08-10 18:14:23,760 epoch 6 - iter 52/139 - loss 0.02154502\n",
      "2019-08-10 18:14:26,365 epoch 6 - iter 65/139 - loss 0.01879423\n",
      "2019-08-10 18:14:29,094 epoch 6 - iter 78/139 - loss 0.01975878\n",
      "2019-08-10 18:14:31,728 epoch 6 - iter 91/139 - loss 0.01973656\n",
      "2019-08-10 18:14:34,521 epoch 6 - iter 104/139 - loss 0.01878228\n",
      "2019-08-10 18:14:37,228 epoch 6 - iter 117/139 - loss 0.01768944\n",
      "2019-08-10 18:14:39,898 epoch 6 - iter 130/139 - loss 0.01691218\n",
      "2019-08-10 18:14:42,049 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:14:42,053 EPOCH 6 done: loss 0.0161 - lr 0.1500 - bad epochs 2\n",
      "2019-08-10 18:14:46,742 DEV : loss 0.05012309551239014 - score 0.9892\n",
      "2019-08-10 18:14:46,746 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:14:48,508 epoch 7 - iter 0/139 - loss 0.00043776\n",
      "2019-08-10 18:14:51,202 epoch 7 - iter 13/139 - loss 0.01330517\n",
      "2019-08-10 18:14:54,048 epoch 7 - iter 26/139 - loss 0.00880361\n",
      "2019-08-10 18:14:56,787 epoch 7 - iter 39/139 - loss 0.01244792\n",
      "2019-08-10 18:14:59,534 epoch 7 - iter 52/139 - loss 0.01126314\n",
      "2019-08-10 18:15:02,535 epoch 7 - iter 65/139 - loss 0.01266762\n",
      "2019-08-10 18:15:05,430 epoch 7 - iter 78/139 - loss 0.01264786\n",
      "2019-08-10 18:15:10,422 epoch 7 - iter 91/139 - loss 0.01412717\n",
      "2019-08-10 18:15:13,124 epoch 7 - iter 104/139 - loss 0.01440497\n",
      "2019-08-10 18:15:15,721 epoch 7 - iter 117/139 - loss 0.01502895\n",
      "2019-08-10 18:15:18,302 epoch 7 - iter 130/139 - loss 0.01387305\n",
      "2019-08-10 18:15:20,525 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:15:20,528 EPOCH 7 done: loss 0.0139 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:15:25,225 DEV : loss 0.04741694778203964 - score 0.9874\n",
      "2019-08-10 18:15:25,229 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:15:27,009 epoch 8 - iter 0/139 - loss 0.01167217\n",
      "2019-08-10 18:15:29,724 epoch 8 - iter 13/139 - loss 0.00273038\n",
      "2019-08-10 18:15:32,557 epoch 8 - iter 26/139 - loss 0.00559021\n",
      "2019-08-10 18:15:35,299 epoch 8 - iter 39/139 - loss 0.00659808\n",
      "2019-08-10 18:15:38,101 epoch 8 - iter 52/139 - loss 0.00675436\n",
      "2019-08-10 18:15:40,871 epoch 8 - iter 65/139 - loss 0.00683517\n",
      "2019-08-10 18:15:43,805 epoch 8 - iter 78/139 - loss 0.00610668\n",
      "2019-08-10 18:15:46,548 epoch 8 - iter 91/139 - loss 0.00758469\n",
      "2019-08-10 18:15:49,349 epoch 8 - iter 104/139 - loss 0.00747988\n",
      "2019-08-10 18:15:52,144 epoch 8 - iter 117/139 - loss 0.00888694\n",
      "2019-08-10 18:15:54,918 epoch 8 - iter 130/139 - loss 0.00909556\n",
      "2019-08-10 18:15:59,344 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:15:59,347 EPOCH 8 done: loss 0.0088 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 18:16:04,004 DEV : loss 0.056217484176158905 - score 0.9838\n",
      "2019-08-10 18:16:04,010 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:16:05,742 epoch 9 - iter 0/139 - loss 0.00084888\n",
      "2019-08-10 18:16:08,407 epoch 9 - iter 13/139 - loss 0.00482777\n",
      "2019-08-10 18:16:11,300 epoch 9 - iter 26/139 - loss 0.00312538\n",
      "2019-08-10 18:16:14,110 epoch 9 - iter 39/139 - loss 0.00325525\n",
      "2019-08-10 18:16:16,765 epoch 9 - iter 52/139 - loss 0.00277385\n",
      "2019-08-10 18:16:19,515 epoch 9 - iter 65/139 - loss 0.00279900\n",
      "2019-08-10 18:16:22,339 epoch 9 - iter 78/139 - loss 0.00328275\n",
      "2019-08-10 18:16:25,187 epoch 9 - iter 91/139 - loss 0.00375230\n",
      "2019-08-10 18:16:28,090 epoch 9 - iter 104/139 - loss 0.00424600\n",
      "2019-08-10 18:16:30,856 epoch 9 - iter 117/139 - loss 0.00529442\n",
      "2019-08-10 18:16:33,594 epoch 9 - iter 130/139 - loss 0.00530316\n",
      "2019-08-10 18:16:35,797 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:16:35,801 EPOCH 9 done: loss 0.0072 - lr 0.1500 - bad epochs 2\n",
      "2019-08-10 18:16:40,484 DEV : loss 0.049609847366809845 - score 0.9838\n",
      "2019-08-10 18:16:40,488 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:16:42,262 epoch 10 - iter 0/139 - loss 0.00112419\n",
      "2019-08-10 18:16:45,108 epoch 10 - iter 13/139 - loss 0.00145037\n",
      "2019-08-10 18:16:47,877 epoch 10 - iter 26/139 - loss 0.00380349\n",
      "2019-08-10 18:16:53,316 epoch 10 - iter 39/139 - loss 0.00387469\n",
      "2019-08-10 18:16:55,926 epoch 10 - iter 52/139 - loss 0.00340594\n",
      "2019-08-10 18:16:58,697 epoch 10 - iter 65/139 - loss 0.00537150\n",
      "2019-08-10 18:17:01,544 epoch 10 - iter 78/139 - loss 0.00494077\n",
      "2019-08-10 18:17:04,201 epoch 10 - iter 91/139 - loss 0.00519276\n",
      "2019-08-10 18:17:06,842 epoch 10 - iter 104/139 - loss 0.00643378\n",
      "2019-08-10 18:17:09,394 epoch 10 - iter 117/139 - loss 0.00670513\n",
      "2019-08-10 18:17:12,010 epoch 10 - iter 130/139 - loss 0.00630062\n",
      "2019-08-10 18:17:14,193 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:17:14,196 EPOCH 10 done: loss 0.0065 - lr 0.1500 - bad epochs 3\n",
      "2019-08-10 18:17:18,896 DEV : loss 0.05682116001844406 - score 0.9856\n",
      "Epoch     9: reducing learning rate of group 0 to 7.5000e-02.                     \n",
      " 90%|█████████ | 9/10 [2:14:57<08:47, 527.32s/it, best loss: 0.011799999999999996]2019-08-10 18:17:18,907 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:17:18,909 Testing using best model ...\n",
      "2019-08-10 18:17:23,625 0.991\t0.991\t0.991\n",
      "2019-08-10 18:17:23,629 \n",
      "MICRO_AVG: acc 0.9821 - f1-score 0.991\n",
      "MACRO_AVG: acc 0.962 - f1-score 0.9803999999999999\n",
      "ham        tp: 479 - fp: 5 - fn: 0 - tn: 71 - precision: 0.9897 - recall: 1.0000 - accuracy: 0.9897 - f1-score: 0.9948\n",
      "spam       tp: 71 - fp: 0 - fn: 5 - tn: 479 - precision: 1.0000 - recall: 0.9342 - accuracy: 0.9342 - f1-score: 0.9660\n",
      "2019-08-10 18:17:23,632 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:17:23,635 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:17:23,638 Training run: 3\n",
      "2019-08-10 18:17:23,945 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:17:23,951 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-10 18:17:24,938 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:17:26,608 epoch 1 - iter 0/139 - loss 0.74460399\n",
      "2019-08-10 18:17:29,462 epoch 1 - iter 13/139 - loss 0.29737339\n",
      "2019-08-10 18:17:32,205 epoch 1 - iter 26/139 - loss 0.18779219\n",
      "2019-08-10 18:17:34,915 epoch 1 - iter 39/139 - loss 0.15108442\n",
      "2019-08-10 18:17:37,757 epoch 1 - iter 52/139 - loss 0.13225299\n",
      "2019-08-10 18:17:40,485 epoch 1 - iter 65/139 - loss 0.11918083\n",
      "2019-08-10 18:17:45,720 epoch 1 - iter 78/139 - loss 0.11009967\n",
      "2019-08-10 18:17:48,394 epoch 1 - iter 91/139 - loss 0.10019720\n",
      "2019-08-10 18:17:51,194 epoch 1 - iter 104/139 - loss 0.09412054\n",
      "2019-08-10 18:17:53,930 epoch 1 - iter 117/139 - loss 0.09371074\n",
      "2019-08-10 18:17:56,588 epoch 1 - iter 130/139 - loss 0.09104539\n",
      "2019-08-10 18:17:58,787 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:17:58,790 EPOCH 1 done: loss 0.0921 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:18:03,468 DEV : loss 0.05643615499138832 - score 0.9802\n",
      "2019-08-10 18:18:03,472 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:18:05,230 epoch 2 - iter 0/139 - loss 0.01072181\n",
      "2019-08-10 18:18:07,975 epoch 2 - iter 13/139 - loss 0.02605087\n",
      "2019-08-10 18:18:10,899 epoch 2 - iter 26/139 - loss 0.04348533\n",
      "2019-08-10 18:18:13,923 epoch 2 - iter 39/139 - loss 0.04107968\n",
      "2019-08-10 18:18:16,630 epoch 2 - iter 52/139 - loss 0.04234040\n",
      "2019-08-10 18:18:19,394 epoch 2 - iter 65/139 - loss 0.04417401\n",
      "2019-08-10 18:18:22,195 epoch 2 - iter 78/139 - loss 0.04280134\n",
      "2019-08-10 18:18:24,989 epoch 2 - iter 91/139 - loss 0.04506005\n",
      "2019-08-10 18:18:27,779 epoch 2 - iter 104/139 - loss 0.04624372\n",
      "2019-08-10 18:18:30,550 epoch 2 - iter 117/139 - loss 0.04612237\n",
      "2019-08-10 18:18:35,542 epoch 2 - iter 130/139 - loss 0.04418256\n",
      "2019-08-10 18:18:37,884 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:18:37,888 EPOCH 2 done: loss 0.0434 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:18:42,627 DEV : loss 0.051048990339040756 - score 0.9784\n",
      "2019-08-10 18:18:42,631 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:18:44,321 epoch 3 - iter 0/139 - loss 0.01282567\n",
      "2019-08-10 18:18:47,261 epoch 3 - iter 13/139 - loss 0.02777253\n",
      "2019-08-10 18:18:50,057 epoch 3 - iter 26/139 - loss 0.03818632\n",
      "2019-08-10 18:18:52,795 epoch 3 - iter 39/139 - loss 0.03839289\n",
      "2019-08-10 18:18:55,623 epoch 3 - iter 52/139 - loss 0.04063563\n",
      "2019-08-10 18:18:58,396 epoch 3 - iter 65/139 - loss 0.03982226\n",
      "2019-08-10 18:19:01,162 epoch 3 - iter 78/139 - loss 0.03649115\n",
      "2019-08-10 18:19:03,986 epoch 3 - iter 91/139 - loss 0.03306254\n",
      "2019-08-10 18:19:06,823 epoch 3 - iter 104/139 - loss 0.03565312\n",
      "2019-08-10 18:19:09,525 epoch 3 - iter 117/139 - loss 0.03470284\n",
      "2019-08-10 18:19:12,322 epoch 3 - iter 130/139 - loss 0.03414050\n",
      "2019-08-10 18:19:14,510 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:19:14,513 EPOCH 3 done: loss 0.0342 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 18:19:19,229 DEV : loss 0.04493643343448639 - score 0.9856\n",
      "2019-08-10 18:19:19,234 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:19:21,026 epoch 4 - iter 0/139 - loss 0.14421102\n",
      "2019-08-10 18:19:26,621 epoch 4 - iter 13/139 - loss 0.05033257\n",
      "2019-08-10 18:19:29,298 epoch 4 - iter 26/139 - loss 0.03320907\n",
      "2019-08-10 18:19:31,763 epoch 4 - iter 39/139 - loss 0.02819564\n",
      "2019-08-10 18:19:34,463 epoch 4 - iter 52/139 - loss 0.03152527\n",
      "2019-08-10 18:19:37,188 epoch 4 - iter 65/139 - loss 0.02809108\n",
      "2019-08-10 18:19:39,997 epoch 4 - iter 78/139 - loss 0.02998591\n",
      "2019-08-10 18:19:42,677 epoch 4 - iter 91/139 - loss 0.02852270\n",
      "2019-08-10 18:19:45,384 epoch 4 - iter 104/139 - loss 0.03039239\n",
      "2019-08-10 18:19:48,159 epoch 4 - iter 117/139 - loss 0.03166579\n",
      "2019-08-10 18:19:50,900 epoch 4 - iter 130/139 - loss 0.02922482\n",
      "2019-08-10 18:19:53,098 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:19:53,101 EPOCH 4 done: loss 0.0279 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:19:57,741 DEV : loss 0.049069736152887344 - score 0.9874\n",
      "2019-08-10 18:19:57,746 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:19:59,461 epoch 5 - iter 0/139 - loss 0.00320809\n",
      "2019-08-10 18:20:02,298 epoch 5 - iter 13/139 - loss 0.02319680\n",
      "2019-08-10 18:20:05,032 epoch 5 - iter 26/139 - loss 0.02925519\n",
      "2019-08-10 18:20:07,752 epoch 5 - iter 39/139 - loss 0.02724168\n",
      "2019-08-10 18:20:10,492 epoch 5 - iter 52/139 - loss 0.02324624\n",
      "2019-08-10 18:20:13,380 epoch 5 - iter 65/139 - loss 0.02608226\n",
      "2019-08-10 18:20:18,617 epoch 5 - iter 78/139 - loss 0.02377136\n",
      "2019-08-10 18:20:21,266 epoch 5 - iter 91/139 - loss 0.02141726\n",
      "2019-08-10 18:20:23,876 epoch 5 - iter 104/139 - loss 0.02156041\n",
      "2019-08-10 18:20:26,742 epoch 5 - iter 117/139 - loss 0.02136912\n",
      "2019-08-10 18:20:29,440 epoch 5 - iter 130/139 - loss 0.02211178\n",
      "2019-08-10 18:20:31,619 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:20:31,622 EPOCH 5 done: loss 0.0211 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:20:36,364 DEV : loss 0.0440310575067997 - score 0.9892\n",
      "2019-08-10 18:20:36,368 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:20:38,221 epoch 6 - iter 0/139 - loss 0.00288062\n",
      "2019-08-10 18:20:41,062 epoch 6 - iter 13/139 - loss 0.01528803\n",
      "2019-08-10 18:20:43,971 epoch 6 - iter 26/139 - loss 0.02254724\n",
      "2019-08-10 18:20:46,711 epoch 6 - iter 39/139 - loss 0.02416417\n",
      "2019-08-10 18:20:49,537 epoch 6 - iter 52/139 - loss 0.01999141\n",
      "2019-08-10 18:20:52,478 epoch 6 - iter 65/139 - loss 0.01700539\n",
      "2019-08-10 18:20:55,267 epoch 6 - iter 78/139 - loss 0.01520846\n",
      "2019-08-10 18:20:57,926 epoch 6 - iter 91/139 - loss 0.01690042\n",
      "2019-08-10 18:21:00,782 epoch 6 - iter 104/139 - loss 0.01712115\n",
      "2019-08-10 18:21:05,702 epoch 6 - iter 117/139 - loss 0.01588408\n",
      "2019-08-10 18:21:08,387 epoch 6 - iter 130/139 - loss 0.01469104\n",
      "2019-08-10 18:21:10,595 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:21:10,598 EPOCH 6 done: loss 0.0139 - lr 0.1500 - bad epochs 0\n",
      "2019-08-10 18:21:15,238 DEV : loss 0.053457967936992645 - score 0.9856\n",
      "2019-08-10 18:21:15,242 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:21:17,059 epoch 7 - iter 0/139 - loss 0.10739389\n",
      "2019-08-10 18:21:19,897 epoch 7 - iter 13/139 - loss 0.01289975\n",
      "2019-08-10 18:21:22,847 epoch 7 - iter 26/139 - loss 0.01425250\n",
      "2019-08-10 18:21:25,681 epoch 7 - iter 39/139 - loss 0.01038589\n",
      "2019-08-10 18:21:28,477 epoch 7 - iter 52/139 - loss 0.00990717\n",
      "2019-08-10 18:21:31,155 epoch 7 - iter 65/139 - loss 0.01106248\n",
      "2019-08-10 18:21:34,028 epoch 7 - iter 78/139 - loss 0.01067462\n",
      "2019-08-10 18:21:36,789 epoch 7 - iter 91/139 - loss 0.01037175\n",
      "2019-08-10 18:21:39,519 epoch 7 - iter 104/139 - loss 0.01005856\n",
      "2019-08-10 18:21:42,318 epoch 7 - iter 117/139 - loss 0.01026345\n",
      "2019-08-10 18:21:44,962 epoch 7 - iter 130/139 - loss 0.01055137\n",
      "2019-08-10 18:21:47,142 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:21:47,145 EPOCH 7 done: loss 0.0117 - lr 0.1500 - bad epochs 1\n",
      "2019-08-10 18:21:51,812 DEV : loss 0.06675975769758224 - score 0.9802\n",
      "2019-08-10 18:21:51,816 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:21:53,535 epoch 8 - iter 0/139 - loss 0.00166741\n",
      "2019-08-10 18:21:59,247 epoch 8 - iter 13/139 - loss 0.00289784\n",
      "2019-08-10 18:22:01,940 epoch 8 - iter 26/139 - loss 0.00467220\n",
      "2019-08-10 18:22:04,515 epoch 8 - iter 39/139 - loss 0.00631270\n",
      "2019-08-10 18:22:07,204 epoch 8 - iter 52/139 - loss 0.00605718\n",
      "2019-08-10 18:22:09,824 epoch 8 - iter 65/139 - loss 0.00677146\n",
      "2019-08-10 18:22:12,600 epoch 8 - iter 78/139 - loss 0.00903904\n",
      "2019-08-10 18:22:15,347 epoch 8 - iter 91/139 - loss 0.00874518\n",
      "2019-08-10 18:22:17,904 epoch 8 - iter 104/139 - loss 0.00987091\n",
      "2019-08-10 18:22:20,703 epoch 8 - iter 117/139 - loss 0.00906957\n",
      "2019-08-10 18:22:23,427 epoch 8 - iter 130/139 - loss 0.00826892\n",
      "2019-08-10 18:22:25,605 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:22:25,609 EPOCH 8 done: loss 0.0082 - lr 0.1500 - bad epochs 2\n",
      "2019-08-10 18:22:30,329 DEV : loss 0.057384464889764786 - score 0.9874\n",
      "2019-08-10 18:22:30,333 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:22:32,161 epoch 9 - iter 0/139 - loss 0.00108087\n",
      "2019-08-10 18:22:34,906 epoch 9 - iter 13/139 - loss 0.00540614\n",
      "2019-08-10 18:22:37,726 epoch 9 - iter 26/139 - loss 0.00752500\n",
      "2019-08-10 18:22:40,562 epoch 9 - iter 39/139 - loss 0.00567428\n",
      "2019-08-10 18:22:46,016 epoch 9 - iter 52/139 - loss 0.00478895\n",
      "2019-08-10 18:22:48,702 epoch 9 - iter 65/139 - loss 0.00434268\n",
      "2019-08-10 18:22:51,357 epoch 9 - iter 78/139 - loss 0.00377337\n",
      "2019-08-10 18:22:54,081 epoch 9 - iter 91/139 - loss 0.00450014\n",
      "2019-08-10 18:22:56,812 epoch 9 - iter 104/139 - loss 0.00432629\n",
      "2019-08-10 18:22:59,542 epoch 9 - iter 117/139 - loss 0.00406792\n",
      "2019-08-10 18:23:02,268 epoch 9 - iter 130/139 - loss 0.00386094\n",
      "2019-08-10 18:23:04,459 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:23:04,462 EPOCH 9 done: loss 0.0038 - lr 0.1500 - bad epochs 3\n",
      "2019-08-10 18:23:09,149 DEV : loss 0.05081697925925255 - score 0.9892\n",
      "Epoch     8: reducing learning rate of group 0 to 7.5000e-02.                     \n",
      " 90%|█████████ | 9/10 [2:20:47<08:47, 527.32s/it, best loss: 0.011799999999999996]2019-08-10 18:23:09,159 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:23:10,942 epoch 10 - iter 0/139 - loss 0.00120728\n",
      "2019-08-10 18:23:13,760 epoch 10 - iter 13/139 - loss 0.00357180\n",
      "2019-08-10 18:23:16,777 epoch 10 - iter 26/139 - loss 0.00247058\n",
      "2019-08-10 18:23:19,688 epoch 10 - iter 39/139 - loss 0.00257588\n",
      "2019-08-10 18:23:22,439 epoch 10 - iter 52/139 - loss 0.00346519\n",
      "2019-08-10 18:23:25,188 epoch 10 - iter 65/139 - loss 0.00317509\n",
      "2019-08-10 18:23:27,914 epoch 10 - iter 78/139 - loss 0.00280629\n",
      "2019-08-10 18:23:30,774 epoch 10 - iter 91/139 - loss 0.00322976\n",
      "2019-08-10 18:23:35,785 epoch 10 - iter 104/139 - loss 0.00306472\n",
      "2019-08-10 18:23:38,484 epoch 10 - iter 117/139 - loss 0.00294267\n",
      "2019-08-10 18:23:41,207 epoch 10 - iter 130/139 - loss 0.00306045\n",
      "2019-08-10 18:23:43,381 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:23:43,384 EPOCH 10 done: loss 0.0029 - lr 0.0750 - bad epochs 0\n",
      "2019-08-10 18:23:48,084 DEV : loss 0.053337521851062775 - score 0.9892\n",
      "2019-08-10 18:23:48,088 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:23:48,090 Testing using best model ...\n",
      "2019-08-10 18:23:52,780 0.9892\t0.9892\t0.9892\n",
      "2019-08-10 18:23:52,784 \n",
      "MICRO_AVG: acc 0.9786 - f1-score 0.9892\n",
      "MACRO_AVG: acc 0.9554 - f1-score 0.97685\n",
      "ham        tp: 477 - fp: 4 - fn: 2 - tn: 72 - precision: 0.9917 - recall: 0.9958 - accuracy: 0.9876 - f1-score: 0.9937\n",
      "spam       tp: 72 - fp: 2 - fn: 4 - tn: 477 - precision: 0.9730 - recall: 0.9474 - accuracy: 0.9231 - f1-score: 0.9600\n",
      "2019-08-10 18:23:52,787 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:23:52,790 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:23:52,793 Done evaluating parameter combination:\n",
      "2019-08-10 18:23:52,797 \tdropout: 0.29794656826671373\n",
      "2019-08-10 18:23:52,800 \tembeddings: /tmp/.flair/embeddings/news-forward-0.4.1.pt,/tmp/.flair/embeddings/news-backward-0.4.1.pt\n",
      "2019-08-10 18:23:52,804 \thidden_size: 64\n",
      "2019-08-10 18:23:52,806 \tlearning_rate: 0.15\n",
      "2019-08-10 18:23:52,808 \tmini_batch_size: 32\n",
      "2019-08-10 18:23:52,810 \trnn_layers: 1\n",
      "2019-08-10 18:23:52,814 score: 0.013199999999999976\n",
      "2019-08-10 18:23:52,817 variance: 4.799999999999831e-07\n",
      "2019-08-10 18:23:52,819 test_score: 0.9892\n",
      "\n",
      "2019-08-10 18:23:52,822 ----------------------------------------------------------------------------------------------------\n",
      "100%|██████████| 10/10 [2:21:31<00:00, 721.33s/it, best loss: 0.011799999999999996]\n",
      "2019-08-10 18:23:52,827 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-10 18:23:52,832 Optimizing parameter configuration done.\n",
      "2019-08-10 18:23:52,836 Best parameter configuration found:\n",
      "2019-08-10 18:23:52,838 \tdropout: 0.1837011674443803\n",
      "2019-08-10 18:23:52,840 \tembeddings: 0\n",
      "2019-08-10 18:23:52,843 \thidden_size: 1\n",
      "2019-08-10 18:23:52,847 \tlearning_rate: 3\n",
      "2019-08-10 18:23:52,849 \tmini_batch_size: 0\n",
      "2019-08-10 18:23:52,854 \trnn_layers: 1\n",
      "2019-08-10 18:23:52,857 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "param_selector.optimize(search_space, max_evals=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter settings and the evaluation scores will be written to $\\textbf{param_selection.txt}$ in the result directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
