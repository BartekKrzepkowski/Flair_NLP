{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdwYLquTZKZm"
   },
   "outputs": [],
   "source": [
    "!pip3 install git+https://github.com/zalandoresearch/flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1518,
     "status": "ok",
     "timestamp": 1565539105157,
     "user": {
      "displayName": "The channel without any content",
      "photoUrl": "",
      "userId": "13639603838420141009"
     },
     "user_tz": -120
    },
    "id": "DQ1HkCWqZKZq",
    "outputId": "3b4d425c-a734-4851-d791-97a34ceca85c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZemUHqu_ZKZu"
   },
   "source": [
    "> ## Create a Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOqs9NWRZKZu"
   },
   "source": [
    "### 1) Load from simple CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "yfDgYb0NZKZv"
   },
   "outputs": [],
   "source": [
    "from flair.datasets import CSVClassificationCorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nnohvD6fZKZz"
   },
   "source": [
    "Great development.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vN5WBqWaZKZ0"
   },
   "source": [
    "### 2) FastText Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WU6TUvLZKZ1"
   },
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ClassificationCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s1zmExAdZKZ3"
   },
   "outputs": [],
   "source": [
    "FILE_PATH = \"bbc-text.csv\"\n",
    "DATASET_FOLDER_PATH = os.path.join(\"splitted_data\", FILE_PATH.split(\".\")[0])\n",
    "\n",
    "column_name = {\n",
    "    \"text\": \"text\",\n",
    "    \"label\": \"category\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KhqNCUv0ZKZ6"
   },
   "source": [
    "# file format\n",
    "__label__<label_1> <text>\n",
    "__label__<label_1> __label__<label_2> <text>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1234,
     "status": "ok",
     "timestamp": 1565539131373,
     "user": {
      "displayName": "The channel without any content",
      "photoUrl": "",
      "userId": "13639603838420141009"
     },
     "user_tz": -120
    },
    "id": "edMTTqPmZKZ7",
    "outputId": "868d2398-67c9-4a0b-8c99-141a2c0fe845"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAJOCAYAAADyEaDvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbQ19AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = pd.read_csv(FILE_PATH).sample(frac=1)\n",
    "data_df[column_name[\"label\"]] = '__label__' + data_df[column_name[\"label\"]].astype(str)\n",
    "\n",
    "# number of chars\n",
    "data_df[column_name[\"text\"]].str.len().plot(kind=\"hist\", title=\"line lenght distribution\", grid=True, figsize=(10,10), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2261,
     "status": "ok",
     "timestamp": 1565539607305,
     "user": {
      "displayName": "The channel without any content",
      "photoUrl": "",
      "userId": "13639603838420141009"
     },
     "user_tz": -120
    },
    "id": "hlyjcZDzZKZ9",
    "outputId": "f0d3f41e-b7dc-46c8-f2a8-8cf2cd3a7945"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAJOCAYAAAAOBIslAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from string import digits, punctuation\n",
    "\n",
    "def clear_text(text, is_all_lower=True):\n",
    "    punct = re.sub(r'[\\.,!?&\\-]', '', punctuation)\n",
    "    punctuation_table = str.maketrans({key: \"#\" for key in punct})\n",
    "    for char in [\"\\\"\", \"\\'\"]:\n",
    "        del punctuation_table[ord(char)]\n",
    "    \n",
    "    review_cleaned = text.apply(lambda x: re.sub(r'[^\\x00-\\x7F]', ' ', x))\n",
    "    review_cleaned = review_cleaned.apply(lambda x: re.sub(r'[0-9]', '9', x))\n",
    "    review_cleaned = review_cleaned.apply(lambda x: x.translate(punctuation_table))\n",
    "    review_cleaned = review_cleaned.apply(lambda x: re.sub(r' +', ' ', x))\n",
    "    review_cleaned = review_cleaned.apply(lambda x: re.sub(r' (?=[\\.,!?&\\-])','', x))\n",
    "    \n",
    "    if is_all_lower:\n",
    "        review_cleaned = review_cleaned.str.lower()\n",
    "        \n",
    "    return review_cleaned\n",
    "\n",
    "data_df[column_name[\"text\"]] = clear_text(data_df[\"text\"])\n",
    "data_df[column_name[\"text\"]] = data_df[column_name[\"text\"]].apply(lambda x: x[:900])\n",
    "\n",
    "# number of chars\n",
    "data_df[column_name[\"text\"]].str.len().plot(kind=\"hist\", title=\"line lenght distribution\", grid=True, figsize=(10,10), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FyIpt0SUZKaB"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DATASET_FOLDER_PATH):\n",
    "    os.makedirs(DATASET_FOLDER_PATH)\n",
    "data_df.iloc[0: int(len(data_df)*0.8)].to_csv(os.path.join(DATASET_FOLDER_PATH, 'train.csv'), sep='\\t', index = False, header = False)\n",
    "data_df.iloc[int(len(data_df)*0.8): int(len(data_df)*0.9)].to_csv(os.path.join(DATASET_FOLDER_PATH, 'dev.csv'), sep='\\t', index = False, header = False)\n",
    "data_df.iloc[int(len(data_df)*0.9): ].to_csv(os.path.join(DATASET_FOLDER_PATH, 'test.csv'), sep='\\t', index = False, header = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1565539613643,
     "user": {
      "displayName": "The channel without any content",
      "photoUrl": "",
      "userId": "13639603838420141009"
     },
     "user_tz": -120
    },
    "id": "3EZFkni-ZKaF",
    "outputId": "6a8216e8-712b-4f1f-a5ed-ac88159dfb5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-11 16:06:53,206 Reading data from splitted_data/bbc-text\n",
      "2019-08-11 16:06:53,207 Train: splitted_data/bbc-text/train.csv\n",
      "2019-08-11 16:06:53,208 Dev: splitted_data/bbc-text/dev.csv\n",
      "2019-08-11 16:06:53,209 Test: splitted_data/bbc-text/test.csv\n"
     ]
    }
   ],
   "source": [
    "corpus = ClassificationCorpus(DATASET_FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ME13aUfiZKaI"
   },
   "source": [
    "Each line in a corpus is converted to a Sentence object annotated with the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TGB6kNeNZKaJ"
   },
   "source": [
    "## Check distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1774,
     "status": "ok",
     "timestamp": 1565539624264,
     "user": {
      "displayName": "The channel without any content",
      "photoUrl": "",
      "userId": "13639603838420141009"
     },
     "user_tz": -120
    },
    "id": "dFsVqhEIZKaJ",
    "outputId": "f8ec1e48-7407-45a2-dba4-a010ca65aec3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__label__business         412\n",
       "__label__sport            411\n",
       "__label__politics         333\n",
       "__label__tech             317\n",
       "__label__entertainment    307\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATASET_FOLDER_PATH, \"train.csv\"), names=[\"label\", \"text\"], delimiter=\"\\t\")\n",
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2463,
     "status": "ok",
     "timestamp": 1565539631012,
     "user": {
      "displayName": "The channel without any content",
      "photoUrl": "",
      "userId": "13639603838420141009"
     },
     "user_tz": -120
    },
    "id": "56ToZVNTZKaN",
    "outputId": "8160af07-69bc-4bfc-83e6-b0417d28afc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__label__sport            50\n",
       "__label__business         46\n",
       "__label__tech             45\n",
       "__label__politics         42\n",
       "__label__entertainment    39\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_csv(os.path.join(DATASET_FOLDER_PATH, \"dev.csv\"), names=[\"label\", \"text\"], delimiter=\"\\t\")\n",
    "val_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1637,
     "status": "ok",
     "timestamp": 1565539628099,
     "user": {
      "displayName": "The channel without any content",
      "photoUrl": "",
      "userId": "13639603838420141009"
     },
     "user_tz": -120
    },
    "id": "0jZ3vZh3ZKaP",
    "outputId": "f6c2c6bb-1903-4426-a399-430ee97830d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__label__business         52\n",
       "__label__sport            50\n",
       "__label__politics         42\n",
       "__label__entertainment    40\n",
       "__label__tech             39\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(DATASET_FOLDER_PATH, \"test.csv\"), names=[\"label\", \"text\"], delimiter=\"\\t\")\n",
    "test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4rB7faCZKaS"
   },
   "source": [
    "## Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bMl1KQu7ZKaS"
   },
   "source": [
    "## RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i3HbWHkAZKaT"
   },
   "outputs": [],
   "source": [
    "from flair.embeddings import RoBERTaEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.training_utils import EvaluationMetric\n",
    "# from flair.visual.training_curves import Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PIrsG8uKZKaW"
   },
   "outputs": [],
   "source": [
    "MODEL_FOLDER_PATH = \"model/RoBERTa\"\n",
    "if not os.path.exists(MODEL_FOLDER_PATH):\n",
    "    os.makedirs(MODEL_FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22357,
     "status": "ok",
     "timestamp": 1565540820617,
     "user": {
      "displayName": "The channel without any content",
      "photoUrl": "",
      "userId": "13639603838420141009"
     },
     "user_tz": -120
    },
    "id": "96_LR8zbZKaZ",
    "outputId": "bd671eb5-c321-46a4-e9b0-9fd6528a5883"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_fairseq_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading archive file http://dl.fbaipublicfiles.com/fairseq/models/roberta.large.tar.gz from cache at /root/.cache/torch/pytorch_fairseq/83e3a689e28e5e4696ecb0bbb05a77355444a5c8a3437e0f736d8a564e80035e.c687083d14776c1979f3f71654febb42f2bb3d9a94ff7ebdfe1ac6748dba89d2\n",
      "| dictionary: 50264 types\n",
      "2019-08-11 16:26:51,602 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1780/1780 [00:07<00:00, 250.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-11 16:26:59,271 [b'tech', b'sport', b'business', b'entertainment', b'politics']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "params_train = {\n",
    "    \"flair_emb_forward\": 'news-forward-fast',\n",
    "    \"flair_emb_backward\": 'news-backward-fast',\n",
    "    \"hidden_size\": 256,\n",
    "    \"reproject_words_dimension\": 128,\n",
    "    \"max_epoch\": 20,\n",
    "    \"evaluation_metric\": EvaluationMetric.MICRO_ACCURACY\n",
    "}\n",
    "\n",
    "word_embeddings = [RoBERTaEmbeddings(), FlairEmbeddings(params_train[\"flair_emb_forward\"]),\n",
    "                   FlairEmbeddings(params_train[\"flair_emb_backward\"])]\n",
    "\n",
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=params_train[\"hidden_size\"],\n",
    "                                            reproject_words=True, reproject_words_dimension=params_train[\"reproject_words_dimension\"])\n",
    "\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdWQWO9aZKab"
   },
   "outputs": [],
   "source": [
    "learning_rate_tsv = trainer.find_learning_rate(MODEL_FOLDER_PATH, 'learning_rate.tsv')\n",
    "\n",
    "plotter = Plotter()\n",
    "plotter.plot_learning_rate(learning_rate_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3804532,
     "status": "ok",
     "timestamp": 1565544638782,
     "user": {
      "displayName": "The channel without any content",
      "photoUrl": "",
      "userId": "13639603838420141009"
     },
     "user_tz": -120
    },
    "id": "e-N8BQgwZKae",
    "outputId": "18729dea-d412-49dd-c786-ece4c3a03945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-11 16:27:14,430 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:27:14,434 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): RoBERTaEmbeddings(\n",
      "        (model): RobertaHubInterface(\n",
      "          (model): RobertaModel(\n",
      "            (decoder): RobertaEncoder(\n",
      "              (sentence_encoder): TransformerSentenceEncoder(\n",
      "                (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
      "                (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
      "                (layers): ModuleList(\n",
      "                  (0): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (1): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (2): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (3): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (4): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (5): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (6): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (7): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (8): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (9): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (10): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (11): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (12): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (13): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (14): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (15): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (16): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (17): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (18): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (19): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (20): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (21): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (22): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (23): TransformerSentenceEncoderLayer(\n",
      "                    (self_attn): MultiheadAttention(\n",
      "                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                    )\n",
      "                    (self_attn_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                    (final_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "                (emb_layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "              (lm_head): RobertaLMHead(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "            (classification_heads): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=3072, out_features=128, bias=True)\n",
      "    (rnn): GRU(128, 256)\n",
      "    (dropout): Dropout(p=0.5)\n",
      "  )\n",
      "  (decoder): Linear(in_features=256, out_features=5, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-08-11 16:27:14,436 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:27:14,438 Corpus: \"Corpus: 1780 train + 222 dev + 223 test sentences\"\n",
      "2019-08-11 16:27:14,439 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:27:14,440 Parameters:\n",
      "2019-08-11 16:27:14,442  - learning_rate: \"0.01\"\n",
      "2019-08-11 16:27:14,443  - mini_batch_size: \"32\"\n",
      "2019-08-11 16:27:14,444  - patience: \"3\"\n",
      "2019-08-11 16:27:14,445  - anneal_factor: \"0.5\"\n",
      "2019-08-11 16:27:14,445  - max_epochs: \"20\"\n",
      "2019-08-11 16:27:14,446  - shuffle: \"True\"\n",
      "2019-08-11 16:27:14,447  - train_with_dev: \"False\"\n",
      "2019-08-11 16:27:14,447 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:27:14,448 Model training base path: \"model/RoBERTa\"\n",
      "2019-08-11 16:27:14,449 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:27:14,450 Device: cuda:0\n",
      "2019-08-11 16:27:14,451 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:27:14,451 Embeddings storage mode: cpu\n",
      "2019-08-11 16:27:14,455 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:27:18,749 epoch 1 - iter 0/56 - loss 1.77321827 throughput (samples/sec): 49.66\n",
      "2019-08-11 16:27:33,574 epoch 1 - iter 5/56 - loss 1.75720062 throughput (samples/sec): 11.21\n",
      "2019-08-11 16:27:48,584 epoch 1 - iter 10/56 - loss 1.71206303 throughput (samples/sec): 11.20\n",
      "2019-08-11 16:28:02,589 epoch 1 - iter 15/56 - loss 1.70973114 throughput (samples/sec): 11.82\n",
      "2019-08-11 16:28:16,763 epoch 1 - iter 20/56 - loss 1.70063967 throughput (samples/sec): 11.90\n",
      "2019-08-11 16:28:30,880 epoch 1 - iter 25/56 - loss 1.70268299 throughput (samples/sec): 11.92\n",
      "2019-08-11 16:28:44,967 epoch 1 - iter 30/56 - loss 1.68680481 throughput (samples/sec): 11.97\n",
      "2019-08-11 16:28:59,255 epoch 1 - iter 35/56 - loss 1.69167219 throughput (samples/sec): 11.57\n",
      "2019-08-11 16:29:13,769 epoch 1 - iter 40/56 - loss 1.68112398 throughput (samples/sec): 11.61\n",
      "2019-08-11 16:29:27,904 epoch 1 - iter 45/56 - loss 1.67617235 throughput (samples/sec): 11.71\n",
      "2019-08-11 16:29:42,162 epoch 1 - iter 50/56 - loss 1.67018681 throughput (samples/sec): 11.81\n",
      "2019-08-11 16:29:55,262 epoch 1 - iter 55/56 - loss 1.66505609 throughput (samples/sec): 12.85\n",
      "2019-08-11 16:29:55,682 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:29:55,684 EPOCH 1 done: loss 1.6651 - lr 0.0100\n",
      "2019-08-11 16:30:16,460 DEV : loss 1.5683914422988892 - score 0.2568\n",
      "2019-08-11 16:30:18,099 BAD EPOCHS (no improvement): 0\n",
      "2019-08-11 16:30:27,719 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:30:32,243 epoch 2 - iter 0/56 - loss 1.70716763 throughput (samples/sec): 56.07\n",
      "2019-08-11 16:30:46,633 epoch 2 - iter 5/56 - loss 1.61983997 throughput (samples/sec): 11.32\n",
      "2019-08-11 16:31:01,401 epoch 2 - iter 10/56 - loss 1.60577593 throughput (samples/sec): 11.14\n",
      "2019-08-11 16:31:15,676 epoch 2 - iter 15/56 - loss 1.60484505 throughput (samples/sec): 11.44\n",
      "2019-08-11 16:31:29,975 epoch 2 - iter 20/56 - loss 1.60322815 throughput (samples/sec): 11.83\n",
      "2019-08-11 16:31:44,056 epoch 2 - iter 25/56 - loss 1.60709876 throughput (samples/sec): 11.96\n",
      "2019-08-11 16:31:58,147 epoch 2 - iter 30/56 - loss 1.59907221 throughput (samples/sec): 11.97\n",
      "2019-08-11 16:32:12,256 epoch 2 - iter 35/56 - loss 1.59240314 throughput (samples/sec): 11.72\n",
      "2019-08-11 16:32:26,838 epoch 2 - iter 40/56 - loss 1.59179767 throughput (samples/sec): 11.53\n",
      "2019-08-11 16:32:40,983 epoch 2 - iter 45/56 - loss 1.58815626 throughput (samples/sec): 11.72\n",
      "2019-08-11 16:32:55,339 epoch 2 - iter 50/56 - loss 1.58217862 throughput (samples/sec): 11.72\n",
      "2019-08-11 16:33:08,567 epoch 2 - iter 55/56 - loss 1.57937045 throughput (samples/sec): 12.73\n",
      "2019-08-11 16:33:08,984 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:33:08,985 EPOCH 2 done: loss 1.5794 - lr 0.0100\n",
      "2019-08-11 16:33:29,936 DEV : loss 1.498595952987671 - score 0.3243\n",
      "2019-08-11 16:33:31,508 BAD EPOCHS (no improvement): 0\n",
      "2019-08-11 16:33:41,307 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:33:45,896 epoch 3 - iter 0/56 - loss 1.49818122 throughput (samples/sec): 47.09\n",
      "2019-08-11 16:34:00,299 epoch 3 - iter 5/56 - loss 1.53053701 throughput (samples/sec): 11.68\n",
      "2019-08-11 16:34:14,997 epoch 3 - iter 10/56 - loss 1.51949056 throughput (samples/sec): 11.28\n",
      "2019-08-11 16:34:29,699 epoch 3 - iter 15/56 - loss 1.52510853 throughput (samples/sec): 11.43\n",
      "2019-08-11 16:34:43,679 epoch 3 - iter 20/56 - loss 1.51177308 throughput (samples/sec): 11.87\n",
      "2019-08-11 16:34:57,774 epoch 3 - iter 25/56 - loss 1.51308507 throughput (samples/sec): 11.96\n",
      "2019-08-11 16:35:12,068 epoch 3 - iter 30/56 - loss 1.51720662 throughput (samples/sec): 11.81\n",
      "2019-08-11 16:35:26,295 epoch 3 - iter 35/56 - loss 1.52130133 throughput (samples/sec): 11.82\n",
      "2019-08-11 16:35:40,591 epoch 3 - iter 40/56 - loss 1.51938649 throughput (samples/sec): 11.59\n",
      "2019-08-11 16:35:54,893 epoch 3 - iter 45/56 - loss 1.51762028 throughput (samples/sec): 11.77\n",
      "2019-08-11 16:36:08,927 epoch 3 - iter 50/56 - loss 1.51585571 throughput (samples/sec): 11.81\n",
      "2019-08-11 16:36:22,309 epoch 3 - iter 55/56 - loss 1.51456248 throughput (samples/sec): 12.57\n",
      "2019-08-11 16:36:22,716 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:36:22,721 EPOCH 3 done: loss 1.5146 - lr 0.0100\n",
      "2019-08-11 16:36:43,554 DEV : loss 1.5373889207839966 - score 0.3063\n",
      "2019-08-11 16:36:44,863 BAD EPOCHS (no improvement): 1\n",
      "2019-08-11 16:36:44,865 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:36:49,508 epoch 4 - iter 0/56 - loss 1.45296061 throughput (samples/sec): 58.05\n",
      "2019-08-11 16:37:03,840 epoch 4 - iter 5/56 - loss 1.45440992 throughput (samples/sec): 11.76\n",
      "2019-08-11 16:37:18,548 epoch 4 - iter 10/56 - loss 1.44877455 throughput (samples/sec): 11.63\n",
      "2019-08-11 16:37:32,910 epoch 4 - iter 15/56 - loss 1.44238175 throughput (samples/sec): 11.70\n",
      "2019-08-11 16:37:47,271 epoch 4 - iter 20/56 - loss 1.45758713 throughput (samples/sec): 11.92\n",
      "2019-08-11 16:38:01,292 epoch 4 - iter 25/56 - loss 1.44896368 throughput (samples/sec): 11.98\n",
      "2019-08-11 16:38:15,532 epoch 4 - iter 30/56 - loss 1.44982237 throughput (samples/sec): 12.01\n",
      "2019-08-11 16:38:29,527 epoch 4 - iter 35/56 - loss 1.45391461 throughput (samples/sec): 12.01\n",
      "2019-08-11 16:38:43,901 epoch 4 - iter 40/56 - loss 1.45172856 throughput (samples/sec): 11.71\n",
      "2019-08-11 16:38:58,376 epoch 4 - iter 45/56 - loss 1.44856674 throughput (samples/sec): 11.26\n",
      "2019-08-11 16:39:12,498 epoch 4 - iter 50/56 - loss 1.44308719 throughput (samples/sec): 11.58\n",
      "2019-08-11 16:39:25,571 epoch 4 - iter 55/56 - loss 1.44680050 throughput (samples/sec): 12.47\n",
      "2019-08-11 16:39:26,184 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:39:26,186 EPOCH 4 done: loss 1.4468 - lr 0.0100\n",
      "2019-08-11 16:39:47,051 DEV : loss 1.3848718404769897 - score 0.4099\n",
      "2019-08-11 16:39:48,362 BAD EPOCHS (no improvement): 0\n",
      "2019-08-11 16:39:57,381 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:40:01,871 epoch 5 - iter 0/56 - loss 1.34657049 throughput (samples/sec): 46.08\n",
      "2019-08-11 16:40:16,100 epoch 5 - iter 5/56 - loss 1.41990628 throughput (samples/sec): 11.60\n",
      "2019-08-11 16:40:31,181 epoch 5 - iter 10/56 - loss 1.41131278 throughput (samples/sec): 11.17\n",
      "2019-08-11 16:40:45,625 epoch 5 - iter 15/56 - loss 1.40249155 throughput (samples/sec): 11.62\n",
      "2019-08-11 16:40:59,938 epoch 5 - iter 20/56 - loss 1.39688209 throughput (samples/sec): 11.74\n",
      "2019-08-11 16:41:13,851 epoch 5 - iter 25/56 - loss 1.39049839 throughput (samples/sec): 11.68\n",
      "2019-08-11 16:41:27,856 epoch 5 - iter 30/56 - loss 1.38345659 throughput (samples/sec): 11.76\n",
      "2019-08-11 16:41:42,217 epoch 5 - iter 35/56 - loss 1.39046316 throughput (samples/sec): 11.46\n",
      "2019-08-11 16:41:56,199 epoch 5 - iter 40/56 - loss 1.38853829 throughput (samples/sec): 11.80\n",
      "2019-08-11 16:42:10,850 epoch 5 - iter 45/56 - loss 1.38705706 throughput (samples/sec): 11.57\n",
      "2019-08-11 16:42:25,028 epoch 5 - iter 50/56 - loss 1.38395028 throughput (samples/sec): 11.64\n",
      "2019-08-11 16:42:38,107 epoch 5 - iter 55/56 - loss 1.38570623 throughput (samples/sec): 12.44\n",
      "2019-08-11 16:42:38,499 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:42:38,501 EPOCH 5 done: loss 1.3857 - lr 0.0100\n",
      "2019-08-11 16:42:59,375 DEV : loss 1.2901272773742676 - score 0.7432\n",
      "2019-08-11 16:43:00,992 BAD EPOCHS (no improvement): 0\n",
      "2019-08-11 16:43:10,692 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:43:15,247 epoch 6 - iter 0/56 - loss 1.41321719 throughput (samples/sec): 55.38\n",
      "2019-08-11 16:43:29,889 epoch 6 - iter 5/56 - loss 1.39765469 throughput (samples/sec): 11.39\n",
      "2019-08-11 16:43:44,619 epoch 6 - iter 10/56 - loss 1.35981191 throughput (samples/sec): 11.27\n",
      "2019-08-11 16:43:59,366 epoch 6 - iter 15/56 - loss 1.36563261 throughput (samples/sec): 11.27\n",
      "2019-08-11 16:44:13,445 epoch 6 - iter 20/56 - loss 1.35880889 throughput (samples/sec): 11.78\n",
      "2019-08-11 16:44:27,765 epoch 6 - iter 25/56 - loss 1.36268388 throughput (samples/sec): 11.58\n",
      "2019-08-11 16:44:41,901 epoch 6 - iter 30/56 - loss 1.36844271 throughput (samples/sec): 11.76\n",
      "2019-08-11 16:44:55,959 epoch 6 - iter 35/56 - loss 1.35750594 throughput (samples/sec): 11.59\n",
      "2019-08-11 16:45:10,541 epoch 6 - iter 40/56 - loss 1.35669829 throughput (samples/sec): 11.39\n",
      "2019-08-11 16:45:24,862 epoch 6 - iter 45/56 - loss 1.34722393 throughput (samples/sec): 11.57\n",
      "2019-08-11 16:45:38,943 epoch 6 - iter 50/56 - loss 1.34428533 throughput (samples/sec): 11.77\n",
      "2019-08-11 16:45:52,078 epoch 6 - iter 55/56 - loss 1.33381947 throughput (samples/sec): 12.61\n",
      "2019-08-11 16:45:52,431 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:45:52,432 EPOCH 6 done: loss 1.3338 - lr 0.0100\n",
      "2019-08-11 16:46:13,275 DEV : loss 1.2750084400177002 - score 0.473\n",
      "2019-08-11 16:46:14,602 BAD EPOCHS (no improvement): 1\n",
      "2019-08-11 16:46:14,604 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:46:21,084 epoch 7 - iter 0/56 - loss 1.45567787 throughput (samples/sec): 57.55\n",
      "2019-08-11 16:46:35,273 epoch 7 - iter 5/56 - loss 1.27627303 throughput (samples/sec): 11.61\n",
      "2019-08-11 16:46:49,926 epoch 7 - iter 10/56 - loss 1.27411530 throughput (samples/sec): 11.51\n",
      "2019-08-11 16:47:04,321 epoch 7 - iter 15/56 - loss 1.25827875 throughput (samples/sec): 11.51\n",
      "2019-08-11 16:47:18,711 epoch 7 - iter 20/56 - loss 1.27482140 throughput (samples/sec): 11.70\n",
      "2019-08-11 16:47:33,017 epoch 7 - iter 25/56 - loss 1.26997814 throughput (samples/sec): 11.80\n",
      "2019-08-11 16:47:47,134 epoch 7 - iter 30/56 - loss 1.27170630 throughput (samples/sec): 11.94\n",
      "2019-08-11 16:48:01,299 epoch 7 - iter 35/56 - loss 1.27156022 throughput (samples/sec): 11.69\n",
      "2019-08-11 16:48:15,770 epoch 7 - iter 40/56 - loss 1.26992459 throughput (samples/sec): 11.65\n",
      "2019-08-11 16:48:30,049 epoch 7 - iter 45/56 - loss 1.26624289 throughput (samples/sec): 11.60\n",
      "2019-08-11 16:48:44,439 epoch 7 - iter 50/56 - loss 1.26416076 throughput (samples/sec): 11.70\n",
      "2019-08-11 16:48:57,603 epoch 7 - iter 55/56 - loss 1.25963372 throughput (samples/sec): 12.82\n",
      "2019-08-11 16:48:57,975 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:48:57,977 EPOCH 7 done: loss 1.2596 - lr 0.0100\n",
      "2019-08-11 16:49:18,870 DEV : loss 1.2241308689117432 - score 0.5541\n",
      "2019-08-11 16:49:20,459 BAD EPOCHS (no improvement): 2\n",
      "2019-08-11 16:49:20,461 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:49:24,660 epoch 8 - iter 0/56 - loss 1.17200875 throughput (samples/sec): 48.96\n",
      "2019-08-11 16:49:39,381 epoch 8 - iter 5/56 - loss 1.21148717 throughput (samples/sec): 11.68\n",
      "2019-08-11 16:49:53,933 epoch 8 - iter 10/56 - loss 1.20062507 throughput (samples/sec): 11.40\n",
      "2019-08-11 16:50:08,208 epoch 8 - iter 15/56 - loss 1.20314720 throughput (samples/sec): 11.45\n",
      "2019-08-11 16:50:22,474 epoch 8 - iter 20/56 - loss 1.19747797 throughput (samples/sec): 11.46\n",
      "2019-08-11 16:50:36,384 epoch 8 - iter 25/56 - loss 1.19987041 throughput (samples/sec): 11.90\n",
      "2019-08-11 16:50:50,703 epoch 8 - iter 30/56 - loss 1.19868839 throughput (samples/sec): 11.97\n",
      "2019-08-11 16:51:05,013 epoch 8 - iter 35/56 - loss 1.19471571 throughput (samples/sec): 11.80\n",
      "2019-08-11 16:51:19,495 epoch 8 - iter 40/56 - loss 1.18981216 throughput (samples/sec): 11.82\n",
      "2019-08-11 16:51:33,772 epoch 8 - iter 45/56 - loss 1.20094245 throughput (samples/sec): 11.81\n",
      "2019-08-11 16:51:48,027 epoch 8 - iter 50/56 - loss 1.20204326 throughput (samples/sec): 12.00\n",
      "2019-08-11 16:52:01,225 epoch 8 - iter 55/56 - loss 1.20024030 throughput (samples/sec): 12.57\n",
      "2019-08-11 16:52:01,583 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:52:01,587 EPOCH 8 done: loss 1.2002 - lr 0.0100\n",
      "2019-08-11 16:52:24,070 DEV : loss 1.157234787940979 - score 0.6802\n",
      "2019-08-11 16:52:25,658 BAD EPOCHS (no improvement): 3\n",
      "2019-08-11 16:52:25,659 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:52:30,136 epoch 9 - iter 0/56 - loss 1.09028900 throughput (samples/sec): 55.54\n",
      "2019-08-11 16:52:44,543 epoch 9 - iter 5/56 - loss 1.17460008 throughput (samples/sec): 11.45\n",
      "2019-08-11 16:52:59,225 epoch 9 - iter 10/56 - loss 1.14780135 throughput (samples/sec): 11.59\n",
      "2019-08-11 16:53:13,811 epoch 9 - iter 15/56 - loss 1.13466122 throughput (samples/sec): 11.52\n",
      "2019-08-11 16:53:27,871 epoch 9 - iter 20/56 - loss 1.14087885 throughput (samples/sec): 11.97\n",
      "2019-08-11 16:53:42,357 epoch 9 - iter 25/56 - loss 1.13863792 throughput (samples/sec): 11.56\n",
      "2019-08-11 16:53:56,597 epoch 9 - iter 30/56 - loss 1.12730178 throughput (samples/sec): 11.54\n",
      "2019-08-11 16:54:10,548 epoch 9 - iter 35/56 - loss 1.12668908 throughput (samples/sec): 11.65\n",
      "2019-08-11 16:54:24,931 epoch 9 - iter 40/56 - loss 1.13682244 throughput (samples/sec): 11.78\n",
      "2019-08-11 16:54:39,080 epoch 9 - iter 45/56 - loss 1.12946236 throughput (samples/sec): 11.90\n",
      "2019-08-11 16:54:53,487 epoch 9 - iter 50/56 - loss 1.13045866 throughput (samples/sec): 11.61\n",
      "2019-08-11 16:55:06,581 epoch 9 - iter 55/56 - loss 1.13523174 throughput (samples/sec): 12.41\n",
      "2019-08-11 16:55:06,948 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:55:06,949 EPOCH 9 done: loss 1.1352 - lr 0.0100\n",
      "2019-08-11 16:55:29,721 DEV : loss 1.100055456161499 - score 0.6216\n",
      "Epoch     8: reducing learning rate of group 0 to 5.0000e-03.\n",
      "2019-08-11 16:55:31,039 BAD EPOCHS (no improvement): 4\n",
      "2019-08-11 16:55:31,040 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:55:35,458 epoch 10 - iter 0/56 - loss 1.09774470 throughput (samples/sec): 45.30\n",
      "2019-08-11 16:55:49,839 epoch 10 - iter 5/56 - loss 1.02985408 throughput (samples/sec): 11.37\n",
      "2019-08-11 16:56:04,200 epoch 10 - iter 10/56 - loss 1.02369968 throughput (samples/sec): 11.50\n",
      "2019-08-11 16:56:18,524 epoch 10 - iter 15/56 - loss 1.01925726 throughput (samples/sec): 11.76\n",
      "2019-08-11 16:56:32,974 epoch 10 - iter 20/56 - loss 1.03083081 throughput (samples/sec): 11.84\n",
      "2019-08-11 16:56:47,028 epoch 10 - iter 25/56 - loss 1.01725313 throughput (samples/sec): 11.99\n",
      "2019-08-11 16:57:01,505 epoch 10 - iter 30/56 - loss 1.03130816 throughput (samples/sec): 11.81\n",
      "2019-08-11 16:57:15,703 epoch 10 - iter 35/56 - loss 1.02883157 throughput (samples/sec): 11.86\n",
      "2019-08-11 16:57:30,084 epoch 10 - iter 40/56 - loss 1.02450441 throughput (samples/sec): 11.87\n",
      "2019-08-11 16:57:44,360 epoch 10 - iter 45/56 - loss 1.02576596 throughput (samples/sec): 11.45\n",
      "2019-08-11 16:57:58,460 epoch 10 - iter 50/56 - loss 1.02835382 throughput (samples/sec): 11.59\n",
      "2019-08-11 16:58:11,311 epoch 10 - iter 55/56 - loss 1.02852375 throughput (samples/sec): 12.72\n",
      "2019-08-11 16:58:11,669 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:58:11,673 EPOCH 10 done: loss 1.0285 - lr 0.0050\n",
      "2019-08-11 16:58:33,881 DEV : loss 1.0062038898468018 - score 0.6937\n",
      "2019-08-11 16:58:35,518 BAD EPOCHS (no improvement): 1\n",
      "2019-08-11 16:58:35,519 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 16:58:39,945 epoch 11 - iter 0/56 - loss 0.98207802 throughput (samples/sec): 55.37\n",
      "2019-08-11 16:58:54,828 epoch 11 - iter 5/56 - loss 0.94425321 throughput (samples/sec): 11.08\n",
      "2019-08-11 16:59:09,017 epoch 11 - iter 10/56 - loss 0.99614922 throughput (samples/sec): 11.54\n",
      "2019-08-11 16:59:23,487 epoch 11 - iter 15/56 - loss 1.03079181 throughput (samples/sec): 11.70\n",
      "2019-08-11 16:59:37,902 epoch 11 - iter 20/56 - loss 1.02315254 throughput (samples/sec): 11.70\n",
      "2019-08-11 16:59:52,153 epoch 11 - iter 25/56 - loss 1.02533891 throughput (samples/sec): 11.85\n",
      "2019-08-11 17:00:06,267 epoch 11 - iter 30/56 - loss 1.01617632 throughput (samples/sec): 11.68\n",
      "2019-08-11 17:00:20,363 epoch 11 - iter 35/56 - loss 1.01136307 throughput (samples/sec): 11.69\n",
      "2019-08-11 17:00:34,455 epoch 11 - iter 40/56 - loss 1.00234441 throughput (samples/sec): 11.89\n",
      "2019-08-11 17:00:49,092 epoch 11 - iter 45/56 - loss 0.99657085 throughput (samples/sec): 11.17\n",
      "2019-08-11 17:01:03,217 epoch 11 - iter 50/56 - loss 0.98928372 throughput (samples/sec): 11.94\n",
      "2019-08-11 17:01:16,423 epoch 11 - iter 55/56 - loss 0.97777496 throughput (samples/sec): 12.56\n",
      "2019-08-11 17:01:16,771 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:01:16,773 EPOCH 11 done: loss 0.9778 - lr 0.0050\n",
      "2019-08-11 17:01:37,638 DEV : loss 1.0479769706726074 - score 0.518\n",
      "2019-08-11 17:01:38,951 BAD EPOCHS (no improvement): 2\n",
      "2019-08-11 17:01:38,952 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:01:45,264 epoch 12 - iter 0/56 - loss 0.85664243 throughput (samples/sec): 51.60\n",
      "2019-08-11 17:01:59,567 epoch 12 - iter 5/56 - loss 0.96348245 throughput (samples/sec): 11.60\n",
      "2019-08-11 17:02:14,001 epoch 12 - iter 10/56 - loss 0.97145737 throughput (samples/sec): 11.67\n",
      "2019-08-11 17:02:28,148 epoch 12 - iter 15/56 - loss 0.97105069 throughput (samples/sec): 11.72\n",
      "2019-08-11 17:02:42,597 epoch 12 - iter 20/56 - loss 0.96612278 throughput (samples/sec): 11.65\n",
      "2019-08-11 17:02:56,988 epoch 12 - iter 25/56 - loss 0.96574503 throughput (samples/sec): 11.73\n",
      "2019-08-11 17:03:11,127 epoch 12 - iter 30/56 - loss 0.96725088 throughput (samples/sec): 11.91\n",
      "2019-08-11 17:03:25,419 epoch 12 - iter 35/56 - loss 0.96997073 throughput (samples/sec): 11.61\n",
      "2019-08-11 17:03:39,900 epoch 12 - iter 40/56 - loss 0.96667920 throughput (samples/sec): 11.62\n",
      "2019-08-11 17:03:54,007 epoch 12 - iter 45/56 - loss 0.96178951 throughput (samples/sec): 11.76\n",
      "2019-08-11 17:04:08,160 epoch 12 - iter 50/56 - loss 0.96056472 throughput (samples/sec): 11.89\n",
      "2019-08-11 17:04:21,422 epoch 12 - iter 55/56 - loss 0.95015296 throughput (samples/sec): 12.72\n",
      "2019-08-11 17:04:21,797 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:04:21,798 EPOCH 12 done: loss 0.9502 - lr 0.0050\n",
      "2019-08-11 17:04:42,650 DEV : loss 0.914436399936676 - score 0.7703\n",
      "2019-08-11 17:04:43,972 BAD EPOCHS (no improvement): 0\n",
      "2019-08-11 17:04:54,027 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:04:59,433 epoch 13 - iter 0/56 - loss 0.87039173 throughput (samples/sec): 35.99\n",
      "2019-08-11 17:05:13,762 epoch 13 - iter 5/56 - loss 0.89762536 throughput (samples/sec): 11.69\n",
      "2019-08-11 17:05:28,683 epoch 13 - iter 10/56 - loss 0.93876684 throughput (samples/sec): 10.96\n",
      "2019-08-11 17:05:43,410 epoch 13 - iter 15/56 - loss 0.93935340 throughput (samples/sec): 11.10\n",
      "2019-08-11 17:05:57,752 epoch 13 - iter 20/56 - loss 0.92509116 throughput (samples/sec): 11.58\n",
      "2019-08-11 17:06:11,696 epoch 13 - iter 25/56 - loss 0.92248662 throughput (samples/sec): 11.93\n",
      "2019-08-11 17:06:25,662 epoch 13 - iter 30/56 - loss 0.90851217 throughput (samples/sec): 11.66\n",
      "2019-08-11 17:06:39,960 epoch 13 - iter 35/56 - loss 0.91012233 throughput (samples/sec): 11.58\n",
      "2019-08-11 17:06:54,441 epoch 13 - iter 40/56 - loss 0.91317742 throughput (samples/sec): 11.46\n",
      "2019-08-11 17:07:08,755 epoch 13 - iter 45/56 - loss 0.91433031 throughput (samples/sec): 11.60\n",
      "2019-08-11 17:07:23,044 epoch 13 - iter 50/56 - loss 0.90896772 throughput (samples/sec): 11.57\n",
      "2019-08-11 17:07:36,052 epoch 13 - iter 55/56 - loss 0.90558940 throughput (samples/sec): 12.73\n",
      "2019-08-11 17:07:36,397 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:07:36,402 EPOCH 13 done: loss 0.9056 - lr 0.0050\n",
      "2019-08-11 17:07:56,922 DEV : loss 0.8875751495361328 - score 0.7297\n",
      "2019-08-11 17:07:58,226 BAD EPOCHS (no improvement): 1\n",
      "2019-08-11 17:07:58,228 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:08:04,510 epoch 14 - iter 0/56 - loss 0.81789565 throughput (samples/sec): 59.25\n",
      "2019-08-11 17:08:18,920 epoch 14 - iter 5/56 - loss 0.91313321 throughput (samples/sec): 11.49\n",
      "2019-08-11 17:08:33,463 epoch 14 - iter 10/56 - loss 0.91268883 throughput (samples/sec): 11.33\n",
      "2019-08-11 17:08:47,961 epoch 14 - iter 15/56 - loss 0.91805268 throughput (samples/sec): 11.38\n",
      "2019-08-11 17:09:02,177 epoch 14 - iter 20/56 - loss 0.89682263 throughput (samples/sec): 11.82\n",
      "2019-08-11 17:09:16,552 epoch 14 - iter 25/56 - loss 0.91300473 throughput (samples/sec): 11.83\n",
      "2019-08-11 17:09:30,631 epoch 14 - iter 30/56 - loss 0.90443198 throughput (samples/sec): 11.52\n",
      "2019-08-11 17:09:44,658 epoch 14 - iter 35/56 - loss 0.90146266 throughput (samples/sec): 11.74\n",
      "2019-08-11 17:09:59,139 epoch 14 - iter 40/56 - loss 0.88838374 throughput (samples/sec): 11.38\n",
      "2019-08-11 17:10:13,247 epoch 14 - iter 45/56 - loss 0.88990459 throughput (samples/sec): 11.77\n",
      "2019-08-11 17:10:27,610 epoch 14 - iter 50/56 - loss 0.88553395 throughput (samples/sec): 11.78\n",
      "2019-08-11 17:10:40,629 epoch 14 - iter 55/56 - loss 0.88036732 throughput (samples/sec): 12.48\n",
      "2019-08-11 17:10:40,995 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:10:41,000 EPOCH 14 done: loss 0.8804 - lr 0.0050\n",
      "2019-08-11 17:11:01,886 DEV : loss 0.8572484850883484 - score 0.7748\n",
      "2019-08-11 17:11:03,211 BAD EPOCHS (no improvement): 0\n",
      "2019-08-11 17:11:13,200 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:11:20,115 epoch 15 - iter 0/56 - loss 0.90730810 throughput (samples/sec): 53.81\n",
      "2019-08-11 17:11:34,218 epoch 15 - iter 5/56 - loss 0.87807362 throughput (samples/sec): 11.52\n",
      "2019-08-11 17:11:48,915 epoch 15 - iter 10/56 - loss 0.84217757 throughput (samples/sec): 11.24\n",
      "2019-08-11 17:12:03,802 epoch 15 - iter 15/56 - loss 0.84583747 throughput (samples/sec): 11.07\n",
      "2019-08-11 17:12:17,900 epoch 15 - iter 20/56 - loss 0.84521717 throughput (samples/sec): 11.90\n",
      "2019-08-11 17:12:32,423 epoch 15 - iter 25/56 - loss 0.84431576 throughput (samples/sec): 11.43\n",
      "2019-08-11 17:12:46,367 epoch 15 - iter 30/56 - loss 0.84015583 throughput (samples/sec): 11.84\n",
      "2019-08-11 17:13:00,529 epoch 15 - iter 35/56 - loss 0.83927182 throughput (samples/sec): 11.46\n",
      "2019-08-11 17:13:14,634 epoch 15 - iter 40/56 - loss 0.82935443 throughput (samples/sec): 11.94\n",
      "2019-08-11 17:13:29,006 epoch 15 - iter 45/56 - loss 0.82795948 throughput (samples/sec): 11.59\n",
      "2019-08-11 17:13:43,361 epoch 15 - iter 50/56 - loss 0.83847205 throughput (samples/sec): 11.48\n",
      "2019-08-11 17:13:56,318 epoch 15 - iter 55/56 - loss 0.83925071 throughput (samples/sec): 12.55\n",
      "2019-08-11 17:13:56,675 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:13:56,676 EPOCH 15 done: loss 0.8393 - lr 0.0050\n",
      "2019-08-11 17:14:19,312 DEV : loss 0.8818145394325256 - score 0.7117\n",
      "2019-08-11 17:14:20,636 BAD EPOCHS (no improvement): 1\n",
      "2019-08-11 17:14:20,645 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:14:25,364 epoch 16 - iter 0/56 - loss 0.86603993 throughput (samples/sec): 53.75\n",
      "2019-08-11 17:14:39,396 epoch 16 - iter 5/56 - loss 0.79620879 throughput (samples/sec): 11.54\n",
      "2019-08-11 17:14:54,302 epoch 16 - iter 10/56 - loss 0.80630351 throughput (samples/sec): 11.38\n",
      "2019-08-11 17:15:08,602 epoch 16 - iter 15/56 - loss 0.81581195 throughput (samples/sec): 11.58\n",
      "2019-08-11 17:15:22,730 epoch 16 - iter 20/56 - loss 0.81830451 throughput (samples/sec): 11.97\n",
      "2019-08-11 17:15:37,236 epoch 16 - iter 25/56 - loss 0.81910656 throughput (samples/sec): 11.39\n",
      "2019-08-11 17:15:51,392 epoch 16 - iter 30/56 - loss 0.82607612 throughput (samples/sec): 11.95\n",
      "2019-08-11 17:16:05,456 epoch 16 - iter 35/56 - loss 0.82228663 throughput (samples/sec): 11.51\n",
      "2019-08-11 17:16:19,458 epoch 16 - iter 40/56 - loss 0.82106905 throughput (samples/sec): 11.78\n",
      "2019-08-11 17:16:33,817 epoch 16 - iter 45/56 - loss 0.81883576 throughput (samples/sec): 11.76\n",
      "2019-08-11 17:16:48,143 epoch 16 - iter 50/56 - loss 0.81504777 throughput (samples/sec): 11.52\n",
      "2019-08-11 17:17:01,095 epoch 16 - iter 55/56 - loss 0.81517531 throughput (samples/sec): 12.87\n",
      "2019-08-11 17:17:01,461 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:17:01,463 EPOCH 16 done: loss 0.8152 - lr 0.0050\n",
      "2019-08-11 17:17:22,465 DEV : loss 0.8453492522239685 - score 0.7342\n",
      "2019-08-11 17:17:24,032 BAD EPOCHS (no improvement): 2\n",
      "2019-08-11 17:17:24,033 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:17:28,536 epoch 17 - iter 0/56 - loss 0.72277075 throughput (samples/sec): 54.41\n",
      "2019-08-11 17:17:42,993 epoch 17 - iter 5/56 - loss 0.78002929 throughput (samples/sec): 11.45\n",
      "2019-08-11 17:17:57,547 epoch 17 - iter 10/56 - loss 0.77129137 throughput (samples/sec): 11.54\n",
      "2019-08-11 17:18:11,854 epoch 17 - iter 15/56 - loss 0.78011321 throughput (samples/sec): 11.75\n",
      "2019-08-11 17:18:26,197 epoch 17 - iter 20/56 - loss 0.78528026 throughput (samples/sec): 11.54\n",
      "2019-08-11 17:18:40,238 epoch 17 - iter 25/56 - loss 0.78979237 throughput (samples/sec): 11.80\n",
      "2019-08-11 17:18:54,551 epoch 17 - iter 30/56 - loss 0.78928653 throughput (samples/sec): 11.80\n",
      "2019-08-11 17:19:08,692 epoch 17 - iter 35/56 - loss 0.78293010 throughput (samples/sec): 11.49\n",
      "2019-08-11 17:19:22,984 epoch 17 - iter 40/56 - loss 0.78652669 throughput (samples/sec): 11.62\n",
      "2019-08-11 17:19:37,592 epoch 17 - iter 45/56 - loss 0.77717028 throughput (samples/sec): 11.35\n",
      "2019-08-11 17:19:51,747 epoch 17 - iter 50/56 - loss 0.78029601 throughput (samples/sec): 11.71\n",
      "2019-08-11 17:20:04,837 epoch 17 - iter 55/56 - loss 0.77891610 throughput (samples/sec): 12.41\n",
      "2019-08-11 17:20:05,182 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:20:05,184 EPOCH 17 done: loss 0.7789 - lr 0.0050\n",
      "2019-08-11 17:20:26,159 DEV : loss 0.8771321177482605 - score 0.5991\n",
      "2019-08-11 17:20:27,477 BAD EPOCHS (no improvement): 3\n",
      "2019-08-11 17:20:27,478 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:20:34,010 epoch 18 - iter 0/56 - loss 0.71763730 throughput (samples/sec): 53.65\n",
      "2019-08-11 17:20:48,368 epoch 18 - iter 5/56 - loss 0.76854989 throughput (samples/sec): 11.51\n",
      "2019-08-11 17:21:02,790 epoch 18 - iter 10/56 - loss 0.78244645 throughput (samples/sec): 11.69\n",
      "2019-08-11 17:21:17,183 epoch 18 - iter 15/56 - loss 0.75499956 throughput (samples/sec): 11.72\n",
      "2019-08-11 17:21:31,243 epoch 18 - iter 20/56 - loss 0.77642196 throughput (samples/sec): 11.80\n",
      "2019-08-11 17:21:45,435 epoch 18 - iter 25/56 - loss 0.78367862 throughput (samples/sec): 11.89\n",
      "2019-08-11 17:21:59,847 epoch 18 - iter 30/56 - loss 0.77444833 throughput (samples/sec): 11.69\n",
      "2019-08-11 17:22:13,907 epoch 18 - iter 35/56 - loss 0.77272229 throughput (samples/sec): 11.73\n",
      "2019-08-11 17:22:28,451 epoch 18 - iter 40/56 - loss 0.76552134 throughput (samples/sec): 11.59\n",
      "2019-08-11 17:22:43,092 epoch 18 - iter 45/56 - loss 0.76977008 throughput (samples/sec): 11.54\n",
      "2019-08-11 17:22:57,419 epoch 18 - iter 50/56 - loss 0.75890129 throughput (samples/sec): 11.59\n",
      "2019-08-11 17:23:10,658 epoch 18 - iter 55/56 - loss 0.76029491 throughput (samples/sec): 12.75\n",
      "2019-08-11 17:23:11,051 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:23:11,053 EPOCH 18 done: loss 0.7603 - lr 0.0050\n",
      "2019-08-11 17:23:32,022 DEV : loss 0.8000187277793884 - score 0.7117\n",
      "Epoch    17: reducing learning rate of group 0 to 2.5000e-03.\n",
      "2019-08-11 17:23:33,334 BAD EPOCHS (no improvement): 4\n",
      "2019-08-11 17:23:33,335 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:23:39,688 epoch 19 - iter 0/56 - loss 0.88779265 throughput (samples/sec): 54.59\n",
      "2019-08-11 17:23:54,046 epoch 19 - iter 5/56 - loss 0.71233745 throughput (samples/sec): 11.75\n",
      "2019-08-11 17:24:08,734 epoch 19 - iter 10/56 - loss 0.69154462 throughput (samples/sec): 11.48\n",
      "2019-08-11 17:24:23,231 epoch 19 - iter 15/56 - loss 0.72201240 throughput (samples/sec): 11.61\n",
      "2019-08-11 17:24:37,460 epoch 19 - iter 20/56 - loss 0.71232619 throughput (samples/sec): 11.87\n",
      "2019-08-11 17:24:51,708 epoch 19 - iter 25/56 - loss 0.72511669 throughput (samples/sec): 11.62\n",
      "2019-08-11 17:25:06,068 epoch 19 - iter 30/56 - loss 0.72312525 throughput (samples/sec): 11.75\n",
      "2019-08-11 17:25:20,253 epoch 19 - iter 35/56 - loss 0.71837510 throughput (samples/sec): 11.67\n",
      "2019-08-11 17:25:34,686 epoch 19 - iter 40/56 - loss 0.71704091 throughput (samples/sec): 11.68\n",
      "2019-08-11 17:25:49,106 epoch 19 - iter 45/56 - loss 0.71940562 throughput (samples/sec): 11.67\n",
      "2019-08-11 17:26:03,036 epoch 19 - iter 50/56 - loss 0.71866303 throughput (samples/sec): 12.11\n",
      "2019-08-11 17:26:16,154 epoch 19 - iter 55/56 - loss 0.71334643 throughput (samples/sec): 12.60\n",
      "2019-08-11 17:26:16,538 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:26:16,540 EPOCH 19 done: loss 0.7133 - lr 0.0025\n",
      "2019-08-11 17:26:37,456 DEV : loss 0.736423134803772 - score 0.7703\n",
      "2019-08-11 17:26:38,773 BAD EPOCHS (no improvement): 1\n",
      "2019-08-11 17:26:38,774 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:26:44,340 epoch 20 - iter 0/56 - loss 0.69973677 throughput (samples/sec): 53.26\n",
      "2019-08-11 17:26:58,671 epoch 20 - iter 5/56 - loss 0.70334069 throughput (samples/sec): 11.39\n",
      "2019-08-11 17:27:13,135 epoch 20 - iter 10/56 - loss 0.67042104 throughput (samples/sec): 11.42\n",
      "2019-08-11 17:27:27,497 epoch 20 - iter 15/56 - loss 0.65584960 throughput (samples/sec): 11.68\n",
      "2019-08-11 17:27:41,894 epoch 20 - iter 20/56 - loss 0.67434057 throughput (samples/sec): 11.89\n",
      "2019-08-11 17:27:55,994 epoch 20 - iter 25/56 - loss 0.68232114 throughput (samples/sec): 11.96\n",
      "2019-08-11 17:28:10,434 epoch 20 - iter 30/56 - loss 0.69005323 throughput (samples/sec): 11.87\n",
      "2019-08-11 17:28:24,583 epoch 20 - iter 35/56 - loss 0.68835041 throughput (samples/sec): 11.89\n",
      "2019-08-11 17:28:39,096 epoch 20 - iter 40/56 - loss 0.69309023 throughput (samples/sec): 11.77\n",
      "2019-08-11 17:28:53,556 epoch 20 - iter 45/56 - loss 0.68686270 throughput (samples/sec): 11.64\n",
      "2019-08-11 17:29:07,615 epoch 20 - iter 50/56 - loss 0.69688493 throughput (samples/sec): 11.62\n",
      "2019-08-11 17:29:20,816 epoch 20 - iter 55/56 - loss 0.69822909 throughput (samples/sec): 12.36\n",
      "2019-08-11 17:29:21,191 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:29:21,196 EPOCH 20 done: loss 0.6982 - lr 0.0025\n",
      "2019-08-11 17:29:43,882 DEV : loss 0.7377538084983826 - score 0.7613\n",
      "2019-08-11 17:29:45,212 BAD EPOCHS (no improvement): 2\n",
      "2019-08-11 17:29:55,212 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-11 17:29:55,227 Testing using best model ...\n",
      "2019-08-11 17:29:55,229 loading file model/RoBERTa/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_fairseq_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading archive file http://dl.fbaipublicfiles.com/fairseq/models/roberta.large.tar.gz from cache at /root/.cache/torch/pytorch_fairseq/83e3a689e28e5e4696ecb0bbb05a77355444a5c8a3437e0f736d8a564e80035e.c687083d14776c1979f3f71654febb42f2bb3d9a94ff7ebdfe1ac6748dba89d2\n",
      "| dictionary: 50264 types\n",
      "2019-08-11 17:30:36,700 0.7668\t0.7668\t0.7668\n",
      "2019-08-11 17:30:36,703 \n",
      "MICRO_AVG: acc 0.6218 - f1-score 0.7668\n",
      "MACRO_AVG: acc 0.6285 - f1-score 0.76726\n",
      "business   tp: 44 - fp: 26 - fn: 8 - tn: 145 - precision: 0.6286 - recall: 0.8462 - accuracy: 0.5641 - f1-score: 0.7213\n",
      "entertainment tp: 32 - fp: 5 - fn: 8 - tn: 178 - precision: 0.8649 - recall: 0.8000 - accuracy: 0.7111 - f1-score: 0.8312\n",
      "politics   tp: 24 - fp: 8 - fn: 18 - tn: 173 - precision: 0.7500 - recall: 0.5714 - accuracy: 0.4800 - f1-score: 0.6486\n",
      "sport      tp: 40 - fp: 3 - fn: 10 - tn: 170 - precision: 0.9302 - recall: 0.8000 - accuracy: 0.7547 - f1-score: 0.8602\n",
      "tech       tp: 31 - fp: 10 - fn: 8 - tn: 174 - precision: 0.7561 - recall: 0.7949 - accuracy: 0.6327 - f1-score: 0.7750\n",
      "2019-08-11 17:30:36,708 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.7668,\n",
       " 'dev_score_history': [0.2568,\n",
       "  0.3243,\n",
       "  0.3063,\n",
       "  0.4099,\n",
       "  0.7432,\n",
       "  0.473,\n",
       "  0.5541,\n",
       "  0.6802,\n",
       "  0.6216,\n",
       "  0.6937,\n",
       "  0.518,\n",
       "  0.7703,\n",
       "  0.7297,\n",
       "  0.7748,\n",
       "  0.7117,\n",
       "  0.7342,\n",
       "  0.5991,\n",
       "  0.7117,\n",
       "  0.7703,\n",
       "  0.7613],\n",
       " 'train_loss_history': [1.6650560923985072,\n",
       "  1.579370447567531,\n",
       "  1.5145624769585473,\n",
       "  1.4468005022832326,\n",
       "  1.3857062309980392,\n",
       "  1.3338194681065423,\n",
       "  1.2596337177923747,\n",
       "  1.2002403001700128,\n",
       "  1.1352317386439867,\n",
       "  1.0285237495388304,\n",
       "  0.9777749595897538,\n",
       "  0.9501529633998871,\n",
       "  0.9055893974644798,\n",
       "  0.8803673216274807,\n",
       "  0.839250705071858,\n",
       "  0.8151753076485225,\n",
       "  0.7789160971130643,\n",
       "  0.7602949142456055,\n",
       "  0.7133464312979153,\n",
       "  0.6982290931046009],\n",
       " 'dev_loss_history': [tensor(1.5684, device='cuda:0'),\n",
       "  tensor(1.4986, device='cuda:0'),\n",
       "  tensor(1.5374, device='cuda:0'),\n",
       "  tensor(1.3849, device='cuda:0'),\n",
       "  tensor(1.2901, device='cuda:0'),\n",
       "  tensor(1.2750, device='cuda:0'),\n",
       "  tensor(1.2241, device='cuda:0'),\n",
       "  tensor(1.1572, device='cuda:0'),\n",
       "  tensor(1.1001, device='cuda:0'),\n",
       "  tensor(1.0062, device='cuda:0'),\n",
       "  tensor(1.0480, device='cuda:0'),\n",
       "  tensor(0.9144, device='cuda:0'),\n",
       "  tensor(0.8876, device='cuda:0'),\n",
       "  tensor(0.8572, device='cuda:0'),\n",
       "  tensor(0.8818, device='cuda:0'),\n",
       "  tensor(0.8453, device='cuda:0'),\n",
       "  tensor(0.8771, device='cuda:0'),\n",
       "  tensor(0.8000, device='cuda:0'),\n",
       "  tensor(0.7364, device='cuda:0'),\n",
       "  tensor(0.7378, device='cuda:0')]}"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(MODEL_FOLDER_PATH, max_epochs=params_train[\"max_epoch\"], learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5mWqEVzjZKah"
   },
   "source": [
    "## Plot training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOGcEpvEZKaj"
   },
   "outputs": [],
   "source": [
    "from flair.visual.training_curves import Plotter\n",
    "\n",
    "plotter = Plotter()\n",
    "plotter.plot_training_curves(os.path.join(MODEL_FOLDER_PATH, 'loss.tsv'))\n",
    "plotter.plot_weights(os.path.join(MODEL_FOLDER_PATH, 'weights.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "grnGDG_CZKan"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "flair_text_classification _RoBERTa.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
