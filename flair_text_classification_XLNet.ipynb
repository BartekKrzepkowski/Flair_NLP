{"cells":[{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip3 install git+https://github.com/zalandoresearch/flair","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting git+https://github.com/zalandoresearch/flair\n  Cloning https://github.com/zalandoresearch/flair to /tmp/pip-req-build-x5hxoil6\n  Running command git clone -q https://github.com/zalandoresearch/flair /tmp/pip-req-build-x5hxoil6\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (1.1.0)\nRequirement already satisfied: matplotlib>=2.2.3 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (3.0.3)\nCollecting sqlitedict>=1.6.0 (from flair==0.4.2)\n  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\nCollecting deprecated>=1.2.4 (from flair==0.4.2)\n  Downloading https://files.pythonhosted.org/packages/88/0e/9d5a1a8cd7130c49334cce7b8167ceda63d6a329c8ea65b626116bc9e9e6/Deprecated-1.2.6-py2.py3-none-any.whl\nRequirement already satisfied: urllib3<1.25,>=1.20 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (1.24.2)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.6/site-packages/tabulate-0.8.3-py3.6.egg (from flair==0.4.2) (0.8.3)\nRequirement already satisfied: mpld3==0.3 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (0.3)\nRequirement already satisfied: pytest>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (5.0.1)\nRequirement already satisfied: hyperopt>=0.1.1 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (0.1.2)\nCollecting segtok>=1.5.7 (from flair==0.4.2)\n  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\nCollecting bpemb>=0.2.9 (from flair==0.4.2)\n  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\nRequirement already satisfied: ipython-genutils==0.2.0 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (0.2.0)\nRequirement already satisfied: gensim>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (3.8.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (2019.6.8)\nRequirement already satisfied: tqdm>=4.26.0 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (4.32.1)\nRequirement already satisfied: langdetect in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (1.0.7)\nCollecting pytorch-transformers>=1.0.0 (from flair==0.4.2)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/b5/2d78e74001af0152ee61d5ad4e290aec9a1e43925b21df2dc74ec100f1ab/pytorch_transformers-1.0.0-py3-none-any.whl (137kB)\n\u001b[K     |████████████████████████████████| 143kB 8.8MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: sklearn in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (0.0)\nRequirement already satisfied: ipython==7.6.1 in /opt/conda/lib/python3.6/site-packages (from flair==0.4.2) (7.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch>=1.0.0->flair==0.4.2) (1.16.4)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair==0.4.2) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair==0.4.2) (1.1.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.4.0)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.8.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.6/site-packages (from deprecated>=1.2.4->flair==0.4.2) (1.11.2)\nRequirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (1.8.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (19.0)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (19.1.0)\nRequirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (7.0.0)\nRequirement already satisfied: atomicwrites>=1.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (1.3.0)\nRequirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (0.12.0)\nRequirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (0.17)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair==0.4.2) (0.1.7)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair==0.4.2) (1.2.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair==0.4.2) (1.12.0)\nRequirement already satisfied: pymongo in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair==0.4.2) (3.8.0)\nRequirement already satisfied: networkx==2.2 in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair==0.4.2) (2.2)\nRequirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair==0.4.2) (0.17.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from bpemb>=0.2.9->flair==0.4.2) (2.22.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (from bpemb>=0.2.9->flair==0.4.2) (0.1.82)\nRequirement already satisfied: smart-open>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from gensim>=3.4.0->flair==0.4.2) (1.8.4)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from pytorch-transformers>=1.0.0->flair==0.4.2) (1.9.194)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from sklearn->flair==0.4.2) (0.21.2)\nRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (2.0.9)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (4.4.0)\nRequirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (2.4.2)\nRequirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (4.3.2)\nRequirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (0.13.3)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (41.0.1)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (0.7.5)\nRequirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (4.7.0)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython==7.6.1->flair==0.4.2) (0.1.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=0.12->pytest>=3.6.4->flair==0.4.2) (0.5.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->bpemb>=0.2.9->flair==0.4.2) (2019.6.16)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->bpemb>=0.2.9->flair==0.4.2) (2.8)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->bpemb>=0.2.9->flair==0.4.2) (3.0.4)\nRequirement already satisfied: boto>=2.32 in /opt/conda/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim>=3.4.0->flair==0.4.2) (2.49.0)\nRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-transformers>=1.0.0->flair==0.4.2) (0.2.1)\n","name":"stdout"},{"output_type":"stream","text":"Requirement already satisfied: botocore<1.13.0,>=1.12.194 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-transformers>=1.0.0->flair==0.4.2) (1.12.194)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-transformers>=1.0.0->flair==0.4.2) (0.9.4)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn->flair==0.4.2) (0.13.2)\nRequirement already satisfied: parso>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from jedi>=0.10->ipython==7.6.1->flair==0.4.2) (0.5.0)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython==7.6.1->flair==0.4.2) (0.6.0)\nRequirement already satisfied: docutils<0.15,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.194->boto3->pytorch-transformers>=1.0.0->flair==0.4.2) (0.14)\nBuilding wheels for collected packages: flair\n  Building wheel for flair (PEP 517) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for flair: filename=flair-0.4.2-cp36-none-any.whl size=102754 sha256=6580386d954f2415d7dcaed473997bd6b0c0a0c02ff54ab90243894288bfd393\n  Stored in directory: /tmp/pip-ephem-wheel-cache-384cr330/wheels/8e/47/da/f22675cf094ae69648b301413ef8639296775f876b38a5507f\nSuccessfully built flair\nBuilding wheels for collected packages: sqlitedict, segtok\n  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=f1e2478a47637bde319eb96d7f11591cc530347d5cc663c9c805b6379f40ee27\n  Stored in directory: /tmp/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n  Building wheel for segtok (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23257 sha256=f21f07bbd65eb0aa06785f91680903baf5a907a47f05eb14e774dba5ee258b39\n  Stored in directory: /tmp/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\nSuccessfully built sqlitedict segtok\nInstalling collected packages: sqlitedict, deprecated, segtok, bpemb, pytorch-transformers, flair\nSuccessfully installed bpemb-0.3.0 deprecated-1.2.6 flair-0.4.2 pytorch-transformers-1.0.0 segtok-1.5.7 sqlitedict-1.6.0\n\u001b[33mWARNING: You are using pip version 19.2.1, however version 19.2.2 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\n%matplotlib inline\n\nimport torch\ntorch.cuda.is_available()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"> ## Create a Corpus"},{"metadata":{},"cell_type":"markdown","source":"### 1) Load from simple CSV file"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from flair.datasets import CSVClassificationCorpus","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great development.."},{"metadata":{},"cell_type":"markdown","source":"### 2) FastText Format"},{"metadata":{"trusted":true},"cell_type":"code","source":"from flair.data import Corpus\nfrom flair.datasets import ClassificationCorpus","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FILE_PATH = \"../input/bbc-text.csv\"\nDATASET_FOLDER_PATH = \"splitted_data\"\n# DATASET_FOLDER_PATH = os.path.join(\"splitted_data\", FILE_PATH.split(\".\")[0].split(\"/\")[1])\n\ncolumn_name = {\n    \"text\": \"text\",\n    \"label\": \"category\"\n}","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# file format\n__label__<label_1> <text>\n__label__<label_1> __label__<label_2> <text>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df = pd.read_csv(FILE_PATH).sample(frac=1)\ndata_df[column_name[\"label\"]] = '__label__' + data_df[column_name[\"label\"]].astype(str)\n\n# number of chars\ndata_df[column_name[\"text\"]].str.len().plot(kind=\"hist\", title=\"line lenght distribution\", grid=True, figsize=(10,10), bins=50);","execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x720 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nfrom string import digits, punctuation\n\ndef clear_text(text, is_all_lower=True):\n    punct = re.sub(r'[\\.,!?&\\-]', '', punctuation)\n    punctuation_table = str.maketrans({key: \"#\" for key in punct})\n    for char in [\"\\\"\", \"\\'\"]:\n        del punctuation_table[ord(char)]\n    \n    review_cleaned = text.apply(lambda x: re.sub(r'[^\\x00-\\x7F]', ' ', x))\n    review_cleaned = review_cleaned.apply(lambda x: re.sub(r'[0-9]', '9', x))\n    review_cleaned = review_cleaned.apply(lambda x: x.translate(punctuation_table))\n    review_cleaned = review_cleaned.apply(lambda x: re.sub(r' +', ' ', x))\n    review_cleaned = review_cleaned.apply(lambda x: re.sub(r' (?=[\\.,!?&\\-])','', x))\n    \n    if is_all_lower:\n        review_cleaned = review_cleaned.str.lower()\n        \n    return review_cleaned\n\ndata_df[column_name[\"text\"]] = clear_text(data_df[\"text\"])\ndata_df[column_name[\"text\"]] = data_df[column_name[\"text\"]].apply(lambda x: x[:5000])\n\n# number of chars\ndata_df[column_name[\"text\"]].str.len().plot(kind=\"hist\", title=\"line lenght distribution\", grid=True, figsize=(10,10), bins=50);","execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x720 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.exists(DATASET_FOLDER_PATH):\n    os.makedirs(DATASET_FOLDER_PATH)\ndata_df.iloc[0: int(len(data_df)*0.8)].to_csv(os.path.join(DATASET_FOLDER_PATH, 'train.csv'), sep='\\t', index = False, header = False)\ndata_df.iloc[int(len(data_df)*0.8): int(len(data_df)*0.9)].to_csv(os.path.join(DATASET_FOLDER_PATH, 'dev.csv'), sep='\\t', index = False, header = False)\ndata_df.iloc[int(len(data_df)*0.9): ].to_csv(os.path.join(DATASET_FOLDER_PATH, 'test.csv'), sep='\\t', index = False, header = False);","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus = ClassificationCorpus(DATASET_FOLDER_PATH)","execution_count":9,"outputs":[{"output_type":"stream","text":"2019-08-11 21:00:45,251 Reading data from splitted_data\n2019-08-11 21:00:45,252 Train: splitted_data/train.csv\n2019-08-11 21:00:45,258 Dev: splitted_data/dev.csv\n2019-08-11 21:00:45,259 Test: splitted_data/test.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Each line in a corpus is converted to a Sentence object annotated with the labels."},{"metadata":{},"cell_type":"markdown","source":"## Check distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(os.path.join(DATASET_FOLDER_PATH, \"train.csv\"), names=[\"label\", \"text\"], delimiter=\"\\t\")\ntrain_df.label.value_counts()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"__label__sport            422\n__label__business         395\n__label__politics         347\n__label__tech             320\n__label__entertainment    296\nName: label, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_df = pd.read_csv(os.path.join(DATASET_FOLDER_PATH, \"dev.csv\"), names=[\"label\", \"text\"], delimiter=\"\\t\")\nval_df.label.value_counts()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"__label__entertainment    53\n__label__business         52\n__label__sport            45\n__label__politics         39\n__label__tech             33\nName: label, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(os.path.join(DATASET_FOLDER_PATH, \"test.csv\"), names=[\"label\", \"text\"], delimiter=\"\\t\")\ntest_df.label.value_counts()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"__label__business         63\n__label__tech             48\n__label__sport            44\n__label__entertainment    37\n__label__politics         31\nName: label, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Training a Model"},{"metadata":{},"cell_type":"markdown","source":"## XLNet"},{"metadata":{"trusted":true},"cell_type":"code","source":"from flair.embeddings import XLNetEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\nfrom flair.models import TextClassifier\nfrom flair.trainers import ModelTrainer\nfrom flair.training_utils import EvaluationMetric\n# from flair.visual.training_curves import Plotter","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MODEL_FOLDER_PATH = \"model/XLNet\"\nif not os.path.exists(MODEL_FOLDER_PATH):\n    os.makedirs(MODEL_FOLDER_PATH)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_train = {\n    \"flair_emb_forward\": 'news-forward-fast',\n    \"flair_emb_backward\": 'news-backward-fast',\n    \"hidden_size\": 256,\n    \"reproject_words_dimension\": 128,\n    \"max_epoch\": 20,\n    \"evaluation_metric\": EvaluationMetric.MICRO_ACCURACY\n}\n\nword_embeddings = [XLNetEmbeddings(), FlairEmbeddings(params_train[\"flair_emb_forward\"]),\n                   FlairEmbeddings(params_train[\"flair_emb_backward\"])]\n\ndocument_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=params_train[\"hidden_size\"],\n                                            reproject_words=True, reproject_words_dimension=params_train[\"reproject_words_dimension\"])\n\nclassifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n\ntrainer = ModelTrainer(classifier, corpus)","execution_count":15,"outputs":[{"output_type":"stream","text":"100%|██████████| 798011/798011 [00:00<00:00, 1959296.06B/s]\n100%|██████████| 467/467 [00:00<00:00, 152028.87B/s]\n100%|██████████| 1441285815/1441285815 [00:52<00:00, 27295175.13B/s]\n","name":"stderr"},{"output_type":"stream","text":"2019-08-11 21:02:26,162 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmp2m7rjwdt\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 19689779/19689779 [00:00<00:00, 41625777.83B/s]","name":"stderr"},{"output_type":"stream","text":"2019-08-11 21:02:26,819 copying /tmp/tmp2m7rjwdt to cache at /tmp/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"2019-08-11 21:02:26,851 removing temp file /tmp/tmp2m7rjwdt\n2019-08-11 21:02:27,006 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmp90aovujn\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 19689779/19689779 [00:00<00:00, 42495572.82B/s]","name":"stderr"},{"output_type":"stream","text":"2019-08-11 21:02:27,623 copying /tmp/tmp90aovujn to cache at /tmp/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n2019-08-11 21:02:27,657 removing temp file /tmp/tmp90aovujn\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"2019-08-11 21:02:27,742 Computing label dictionary. Progress:\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 1780/1780 [00:23<00:00, 74.77it/s]","name":"stderr"},{"output_type":"stream","text":"2019-08-11 21:02:52,028 [b'tech', b'politics', b'business', b'sport', b'entertainment']\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate_tsv = trainer.find_learning_rate(MODEL_FOLDER_PATH, 'learning_rate.tsv')\n\nplotter = Plotter()\nplotter.plot_learning_rate(learning_rate_tsv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer.train(MODEL_FOLDER_PATH, max_epochs=params_train[\"max_epoch\"])#, evaluation_metric=params_train[\"evaluation_metric\"])","execution_count":16,"outputs":[{"output_type":"stream","text":"2019-08-11 21:02:52,047 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:02:52,053 Model: \"TextClassifier(\n  (document_embeddings): DocumentRNNEmbeddings(\n    (embeddings): StackedEmbeddings(\n      (list_embedding_0): XLNetEmbeddings(\n        model=xlnet-large-cased\n        (model): XLNetModel(\n          (word_embedding): Embedding(32000, 1024)\n          (layer): ModuleList(\n            (0): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (1): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (2): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (3): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (4): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (5): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (6): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (7): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (8): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (9): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (10): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (11): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (12): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (13): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (14): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (15): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (16): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (17): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (18): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (19): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (20): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (21): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (22): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n            (23): XLNetLayer(\n              (rel_attn): XLNetRelativeAttention(\n                (layer_norm): XLNetLayerNorm()\n                (dropout): Dropout(p=0.1)\n              )\n              (ff): XLNetFeedForward(\n                (layer_norm): XLNetLayerNorm()\n                (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n                (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1)\n              )\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (dropout): Dropout(p=0.1)\n        )\n      )\n      (list_embedding_1): FlairEmbeddings(\n        (lm): LanguageModel(\n          (drop): Dropout(p=0.25)\n          (encoder): Embedding(275, 100)\n          (rnn): LSTM(100, 1024)\n          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n        )\n      )\n      (list_embedding_2): FlairEmbeddings(\n        (lm): LanguageModel(\n          (drop): Dropout(p=0.25)\n          (encoder): Embedding(275, 100)\n          (rnn): LSTM(100, 1024)\n          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n        )\n      )\n    )\n    (word_reprojection_map): Linear(in_features=4096, out_features=128, bias=True)\n    (rnn): GRU(128, 256)\n    (dropout): Dropout(p=0.5)\n  )\n  (decoder): Linear(in_features=256, out_features=5, bias=True)\n  (loss_function): CrossEntropyLoss()\n)\"\n","name":"stdout"},{"output_type":"stream","text":"2019-08-11 21:02:52,055 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:02:52,057 Corpus: \"Corpus: 1780 train + 222 dev + 223 test sentences\"\n2019-08-11 21:02:52,059 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:02:52,060 Parameters:\n2019-08-11 21:02:52,062  - learning_rate: \"0.1\"\n2019-08-11 21:02:52,063  - mini_batch_size: \"32\"\n2019-08-11 21:02:52,065  - patience: \"3\"\n2019-08-11 21:02:52,066  - anneal_factor: \"0.5\"\n2019-08-11 21:02:52,068  - max_epochs: \"20\"\n2019-08-11 21:02:52,069  - shuffle: \"True\"\n2019-08-11 21:02:52,070  - train_with_dev: \"False\"\n2019-08-11 21:02:52,070 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:02:52,071 Model training base path: \"model/XLNet\"\n2019-08-11 21:02:52,072 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:02:52,073 Device: cuda:0\n2019-08-11 21:02:52,074 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:02:52,075 Embeddings storage mode: cpu\n2019-08-11 21:02:52,078 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:03:07,092 epoch 1 - iter 0/56 - loss 1.81420386 throughput (samples/sec): 14.02\n2019-08-11 21:03:51,625 epoch 1 - iter 5/56 - loss 2.02399637 throughput (samples/sec): 3.71\n2019-08-11 21:04:36,056 epoch 1 - iter 10/56 - loss 1.93481602 throughput (samples/sec): 3.77\n2019-08-11 21:05:24,658 epoch 1 - iter 15/56 - loss 1.85725356 throughput (samples/sec): 3.37\n2019-08-11 21:06:08,378 epoch 1 - iter 20/56 - loss 1.81716320 throughput (samples/sec): 3.80\n2019-08-11 21:06:55,684 epoch 1 - iter 25/56 - loss 1.81109017 throughput (samples/sec): 3.50\n2019-08-11 21:07:44,866 epoch 1 - iter 30/56 - loss 1.78587899 throughput (samples/sec): 3.34\n2019-08-11 21:08:33,002 epoch 1 - iter 35/56 - loss 1.77084007 throughput (samples/sec): 3.45\n2019-08-11 21:09:20,411 epoch 1 - iter 40/56 - loss 1.76565667 throughput (samples/sec): 3.52\n2019-08-11 21:10:08,799 epoch 1 - iter 45/56 - loss 1.74429310 throughput (samples/sec): 3.45\n2019-08-11 21:10:52,863 epoch 1 - iter 50/56 - loss 1.72460998 throughput (samples/sec): 3.76\n2019-08-11 21:11:33,019 epoch 1 - iter 55/56 - loss 1.69901044 throughput (samples/sec): 4.11\n2019-08-11 21:11:33,560 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:11:33,561 EPOCH 1 done: loss 1.6990 - lr 0.1000\n2019-08-11 21:12:41,511 DEV : loss 1.511185884475708 - score 0.3333\n2019-08-11 21:12:46,958 BAD EPOCHS (no improvement): 0\n2019-08-11 21:12:49,338 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:13:03,469 epoch 2 - iter 0/56 - loss 0.99797136 throughput (samples/sec): 14.41\n2019-08-11 21:13:53,294 epoch 2 - iter 5/56 - loss 1.38267643 throughput (samples/sec): 3.30\n2019-08-11 21:14:43,556 epoch 2 - iter 10/56 - loss 1.37936426 throughput (samples/sec): 3.27\n2019-08-11 21:15:30,430 epoch 2 - iter 15/56 - loss 1.36462631 throughput (samples/sec): 3.54\n2019-08-11 21:16:16,178 epoch 2 - iter 20/56 - loss 1.33226089 throughput (samples/sec): 3.61\n2019-08-11 21:17:03,657 epoch 2 - iter 25/56 - loss 1.32152350 throughput (samples/sec): 3.47\n2019-08-11 21:17:46,751 epoch 2 - iter 30/56 - loss 1.31876459 throughput (samples/sec): 3.81\n2019-08-11 21:18:35,902 epoch 2 - iter 35/56 - loss 1.30699956 throughput (samples/sec): 3.34\n2019-08-11 21:19:20,247 epoch 2 - iter 40/56 - loss 1.30241554 throughput (samples/sec): 3.71\n2019-08-11 21:20:06,774 epoch 2 - iter 45/56 - loss 1.29687253 throughput (samples/sec): 3.55\n2019-08-11 21:20:50,477 epoch 2 - iter 50/56 - loss 1.28062161 throughput (samples/sec): 3.78\n2019-08-11 21:21:30,236 epoch 2 - iter 55/56 - loss 1.25894499 throughput (samples/sec): 4.15\n2019-08-11 21:21:30,827 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:21:30,828 EPOCH 2 done: loss 1.2589 - lr 0.1000\n2019-08-11 21:22:40,035 DEV : loss 1.1443533897399902 - score 0.5586\n2019-08-11 21:22:45,241 BAD EPOCHS (no improvement): 0\n2019-08-11 21:22:47,773 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:23:03,655 epoch 3 - iter 0/56 - loss 0.82951409 throughput (samples/sec): 16.07\n2019-08-11 21:23:53,109 epoch 3 - iter 5/56 - loss 0.92787263 throughput (samples/sec): 3.35\n2019-08-11 21:24:41,792 epoch 3 - iter 10/56 - loss 0.89177034 throughput (samples/sec): 3.41\n2019-08-11 21:25:30,498 epoch 3 - iter 15/56 - loss 0.87284896 throughput (samples/sec): 3.40\n2019-08-11 21:26:15,021 epoch 3 - iter 20/56 - loss 0.86940693 throughput (samples/sec): 3.73\n2019-08-11 21:26:58,439 epoch 3 - iter 25/56 - loss 0.89296936 throughput (samples/sec): 3.81\n2019-08-11 21:27:45,393 epoch 3 - iter 30/56 - loss 0.91014759 throughput (samples/sec): 3.51\n2019-08-11 21:28:31,156 epoch 3 - iter 35/56 - loss 0.89281268 throughput (samples/sec): 3.62\n2019-08-11 21:29:17,374 epoch 3 - iter 40/56 - loss 0.87166456 throughput (samples/sec): 3.59\n2019-08-11 21:30:06,091 epoch 3 - iter 45/56 - loss 0.84430831 throughput (samples/sec): 3.40\n2019-08-11 21:30:49,288 epoch 3 - iter 50/56 - loss 0.84680003 throughput (samples/sec): 3.84\n2019-08-11 21:31:35,080 epoch 3 - iter 55/56 - loss 0.83995420 throughput (samples/sec): 3.61\n2019-08-11 21:31:35,678 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:31:35,679 EPOCH 3 done: loss 0.8400 - lr 0.1000\n2019-08-11 21:32:44,860 DEV : loss 0.9159009456634521 - score 0.6802\n2019-08-11 21:32:50,144 BAD EPOCHS (no improvement): 0\n2019-08-11 21:32:52,502 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:33:09,862 epoch 4 - iter 0/56 - loss 0.50273657 throughput (samples/sec): 15.44\n2019-08-11 21:33:56,261 epoch 4 - iter 5/56 - loss 0.55481663 throughput (samples/sec): 3.49\n2019-08-11 21:34:44,724 epoch 4 - iter 10/56 - loss 0.56819396 throughput (samples/sec): 3.40\n2019-08-11 21:35:30,105 epoch 4 - iter 15/56 - loss 0.53415141 throughput (samples/sec): 3.61\n2019-08-11 21:36:18,934 epoch 4 - iter 20/56 - loss 0.52457358 throughput (samples/sec): 3.37\n2019-08-11 21:37:07,044 epoch 4 - iter 25/56 - loss 0.51022095 throughput (samples/sec): 3.43\n2019-08-11 21:37:53,527 epoch 4 - iter 30/56 - loss 0.49954229 throughput (samples/sec): 3.54\n2019-08-11 21:38:38,255 epoch 4 - iter 35/56 - loss 0.50482722 throughput (samples/sec): 3.63\n2019-08-11 21:39:20,702 epoch 4 - iter 40/56 - loss 0.51603997 throughput (samples/sec): 3.89\n2019-08-11 21:40:08,812 epoch 4 - iter 45/56 - loss 0.52184120 throughput (samples/sec): 3.40\n2019-08-11 21:40:52,835 epoch 4 - iter 50/56 - loss 0.52720577 throughput (samples/sec): 3.74\n2019-08-11 21:41:33,577 epoch 4 - iter 55/56 - loss 0.52338156 throughput (samples/sec): 4.01\n2019-08-11 21:41:34,187 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:41:34,188 EPOCH 4 done: loss 0.5234 - lr 0.1000\n2019-08-11 21:42:39,160 DEV : loss 0.760908842086792 - score 0.7387\n2019-08-11 21:42:44,380 BAD EPOCHS (no improvement): 0\n2019-08-11 21:42:46,638 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:43:00,389 epoch 5 - iter 0/56 - loss 0.32308036 throughput (samples/sec): 14.29\n2019-08-11 21:43:49,367 epoch 5 - iter 5/56 - loss 0.51836693 throughput (samples/sec): 3.34\n2019-08-11 21:44:36,211 epoch 5 - iter 10/56 - loss 0.48810141 throughput (samples/sec): 3.52\n2019-08-11 21:45:19,642 epoch 5 - iter 15/56 - loss 0.43963170 throughput (samples/sec): 3.80\n2019-08-11 21:46:09,285 epoch 5 - iter 20/56 - loss 0.41505874 throughput (samples/sec): 3.32\n2019-08-11 21:46:56,373 epoch 5 - iter 25/56 - loss 0.38885937 throughput (samples/sec): 3.50\n2019-08-11 21:47:39,874 epoch 5 - iter 30/56 - loss 0.38822781 throughput (samples/sec): 3.73\n","name":"stdout"},{"output_type":"stream","text":"2019-08-11 21:48:26,783 epoch 5 - iter 35/56 - loss 0.37509374 throughput (samples/sec): 3.50\n2019-08-11 21:49:14,546 epoch 5 - iter 40/56 - loss 0.37047550 throughput (samples/sec): 3.45\n2019-08-11 21:49:59,658 epoch 5 - iter 45/56 - loss 0.36532876 throughput (samples/sec): 3.66\n2019-08-11 21:50:41,555 epoch 5 - iter 50/56 - loss 0.36349464 throughput (samples/sec): 3.92\n2019-08-11 21:51:24,764 epoch 5 - iter 55/56 - loss 0.36419871 throughput (samples/sec): 3.78\n2019-08-11 21:51:25,359 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:51:25,360 EPOCH 5 done: loss 0.3642 - lr 0.1000\n2019-08-11 21:52:33,215 DEV : loss 0.7668599486351013 - score 0.7432\n2019-08-11 21:52:38,214 BAD EPOCHS (no improvement): 0\n2019-08-11 21:52:40,510 ----------------------------------------------------------------------------------------------------\n2019-08-11 21:52:57,845 epoch 6 - iter 0/56 - loss 0.35556152 throughput (samples/sec): 15.27\n2019-08-11 21:53:44,919 epoch 6 - iter 5/56 - loss 0.20813602 throughput (samples/sec): 3.45\n2019-08-11 21:54:30,498 epoch 6 - iter 10/56 - loss 0.20765575 throughput (samples/sec): 3.61\n2019-08-11 21:55:17,775 epoch 6 - iter 15/56 - loss 0.18070957 throughput (samples/sec): 3.46\n2019-08-11 21:56:02,510 epoch 6 - iter 20/56 - loss 0.21545084 throughput (samples/sec): 3.68\n2019-08-11 21:56:50,366 epoch 6 - iter 25/56 - loss 0.22592142 throughput (samples/sec): 3.44\n2019-08-11 21:57:31,951 epoch 6 - iter 30/56 - loss 0.23191939 throughput (samples/sec): 3.97\n2019-08-11 21:58:17,862 epoch 6 - iter 35/56 - loss 0.24180695 throughput (samples/sec): 3.54\n2019-08-11 21:59:08,181 epoch 6 - iter 40/56 - loss 0.23945821 throughput (samples/sec): 3.27\n2019-08-11 21:59:57,342 epoch 6 - iter 45/56 - loss 0.24288245 throughput (samples/sec): 3.33\n2019-08-11 22:00:40,274 epoch 6 - iter 50/56 - loss 0.23751942 throughput (samples/sec): 3.83\n2019-08-11 22:01:19,770 epoch 6 - iter 55/56 - loss 0.23828043 throughput (samples/sec): 4.14\n2019-08-11 22:01:20,358 ----------------------------------------------------------------------------------------------------\n2019-08-11 22:01:20,360 EPOCH 6 done: loss 0.2383 - lr 0.1000\n2019-08-11 22:02:28,056 DEV : loss 0.535214364528656 - score 0.8288\n2019-08-11 22:02:33,316 BAD EPOCHS (no improvement): 0\n2019-08-11 22:02:35,609 ----------------------------------------------------------------------------------------------------\n2019-08-11 22:02:51,275 epoch 7 - iter 0/56 - loss 0.13328777 throughput (samples/sec): 16.05\n2019-08-11 22:03:35,140 epoch 7 - iter 5/56 - loss 0.20584188 throughput (samples/sec): 3.68\n2019-08-11 22:04:20,764 epoch 7 - iter 10/56 - loss 0.18521882 throughput (samples/sec): 3.61\n2019-08-11 22:05:05,926 epoch 7 - iter 15/56 - loss 0.16361972 throughput (samples/sec): 3.63\n2019-08-11 22:05:50,004 epoch 7 - iter 20/56 - loss 0.14928019 throughput (samples/sec): 3.73\n2019-08-11 22:06:37,217 epoch 7 - iter 25/56 - loss 0.15666765 throughput (samples/sec): 3.47\n2019-08-11 22:07:21,715 epoch 7 - iter 30/56 - loss 0.15965302 throughput (samples/sec): 3.71\n2019-08-11 22:08:06,270 epoch 7 - iter 35/56 - loss 0.15483782 throughput (samples/sec): 3.63\n2019-08-11 22:08:55,421 epoch 7 - iter 40/56 - loss 0.16671647 throughput (samples/sec): 3.33\n2019-08-11 22:09:44,239 epoch 7 - iter 45/56 - loss 0.16353082 throughput (samples/sec): 3.37\n2019-08-11 22:10:30,923 epoch 7 - iter 50/56 - loss 0.15836554 throughput (samples/sec): 3.52\n2019-08-11 22:11:14,095 epoch 7 - iter 55/56 - loss 0.15946949 throughput (samples/sec): 3.76\n2019-08-11 22:11:14,702 ----------------------------------------------------------------------------------------------------\n2019-08-11 22:11:14,703 EPOCH 7 done: loss 0.1595 - lr 0.1000\n2019-08-11 22:12:22,661 DEV : loss 0.4873341917991638 - score 0.8288\n2019-08-11 22:12:27,890 BAD EPOCHS (no improvement): 1\n2019-08-11 22:12:30,215 ----------------------------------------------------------------------------------------------------\n2019-08-11 22:12:45,382 epoch 8 - iter 0/56 - loss 0.04664762 throughput (samples/sec): 15.34\n2019-08-11 22:13:33,470 epoch 8 - iter 5/56 - loss 0.10579078 throughput (samples/sec): 3.41\n2019-08-11 22:14:18,404 epoch 8 - iter 10/56 - loss 0.11036012 throughput (samples/sec): 3.72\n2019-08-11 22:15:05,885 epoch 8 - iter 15/56 - loss 0.11780161 throughput (samples/sec): 3.52\n2019-08-11 22:15:52,017 epoch 8 - iter 20/56 - loss 0.10561500 throughput (samples/sec): 3.57\n2019-08-11 22:16:39,781 epoch 8 - iter 25/56 - loss 0.10369915 throughput (samples/sec): 3.43\n2019-08-11 22:17:28,476 epoch 8 - iter 30/56 - loss 0.10202468 throughput (samples/sec): 3.37\n2019-08-11 22:18:13,170 epoch 8 - iter 35/56 - loss 0.11872724 throughput (samples/sec): 3.69\n2019-08-11 22:18:56,810 epoch 8 - iter 40/56 - loss 0.11893413 throughput (samples/sec): 3.72\n2019-08-11 22:19:44,067 epoch 8 - iter 45/56 - loss 0.12016697 throughput (samples/sec): 3.49\n2019-08-11 22:20:29,727 epoch 8 - iter 50/56 - loss 0.11856521 throughput (samples/sec): 3.60\n2019-08-11 22:21:09,244 epoch 8 - iter 55/56 - loss 0.11300818 throughput (samples/sec): 4.12\n2019-08-11 22:21:09,843 ----------------------------------------------------------------------------------------------------\n2019-08-11 22:21:09,844 EPOCH 8 done: loss 0.1130 - lr 0.1000\n2019-08-11 22:22:17,222 DEV : loss 0.4286274313926697 - score 0.8604\n2019-08-11 22:22:22,491 BAD EPOCHS (no improvement): 0\n2019-08-11 22:22:24,895 ----------------------------------------------------------------------------------------------------\n2019-08-11 22:22:40,018 epoch 9 - iter 0/56 - loss 0.04269969 throughput (samples/sec): 16.90\n2019-08-11 22:23:21,981 epoch 9 - iter 5/56 - loss 0.05092711 throughput (samples/sec): 3.87\n2019-08-11 22:24:12,054 epoch 9 - iter 10/56 - loss 0.07047408 throughput (samples/sec): 3.27\n2019-08-11 22:24:56,387 epoch 9 - iter 15/56 - loss 0.07085600 throughput (samples/sec): 3.74\n2019-08-11 22:25:42,120 epoch 9 - iter 20/56 - loss 0.06837158 throughput (samples/sec): 3.61\n2019-08-11 22:26:30,175 epoch 9 - iter 25/56 - loss 0.06673711 throughput (samples/sec): 3.43\n2019-08-11 22:27:15,530 epoch 9 - iter 30/56 - loss 0.06971774 throughput (samples/sec): 3.64\n2019-08-11 22:28:05,265 epoch 9 - iter 35/56 - loss 0.07349810 throughput (samples/sec): 3.26\n2019-08-11 22:28:50,325 epoch 9 - iter 40/56 - loss 0.07153201 throughput (samples/sec): 3.64\n2019-08-11 22:29:35,659 epoch 9 - iter 45/56 - loss 0.07147552 throughput (samples/sec): 3.67\n2019-08-11 22:30:22,072 epoch 9 - iter 50/56 - loss 0.07528603 throughput (samples/sec): 3.55\n2019-08-11 22:31:02,602 epoch 9 - iter 55/56 - loss 0.07631826 throughput (samples/sec): 4.04\n2019-08-11 22:31:03,201 ----------------------------------------------------------------------------------------------------\n2019-08-11 22:31:03,202 EPOCH 9 done: loss 0.0763 - lr 0.1000\n2019-08-11 22:32:10,562 DEV : loss 0.49445217847824097 - score 0.8243\n2019-08-11 22:32:15,502 BAD EPOCHS (no improvement): 1\n2019-08-11 22:32:15,503 ----------------------------------------------------------------------------------------------------\n2019-08-11 22:32:30,676 epoch 10 - iter 0/56 - loss 0.27519774 throughput (samples/sec): 16.46\n2019-08-11 22:33:15,212 epoch 10 - iter 5/56 - loss 0.14392814 throughput (samples/sec): 3.68\n2019-08-11 22:34:01,981 epoch 10 - iter 10/56 - loss 0.09033974 throughput (samples/sec): 3.54\n2019-08-11 22:34:47,813 epoch 10 - iter 15/56 - loss 0.07977746 throughput (samples/sec): 3.60\n2019-08-11 22:35:34,899 epoch 10 - iter 20/56 - loss 0.08139728 throughput (samples/sec): 3.52\n2019-08-11 22:36:22,151 epoch 10 - iter 25/56 - loss 0.07845104 throughput (samples/sec): 3.50\n2019-08-11 22:37:09,446 epoch 10 - iter 30/56 - loss 0.07296785 throughput (samples/sec): 3.47\n2019-08-11 22:37:56,510 epoch 10 - iter 35/56 - loss 0.06861129 throughput (samples/sec): 3.48\n2019-08-11 22:38:42,791 epoch 10 - iter 40/56 - loss 0.06427237 throughput (samples/sec): 3.58\n2019-08-11 22:39:26,816 epoch 10 - iter 45/56 - loss 0.06688047 throughput (samples/sec): 3.75\n2019-08-11 22:40:12,172 epoch 10 - iter 50/56 - loss 0.06375312 throughput (samples/sec): 3.65\n","name":"stdout"},{"output_type":"stream","text":"2019-08-11 22:40:53,156 epoch 10 - iter 55/56 - loss 0.06143723 throughput (samples/sec): 4.01\n2019-08-11 22:40:53,775 ----------------------------------------------------------------------------------------------------\n2019-08-11 22:40:53,776 EPOCH 10 done: loss 0.0614 - lr 0.1000\n2019-08-11 22:42:00,365 DEV : loss 0.44395333528518677 - score 0.8649\n2019-08-11 22:42:05,619 BAD EPOCHS (no improvement): 0\n2019-08-11 22:42:07,901 ----------------------------------------------------------------------------------------------------\n2019-08-11 22:42:22,651 epoch 11 - iter 0/56 - loss 0.02941830 throughput (samples/sec): 13.21\n2019-08-11 22:43:09,046 epoch 11 - iter 5/56 - loss 0.03640752 throughput (samples/sec): 3.55\n2019-08-11 22:43:54,175 epoch 11 - iter 10/56 - loss 0.03933015 throughput (samples/sec): 3.70\n2019-08-11 22:44:41,842 epoch 11 - iter 15/56 - loss 0.03523559 throughput (samples/sec): 3.50\n2019-08-11 22:45:29,287 epoch 11 - iter 20/56 - loss 0.03409601 throughput (samples/sec): 3.46\n2019-08-11 22:46:15,825 epoch 11 - iter 25/56 - loss 0.03231617 throughput (samples/sec): 3.56\n2019-08-11 22:47:01,223 epoch 11 - iter 30/56 - loss 0.03216134 throughput (samples/sec): 3.65\n2019-08-11 22:47:46,678 epoch 11 - iter 35/56 - loss 0.03403513 throughput (samples/sec): 3.65\n2019-08-11 22:48:33,453 epoch 11 - iter 40/56 - loss 0.03417733 throughput (samples/sec): 3.57\n2019-08-11 22:49:20,799 epoch 11 - iter 45/56 - loss 0.03361747 throughput (samples/sec): 3.52\n2019-08-11 22:50:05,800 epoch 11 - iter 50/56 - loss 0.03358137 throughput (samples/sec): 3.66\n2019-08-11 22:50:50,487 epoch 11 - iter 55/56 - loss 0.03515665 throughput (samples/sec): 3.70\n2019-08-11 22:50:51,095 ----------------------------------------------------------------------------------------------------\n2019-08-11 22:50:51,097 EPOCH 11 done: loss 0.0352 - lr 0.1000\n2019-08-11 22:51:59,055 DEV : loss 0.5464146137237549 - score 0.8739\n2019-08-11 22:52:04,315 BAD EPOCHS (no improvement): 0\n2019-08-11 22:52:06,785 ----------------------------------------------------------------------------------------------------\n2019-08-11 22:52:21,465 epoch 12 - iter 0/56 - loss 0.11565808 throughput (samples/sec): 16.64\n2019-08-11 22:53:06,727 epoch 12 - iter 5/56 - loss 0.03066471 throughput (samples/sec): 3.60\n2019-08-11 22:53:52,541 epoch 12 - iter 10/56 - loss 0.02765049 throughput (samples/sec): 3.60\n2019-08-11 22:54:40,157 epoch 12 - iter 15/56 - loss 0.03429441 throughput (samples/sec): 3.47\n2019-08-11 22:55:30,973 epoch 12 - iter 20/56 - loss 0.03232376 throughput (samples/sec): 3.24\n2019-08-11 22:56:17,006 epoch 12 - iter 25/56 - loss 0.02998067 throughput (samples/sec): 3.59\n2019-08-11 22:57:03,992 epoch 12 - iter 30/56 - loss 0.03021718 throughput (samples/sec): 3.48\n2019-08-11 22:57:49,627 epoch 12 - iter 35/56 - loss 0.02886271 throughput (samples/sec): 3.57\n2019-08-11 22:58:32,001 epoch 12 - iter 40/56 - loss 0.02928851 throughput (samples/sec): 3.91\n2019-08-11 22:59:18,014 epoch 12 - iter 45/56 - loss 0.02878420 throughput (samples/sec): 3.59\n2019-08-11 23:00:02,741 epoch 12 - iter 50/56 - loss 0.02775219 throughput (samples/sec): 3.69\n2019-08-11 23:00:45,731 epoch 12 - iter 55/56 - loss 0.02809566 throughput (samples/sec): 3.80\n2019-08-11 23:00:46,346 ----------------------------------------------------------------------------------------------------\n2019-08-11 23:00:46,347 EPOCH 12 done: loss 0.0281 - lr 0.1000\n2019-08-11 23:01:54,624 DEV : loss 0.4369787573814392 - score 0.8739\n2019-08-11 23:01:59,713 BAD EPOCHS (no improvement): 1\n2019-08-11 23:02:01,976 ----------------------------------------------------------------------------------------------------\n2019-08-11 23:02:17,923 epoch 13 - iter 0/56 - loss 0.01858345 throughput (samples/sec): 15.84\n2019-08-11 23:03:03,987 epoch 13 - iter 5/56 - loss 0.02336314 throughput (samples/sec): 3.55\n2019-08-11 23:03:51,203 epoch 13 - iter 10/56 - loss 0.02430956 throughput (samples/sec): 3.49\n2019-08-11 23:04:40,422 epoch 13 - iter 15/56 - loss 0.02052494 throughput (samples/sec): 3.34\n2019-08-11 23:05:28,184 epoch 13 - iter 20/56 - loss 0.02497648 throughput (samples/sec): 3.44\n2019-08-11 23:06:12,791 epoch 13 - iter 25/56 - loss 0.02416025 throughput (samples/sec): 3.68\n2019-08-11 23:06:55,671 epoch 13 - iter 30/56 - loss 0.02425240 throughput (samples/sec): 3.85\n2019-08-11 23:07:41,616 epoch 13 - iter 35/56 - loss 0.02298440 throughput (samples/sec): 3.56\n2019-08-11 23:08:27,427 epoch 13 - iter 40/56 - loss 0.02110173 throughput (samples/sec): 3.59\n2019-08-11 23:09:14,183 epoch 13 - iter 45/56 - loss 0.02081281 throughput (samples/sec): 3.51\n2019-08-11 23:09:58,070 epoch 13 - iter 50/56 - loss 0.02267187 throughput (samples/sec): 3.73\n2019-08-11 23:10:41,450 epoch 13 - iter 55/56 - loss 0.02278230 throughput (samples/sec): 3.81\n2019-08-11 23:10:42,059 ----------------------------------------------------------------------------------------------------\n2019-08-11 23:10:42,060 EPOCH 13 done: loss 0.0228 - lr 0.1000\n2019-08-11 23:11:50,557 DEV : loss 0.5136649012565613 - score 0.8649\n2019-08-11 23:11:55,955 BAD EPOCHS (no improvement): 2\n2019-08-11 23:11:55,957 ----------------------------------------------------------------------------------------------------\n2019-08-11 23:12:11,171 epoch 14 - iter 0/56 - loss 0.00864273 throughput (samples/sec): 14.33\n2019-08-11 23:12:59,851 epoch 14 - iter 5/56 - loss 0.01584687 throughput (samples/sec): 3.35\n2019-08-11 23:13:45,111 epoch 14 - iter 10/56 - loss 0.01620846 throughput (samples/sec): 3.65\n2019-08-11 23:14:32,353 epoch 14 - iter 15/56 - loss 0.01314310 throughput (samples/sec): 3.51\n2019-08-11 23:15:15,668 epoch 14 - iter 20/56 - loss 0.01299176 throughput (samples/sec): 3.79\n2019-08-11 23:16:03,476 epoch 14 - iter 25/56 - loss 0.01320815 throughput (samples/sec): 3.45\n2019-08-11 23:16:49,697 epoch 14 - iter 30/56 - loss 0.01242623 throughput (samples/sec): 3.57\n2019-08-11 23:17:37,442 epoch 14 - iter 35/56 - loss 0.01140092 throughput (samples/sec): 3.45\n2019-08-11 23:18:24,398 epoch 14 - iter 40/56 - loss 0.01139052 throughput (samples/sec): 3.51\n2019-08-11 23:19:10,897 epoch 14 - iter 45/56 - loss 0.01133142 throughput (samples/sec): 3.54\n2019-08-11 23:19:54,515 epoch 14 - iter 50/56 - loss 0.01154330 throughput (samples/sec): 3.75\n2019-08-11 23:20:34,935 epoch 14 - iter 55/56 - loss 0.01231058 throughput (samples/sec): 4.07\n2019-08-11 23:20:35,545 ----------------------------------------------------------------------------------------------------\n2019-08-11 23:20:35,547 EPOCH 14 done: loss 0.0123 - lr 0.1000\n2019-08-11 23:21:43,811 DEV : loss 0.42502957582473755 - score 0.8784\n2019-08-11 23:21:48,937 BAD EPOCHS (no improvement): 0\n2019-08-11 23:21:51,547 ----------------------------------------------------------------------------------------------------\n2019-08-11 23:22:09,333 epoch 15 - iter 0/56 - loss 0.00689173 throughput (samples/sec): 14.61\n2019-08-11 23:22:56,144 epoch 15 - iter 5/56 - loss 0.00765407 throughput (samples/sec): 3.49\n2019-08-11 23:23:41,522 epoch 15 - iter 10/56 - loss 0.00742438 throughput (samples/sec): 3.65\n2019-08-11 23:24:28,616 epoch 15 - iter 15/56 - loss 0.01366561 throughput (samples/sec): 3.49\n2019-08-11 23:25:13,990 epoch 15 - iter 20/56 - loss 0.01617899 throughput (samples/sec): 3.63\n2019-08-11 23:25:59,179 epoch 15 - iter 25/56 - loss 0.01568248 throughput (samples/sec): 3.67\n2019-08-11 23:26:45,187 epoch 15 - iter 30/56 - loss 0.01485171 throughput (samples/sec): 3.60\n2019-08-11 23:27:32,129 epoch 15 - iter 35/56 - loss 0.01479873 throughput (samples/sec): 3.48\n2019-08-11 23:28:16,886 epoch 15 - iter 40/56 - loss 0.01436540 throughput (samples/sec): 3.70\n2019-08-11 23:29:00,721 epoch 15 - iter 45/56 - loss 0.01467403 throughput (samples/sec): 3.76\n2019-08-11 23:29:49,692 epoch 15 - iter 50/56 - loss 0.01411838 throughput (samples/sec): 3.36\n2019-08-11 23:30:31,565 epoch 15 - iter 55/56 - loss 0.01427819 throughput (samples/sec): 3.93\n2019-08-11 23:30:32,170 ----------------------------------------------------------------------------------------------------\n2019-08-11 23:30:32,171 EPOCH 15 done: loss 0.0143 - lr 0.1000\n2019-08-11 23:31:40,118 DEV : loss 0.5312831401824951 - score 0.8784\n","name":"stdout"},{"output_type":"stream","text":"2019-08-11 23:31:45,378 BAD EPOCHS (no improvement): 1\n2019-08-11 23:31:47,798 ----------------------------------------------------------------------------------------------------\n2019-08-11 23:32:02,593 epoch 16 - iter 0/56 - loss 0.01503138 throughput (samples/sec): 13.20\n2019-08-11 23:32:49,879 epoch 16 - iter 5/56 - loss 0.00810531 throughput (samples/sec): 3.49\n2019-08-11 23:33:34,731 epoch 16 - iter 10/56 - loss 0.00848951 throughput (samples/sec): 3.68\n2019-08-11 23:34:20,931 epoch 16 - iter 15/56 - loss 0.00873140 throughput (samples/sec): 3.59\n2019-08-11 23:35:08,821 epoch 16 - iter 20/56 - loss 0.01021040 throughput (samples/sec): 3.44\n2019-08-11 23:35:52,216 epoch 16 - iter 25/56 - loss 0.01102074 throughput (samples/sec): 3.77\n2019-08-11 23:36:38,986 epoch 16 - iter 30/56 - loss 0.01100238 throughput (samples/sec): 3.49\n2019-08-11 23:37:24,549 epoch 16 - iter 35/56 - loss 0.01081148 throughput (samples/sec): 3.60\n2019-08-11 23:38:14,540 epoch 16 - iter 40/56 - loss 0.01149693 throughput (samples/sec): 3.29\n2019-08-11 23:38:57,156 epoch 16 - iter 45/56 - loss 0.01138903 throughput (samples/sec): 3.87\n2019-08-11 23:39:42,274 epoch 16 - iter 50/56 - loss 0.01125481 throughput (samples/sec): 3.65\n2019-08-11 23:40:24,888 epoch 16 - iter 55/56 - loss 0.01084854 throughput (samples/sec): 3.81\n2019-08-11 23:40:25,492 ----------------------------------------------------------------------------------------------------\n2019-08-11 23:40:25,493 EPOCH 16 done: loss 0.0108 - lr 0.1000\n2019-08-11 23:41:33,549 DEV : loss 0.41548940539360046 - score 0.8874\n2019-08-11 23:41:38,836 BAD EPOCHS (no improvement): 0\n2019-08-11 23:41:41,502 ----------------------------------------------------------------------------------------------------\n2019-08-11 23:41:57,466 epoch 17 - iter 0/56 - loss 0.00815070 throughput (samples/sec): 15.35\n2019-08-11 23:42:43,084 epoch 17 - iter 5/56 - loss 0.01066555 throughput (samples/sec): 3.56\n2019-08-11 23:43:28,807 epoch 17 - iter 10/56 - loss 0.00986383 throughput (samples/sec): 3.60\n2019-08-11 23:44:16,572 epoch 17 - iter 15/56 - loss 0.00932670 throughput (samples/sec): 3.45\n2019-08-11 23:45:01,785 epoch 17 - iter 20/56 - loss 0.01036796 throughput (samples/sec): 3.64\n2019-08-11 23:45:46,807 epoch 17 - iter 25/56 - loss 0.00976947 throughput (samples/sec): 3.63\n2019-08-11 23:46:35,939 epoch 17 - iter 30/56 - loss 0.00979328 throughput (samples/sec): 3.35\n2019-08-11 23:47:21,510 epoch 17 - iter 35/56 - loss 0.00954211 throughput (samples/sec): 3.57\n2019-08-11 23:48:05,540 epoch 17 - iter 40/56 - loss 0.01005102 throughput (samples/sec): 3.75\n2019-08-11 23:48:52,934 epoch 17 - iter 45/56 - loss 0.00993449 throughput (samples/sec): 3.47\n2019-08-11 23:49:39,361 epoch 17 - iter 50/56 - loss 0.00958636 throughput (samples/sec): 3.54\n2019-08-11 23:50:20,119 epoch 17 - iter 55/56 - loss 0.00924989 throughput (samples/sec): 3.99\n2019-08-11 23:50:20,706 ----------------------------------------------------------------------------------------------------\n2019-08-11 23:50:20,707 EPOCH 17 done: loss 0.0092 - lr 0.1000\n2019-08-11 23:51:28,754 DEV : loss 0.4243521988391876 - score 0.8919\n2019-08-11 23:51:34,093 BAD EPOCHS (no improvement): 0\n2019-08-11 23:51:36,563 ----------------------------------------------------------------------------------------------------\n2019-08-11 23:51:53,355 epoch 18 - iter 0/56 - loss 0.00539139 throughput (samples/sec): 14.47\n2019-08-11 23:52:43,042 epoch 18 - iter 5/56 - loss 0.01258009 throughput (samples/sec): 3.26\n2019-08-11 23:53:27,044 epoch 18 - iter 10/56 - loss 0.01216321 throughput (samples/sec): 3.75\n2019-08-11 23:54:10,952 epoch 18 - iter 15/56 - loss 0.01176229 throughput (samples/sec): 3.73\n2019-08-11 23:54:56,716 epoch 18 - iter 20/56 - loss 0.01013553 throughput (samples/sec): 3.60\n2019-08-11 23:55:40,587 epoch 18 - iter 25/56 - loss 0.01022111 throughput (samples/sec): 3.76\n2019-08-11 23:56:28,902 epoch 18 - iter 30/56 - loss 0.01103779 throughput (samples/sec): 3.40\n2019-08-11 23:57:14,848 epoch 18 - iter 35/56 - loss 0.01100198 throughput (samples/sec): 3.57\n2019-08-11 23:58:03,589 epoch 18 - iter 40/56 - loss 0.01068010 throughput (samples/sec): 3.38\n2019-08-11 23:58:48,727 epoch 18 - iter 45/56 - loss 0.01046252 throughput (samples/sec): 3.60\n2019-08-11 23:59:32,220 epoch 18 - iter 50/56 - loss 0.01006615 throughput (samples/sec): 3.80\n2019-08-12 00:00:14,593 epoch 18 - iter 55/56 - loss 0.00972359 throughput (samples/sec): 3.86\n2019-08-12 00:00:15,204 ----------------------------------------------------------------------------------------------------\n2019-08-12 00:00:15,205 EPOCH 18 done: loss 0.0097 - lr 0.1000\n2019-08-12 00:01:20,776 DEV : loss 0.44560182094573975 - score 0.9009\n2019-08-12 00:01:25,866 BAD EPOCHS (no improvement): 0\n2019-08-12 00:01:28,499 ----------------------------------------------------------------------------------------------------\n2019-08-12 00:01:45,810 epoch 19 - iter 0/56 - loss 0.00822274 throughput (samples/sec): 15.80\n2019-08-12 00:02:30,125 epoch 19 - iter 5/56 - loss 0.00839595 throughput (samples/sec): 3.64\n2019-08-12 00:03:14,178 epoch 19 - iter 10/56 - loss 0.00679913 throughput (samples/sec): 3.73\n2019-08-12 00:04:03,163 epoch 19 - iter 15/56 - loss 0.00626727 throughput (samples/sec): 3.35\n2019-08-12 00:04:52,425 epoch 19 - iter 20/56 - loss 0.00710139 throughput (samples/sec): 3.33\n2019-08-12 00:05:38,489 epoch 19 - iter 25/56 - loss 0.00651699 throughput (samples/sec): 3.57\n2019-08-12 00:06:29,416 epoch 19 - iter 30/56 - loss 0.00713563 throughput (samples/sec): 3.23\n2019-08-12 00:07:14,343 epoch 19 - iter 35/56 - loss 0.00763849 throughput (samples/sec): 3.59\n2019-08-12 00:08:00,887 epoch 19 - iter 40/56 - loss 0.00736985 throughput (samples/sec): 3.52\n2019-08-12 00:08:43,583 epoch 19 - iter 45/56 - loss 0.00718733 throughput (samples/sec): 3.85\n2019-08-12 00:09:27,825 epoch 19 - iter 50/56 - loss 0.00734488 throughput (samples/sec): 3.73\n2019-08-12 00:10:08,992 epoch 19 - iter 55/56 - loss 0.00715272 throughput (samples/sec): 3.95\n2019-08-12 00:10:09,646 ----------------------------------------------------------------------------------------------------\n2019-08-12 00:10:09,647 EPOCH 19 done: loss 0.0072 - lr 0.1000\n2019-08-12 00:11:15,019 DEV : loss 0.43727773427963257 - score 0.8874\n2019-08-12 00:11:20,166 BAD EPOCHS (no improvement): 1\n2019-08-12 00:11:20,168 ----------------------------------------------------------------------------------------------------\n2019-08-12 00:11:31,222 epoch 20 - iter 0/56 - loss 0.02225535 throughput (samples/sec): 17.93\n2019-08-12 00:12:16,595 epoch 20 - iter 5/56 - loss 0.00886716 throughput (samples/sec): 3.63\n2019-08-12 00:13:03,353 epoch 20 - iter 10/56 - loss 0.00705986 throughput (samples/sec): 3.53\n2019-08-12 00:13:46,410 epoch 20 - iter 15/56 - loss 0.00754714 throughput (samples/sec): 3.85\n2019-08-12 00:14:32,049 epoch 20 - iter 20/56 - loss 0.00723437 throughput (samples/sec): 3.64\n2019-08-12 00:15:22,438 epoch 20 - iter 25/56 - loss 0.00706562 throughput (samples/sec): 3.31\n2019-08-12 00:16:09,094 epoch 20 - iter 30/56 - loss 0.00706174 throughput (samples/sec): 3.50\n2019-08-12 00:16:54,851 epoch 20 - iter 35/56 - loss 0.01010444 throughput (samples/sec): 3.60\n2019-08-12 00:17:40,825 epoch 20 - iter 40/56 - loss 0.00972887 throughput (samples/sec): 3.59\n2019-08-12 00:18:25,372 epoch 20 - iter 45/56 - loss 0.00943610 throughput (samples/sec): 3.72\n2019-08-12 00:19:12,086 epoch 20 - iter 50/56 - loss 0.00925360 throughput (samples/sec): 3.54\n2019-08-12 00:19:55,646 epoch 20 - iter 55/56 - loss 0.00891646 throughput (samples/sec): 3.77\n2019-08-12 00:19:56,266 ----------------------------------------------------------------------------------------------------\n2019-08-12 00:19:56,267 EPOCH 20 done: loss 0.0089 - lr 0.1000\n2019-08-12 00:21:03,342 DEV : loss 0.43028390407562256 - score 0.8829\n2019-08-12 00:21:08,414 BAD EPOCHS (no improvement): 2\n2019-08-12 00:21:10,613 ----------------------------------------------------------------------------------------------------\n2019-08-12 00:21:10,615 Testing using best model ...\n2019-08-12 00:21:10,621 loading file model/XLNet/best-model.pt\n2019-08-12 00:22:11,927 0.8969\t0.8969\t0.8969\n","name":"stdout"},{"output_type":"stream","text":"2019-08-12 00:22:11,929 \nMICRO_AVG: acc 0.813 - f1-score 0.8969\nMACRO_AVG: acc 0.8082 - f1-score 0.8933\nbusiness   tp: 54 - fp: 2 - fn: 9 - tn: 158 - precision: 0.9643 - recall: 0.8571 - accuracy: 0.8308 - f1-score: 0.9075\nentertainment tp: 32 - fp: 5 - fn: 5 - tn: 181 - precision: 0.8649 - recall: 0.8649 - accuracy: 0.7619 - f1-score: 0.8649\npolitics   tp: 29 - fp: 7 - fn: 2 - tn: 185 - precision: 0.8056 - recall: 0.9355 - accuracy: 0.7632 - f1-score: 0.8657\nsport      tp: 42 - fp: 8 - fn: 2 - tn: 171 - precision: 0.8400 - recall: 0.9545 - accuracy: 0.8077 - f1-score: 0.8936\ntech       tp: 43 - fp: 1 - fn: 5 - tn: 174 - precision: 0.9773 - recall: 0.8958 - accuracy: 0.8776 - f1-score: 0.9348\n2019-08-12 00:22:11,932 ----------------------------------------------------------------------------------------------------\n","name":"stdout"},{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"{'test_score': 0.8969,\n 'dev_score_history': [0.3333,\n  0.5586,\n  0.6802,\n  0.7387,\n  0.7432,\n  0.8288,\n  0.8288,\n  0.8604,\n  0.8243,\n  0.8649,\n  0.8739,\n  0.8739,\n  0.8649,\n  0.8784,\n  0.8784,\n  0.8874,\n  0.8919,\n  0.9009,\n  0.8874,\n  0.8829],\n 'train_loss_history': [1.6990104424101966,\n  1.258944992508207,\n  0.8399542005998748,\n  0.523381558912141,\n  0.36419871023723055,\n  0.23828042950481176,\n  0.15946949226781726,\n  0.1130081759433129,\n  0.07631825782092554,\n  0.061437229925234406,\n  0.0351566451468638,\n  0.028095657138952186,\n  0.02278229793799775,\n  0.012310581653894457,\n  0.01427818974480033,\n  0.010848539004135611,\n  0.009249894505566252,\n  0.009723590953009469,\n  0.007152717851568013,\n  0.008916460455761157],\n 'dev_loss_history': [tensor(1.5112, device='cuda:0'),\n  tensor(1.1444, device='cuda:0'),\n  tensor(0.9159, device='cuda:0'),\n  tensor(0.7609, device='cuda:0'),\n  tensor(0.7669, device='cuda:0'),\n  tensor(0.5352, device='cuda:0'),\n  tensor(0.4873, device='cuda:0'),\n  tensor(0.4286, device='cuda:0'),\n  tensor(0.4945, device='cuda:0'),\n  tensor(0.4440, device='cuda:0'),\n  tensor(0.5464, device='cuda:0'),\n  tensor(0.4370, device='cuda:0'),\n  tensor(0.5137, device='cuda:0'),\n  tensor(0.4250, device='cuda:0'),\n  tensor(0.5313, device='cuda:0'),\n  tensor(0.4155, device='cuda:0'),\n  tensor(0.4244, device='cuda:0'),\n  tensor(0.4456, device='cuda:0'),\n  tensor(0.4373, device='cuda:0'),\n  tensor(0.4303, device='cuda:0')]}"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Plot training curves"},{"metadata":{"trusted":false},"cell_type":"code","source":"from flair.visual.training_curves import Plotter\n\nplotter = Plotter()\nplotter.plot_training_curves(os.path.join(MODEL_FOLDER_PATH, 'loss.tsv'))\nplotter.plot_weights(os.path.join(MODEL_FOLDER_PATH, 'weights.txt'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}